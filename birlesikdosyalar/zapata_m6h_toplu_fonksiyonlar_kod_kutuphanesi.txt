=== __getitem__ ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuningDataset
Program: zapata_m6h

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx], truncation=True, padding="max_length", max_length=self.max_length, return_tensors="pt"
        )
        encoding = {key: val.squeeze() for key, val in encoding.items()}
        encoding["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return encoding

=== __getitem__ ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningDataset
Program: zapata_m6h

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx], truncation=True, padding="max_length", max_length=self.max_length, return_tensors="pt"
        )
        encoding = {key: val.squeeze() for key, val in encoding.items()}
        encoding["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return encoding

=== __init__ ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def __init__(self, text_method="multi", table_method="multi", reference_method="advanced", debug_mode=False):
        self.text_methods = ["pdfplumber", "pymupdf", "pdfminer", "borb", "tika"]
        self.table_methods = ["pymupdf", "pdfplumber", "tabula", "camelot"]
        self.reference_methods = ["regex", "ml", "section_based"]

        self.text_method = text_method
        self.table_method = table_method
        self.reference_method = reference_method
        self.debug_mode = debug_mode

        # ML Modelleri
        self.reference_model = self._load_reference_model()
        self.layout_model = self._load_layout_model()

=== __init__ ===
ModÃ¼l: alternativeembeddingmodule
SÄ±nÄ±f: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def __init__(self):
        """Alternatif embedding modellerini yÃ¶neten sÄ±nÄ±f."""
        self.embedding_models = {
            "contriever": SentenceTransformer("facebook/contriever"),
            "specter": SentenceTransformer("allenai/specter"),
            "minilm": SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2"),
            "scibert": SentenceTransformer("allenai/scibert_scivocab_uncased"),
            "mpnet": SentenceTransformer("sentence-transformers/all-mpnet-base-v2"),
            "gte": SentenceTransformer("thenlper/gte-base"),
        }
        self.selected_model = self.embedding_models.get(config.EMBEDDING_MODEL, None)

        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
        self.logger = self.setup_logging()

=== __init__ ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def __init__(self):
        """AtÄ±f zinciri analizi ve veri iÅŸleme yÃ¶neticisi."""
        self.logger = self.setup_logging()
        self.chroma_db = ChromaDB()
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

=== __init__ ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def __init__(self):
        """AtÄ±f haritalama iÅŸlemleri iÃ§in sÄ±nÄ±f."""
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, db=4, decode_responses=True)
        self.db_path = config.SQLITE_DB_PATH
        self.logger = self.setup_logging()

=== __init__ ===
ModÃ¼l: clustering_module
SÄ±nÄ±f: ClusteringProcessor
Program: zapata_m6h

    def __init__(self, method="kmeans", num_clusters=5):
        """Embedding tabanlÄ± kÃ¼meleme iÅŸlemleri iÃ§in sÄ±nÄ±f."""
        self.method = method.lower()
        self.num_clusters = num_clusters
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.db_path = config.SQLITE_DB_PATH
        self.logger = self.setup_logging()

=== __init__ ===
ModÃ¼l: configmodule
SÄ±nÄ±f: Config
Program: zapata_m6h

    def __init__(self):
        """KonfigÃ¼rasyon sÄ±nÄ±fÄ±, tÃ¼m sistem ayarlarÄ±nÄ± yÃ¼kler ve yÃ¶netir."""

        # .env dosyasÄ±nÄ± yÃ¼kle
        load_dotenv()

        # ğŸ“Œ Dizin AyarlarÄ±
        self.KAYNAK_DIZIN = Path(os.getenv("KAYNAK_DIZIN", r"C:\Users\mete\Zotero\zotai"))
        self.STORAGE_DIR = Path(os.getenv("STORAGE_DIR", r"C:\Users\mete\Zotero\storage"))
        self.SUCCESS_DIR = Path(os.getenv("SUCCESS_DIR", r"C:\Users\mete\Zotero\zotai"))
        self.HEDEF_DIZIN = Path(self.KAYNAK_DIZIN / "TemizMetin")
        self.TEMIZ_TABLO_DIZIN = Path(self.KAYNAK_DIZIN / "TemizTablo")
        self.TEMIZ_KAYNAKCA_DIZIN = Path(self.KAYNAK_DIZIN / "TemizKaynakca")
        self.PDF_DIR = Path(self.SUCCESS_DIR / "pdfler")
        self.EMBEDDING_PARCA_DIR = Path(self.SUCCESS_DIR / "embedingparca")
        self.CITATIONS_DIR = Path(self.SUCCESS_DIR / "citations")
        self.TABLES_DIR = Path(self.KAYNAK_DIZIN / "TemizTablo")
        self.CHROMA_DB_PATH = Path(os.getenv("CHROMA_DB_PATH", r"C:\Users\mete\Zotero\zotai\chroma_db"))

        # ğŸ“Œ API AyarlarÄ±
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your_openai_api_key")
        self.ZOTERO_API_KEY = os.getenv("ZOTERO_API_KEY", "your_zotero_api_key")
        self.ZOTERO_USER_ID = os.getenv("ZOTERO_USER_ID", "your_zotero_user_id")
        self.ZOTERO_API_URL = f"https://api.zotero.org/users/{self.ZOTERO_USER_ID}/items"

        # ğŸ“Œ PDF Ä°ÅŸleme AyarlarÄ±
        self.PDF_TEXT_EXTRACTION_METHOD = os.getenv("PDF_TEXT_EXTRACTION_METHOD", "pdfplumber").lower()
        self.TABLE_EXTRACTION_METHOD = os.getenv("TABLE_EXTRACTION_METHOD", "pymupdf").lower()
        self.COLUMN_DETECTION = os.getenv("COLUMN_DETECTION", "True").lower() == "true"

        # ğŸ“Œ Embedding & NLP AyarlarÄ±
        self.EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")
        self.CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "256"))
        self.PARAGRAPH_BASED_SPLIT = os.getenv("PARAGRAPH_BASED_SPLIT", "True").lower() == "true"
        self.MULTI_PROCESSING = os.getenv("MULTI_PROCESSING", "True").lower() == "true"
        self.MAX_WORKERS = int(os.getenv("MAX_WORKERS", "4"))

        # ğŸ“Œ Citation Mapping & Analiz AyarlarÄ±
        self.ENABLE_CITATION_MAPPING = os.getenv("ENABLE_CITATION_MAPPING", "True").lower() == "true"
        self.ENABLE_TABLE_EXTRACTION = os.getenv("ENABLE_TABLE_EXTRACTION", "True").lower() == "true"
        self.ENABLE_CLUSTERING = os.getenv("ENABLE_CLUSTERING", "True").lower() == "true"

        # ğŸ“Œ Loglama & Debug AyarlarÄ±
        self.LOG_LEVEL = os.getenv("LOG_LEVEL", "DEBUG")
        self.ENABLE_ERROR_LOGGING = os.getenv("ENABLE_ERROR_LOGGING", "True").lower() == "true"
        self.DEBUG_MODE = os.getenv("DEBUG_MODE", "False").lower() == "true"

        # ğŸ“Œ Ã‡alÄ±ÅŸma Modu SeÃ§imi (GUI veya Konsol)
        self.RUN_MODE = os.getenv("RUN_MODE", os.getenv("runGUI", "gui")).lower()

        # ğŸ“Œ VeritabanÄ± AyarlarÄ± (SQLite & Redis)
        self.USE_SQLITE = os.getenv("USE_SQLITE", "True").lower() == "true"
        self.SQLITE_DB_PATH = Path(self.SUCCESS_DIR / "database.db")
        self.REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
        self.REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))

        # ğŸ“Œ Layout AlgÄ±lama YÃ¶ntemi
        self.LAYOUT_DETECTION_METHOD = os.getenv("LAYOUT_DETECTION_METHOD", "regex").lower()

        # ğŸ“Œ Gerekli dizinleri oluÅŸtur
        self.ensure_directories()

        # ğŸ“Œ Loglama sistemini baÅŸlat
        self.setup_logging()

        # ğŸ“Œ ChromaDB baÄŸlantÄ±sÄ±nÄ± oluÅŸtur
        self.chroma_client = chromadb.PersistentClient(path=str(self.CHROMA_DB_PATH))

        # ğŸ“Œ Redis baÄŸlantÄ±sÄ±nÄ± oluÅŸtur
        self.redis_client = redis.StrictRedis(host=self.REDIS_HOST, port=self.REDIS_PORT, decode_responses=True)

        # ğŸ“Œ SQLite baÄŸlantÄ±sÄ±nÄ± oluÅŸtur
        if self.USE_SQLITE:
            self.sqlite_connection = sqlite3.connect(str(self.SQLITE_DB_PATH))

=== __init__ ===
ModÃ¼l: d3js_visualizer
SÄ±nÄ±f: D3Visualizer
Program: zapata_m6h

    def __init__(self):
        self.html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <script src="https://d3js.org/d3.v7.min.js"></script>
            <style>
                .node circle {
                    fill: steelblue;
                    stroke: white;
                    stroke-width: 2px;
                }
                .node text {
                    font-size: 14px;
                    fill: black;
                }
                .link {
                    fill: none;
                    stroke: #ccc;
                    stroke-width: 2px;
                }
            </style>
        </head>
        <body>
            <svg width="960" height="600"></svg>
            <script>
                var treeData = JSON.parse('%DATA%');

                var margin = {{top: 20, right: 90, bottom: 30, left: 90}},
                    width = 960 - margin.left - margin.right,
                    height = 600 - margin.top - margin.bottom;

                var svg = d3.select("svg")
                    .attr("width", width + margin.left + margin.right)
                    .attr("height", height + margin.top + margin.bottom)
                    .append("g")
                    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

                var treeLayout = d3.tree().size([height, width]);

                var root = d3.hierarchy(treeData);
                treeLayout(root);

                var link = svg.selectAll(".link")
                    .data(root.links())
                    .enter().append("path")
                    .attr("class", "link")
                    .attr("d", d3.linkHorizontal()
                        .x(function(d) { return d.y; })
                        .y(function(d) { return d.x; }));

                var node = svg.selectAll(".node")
                    .data(root.descendants())
                    .enter().append("g")
                    .attr("class", "node")
                    .attr("transform", function(d) { return "translate(" + d.y + "," + d.x + ")"; });

                node.append("circle")
                    .attr("r", 10);

                node.append("text")
                    .attr("dy", ".35em")
                    .attr("x", function(d) { return d.children ? -13 : 13; })
                    .style("text-anchor", function(d) { return d.children ? "end" : "start"; })
                    .text(function(d) { return d.data.name; });
            </script>
        </body>
        </html>
        """

=== __init__ ===
ModÃ¼l: veri_gorsellestirme
SÄ±nÄ±f: DataVisualizer
Program: zapata_m6h

    def __init__(self):
        """AtÄ±f aÄŸÄ± ve veri gÃ¶rselleÅŸtirme yÃ¶neticisi."""
        self.logger = self.setup_logging()
        self.connection = self.create_db_connection()

=== __init__ ===
ModÃ¼l: document_parser
SÄ±nÄ±f: DocumentParser
Program: zapata_m6h

    def __init__(self):
        """DÃ¶kÃ¼man analiz modÃ¼lÃ¼nÃ¼ baÅŸlatÄ±r"""
        self.logger = self.setup_logging()
        self.queue = RedisQueue()
        self.db = SQLiteStorage()
        self.layout_analyzer = LayoutAnalyzer()
        self.scientific_mapper = ScientificMapper()

=== __init__ ===
ModÃ¼l: embeddingmodule
SÄ±nÄ±f: EmbeddingProcessor
Program: zapata_m6h

    def __init__(self):
        """Embedding iÅŸlemleri iÃ§in sÄ±nÄ±f. OpenAI veya alternatif embedding modellerini kullanÄ±r."""
        self.embedding_model = config.EMBEDDING_MODEL
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
        self.logger = self.setup_logging()

=== __init__ ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def __init__(self):
        """
        Hata loglama sistemini baÅŸlatÄ±r.
        """
        self.log_dir = config.LOG_DIR
        self.sqlite_db_path = config.SQLITE_DB_PATH
        self.log_file = os.path.join(self.log_dir, "error_logs.txt")
        self.json_log_file = os.path.join(self.log_dir, "error_logs.json")

        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)

        logging.basicConfig(
            filename=self.log_file,
            level=logging.ERROR,
            format="%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        self.init_sqlite_log_table()

=== __init__ ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def __init__(self, dimension=768):
        """FAISS Entegrasyonu"""
        self.logger = self.setup_logging()
        self.dimension = dimension  # VektÃ¶r boyutu
        self.index = faiss.IndexFlatL2(self.dimension)  # L2 mesafesiyle FAISS indeksi
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

=== __init__ ===
ModÃ¼l: fetch_top_k_results
SÄ±nÄ±f: FetchTopKResults
Program: zapata_m6h

    def __init__(self, top_k=5):
        """En iyi K sonucu getirme modÃ¼lÃ¼ baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.search_engine = MultiSourceSearch()
        self.reranker = Reranker()
        self.top_k = top_k
        self.error_log_file = "error_logs.json"

=== __init__ ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def __init__(self, model_name):
        """Fine-Tuning iÅŸlemlerini yÃ¶neten sÄ±nÄ±f"""
        self.model_name = model_name
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name.replace("/", "_"))

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)

=== __init__ ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def __init__(self, model_name):
        self.model_name = AVAILABLE_MODELS[model_name]
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR

=== __init__ ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuningDataset
Program: zapata_m6h

    def __init__(self, model_name):
        """Fine-Tuning iÅŸlemlerini yÃ¶neten sÄ±nÄ±f"""
        self.model_name = model_name
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name.replace("/", "_"))

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)

=== __init__ ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningDataset
Program: zapata_m6h

    def __init__(self, model_name):
        self.model_name = AVAILABLE_MODELS[model_name]
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR

=== __init__ ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningManager
Program: zapata_m6h

    def __init__(self, model_name):
        self.model_name = AVAILABLE_MODELS[model_name]
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR

=== __init__ ===
ModÃ¼l: helpermodule
SÄ±nÄ±f: HelperFunctions
Program: zapata_m6h

    def __init__(self):
        """YardÄ±mcÄ± fonksiyonlar sÄ±nÄ±fÄ±."""
        self.logger = self.setup_logging()
        self.turkish_stopwords = set(stopwords.words("turkish"))
        self.english_stopwords = set(stopwords.words("english"))

=== __init__ ===
ModÃ¼l: layout_analysis
SÄ±nÄ±f: LayoutAnalyzer
Program: zapata_m6h

    def __init__(self):
        """YapÄ±sal analiz yÃ¶neticisi"""
        self.logger = self.setup_logging()
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

        # YapÄ±sal Ã¶ÄŸeleri belirlemek iÃ§in regex desenleri
        self.layout_patterns = {
            "BaÅŸlÄ±k": r"^\s*[A-ZÃ‡ÄÄ°Ã–ÅÃœ].+\s*$",
            "Alt BaÅŸlÄ±k": r"^\s*[A-ZÃ‡ÄÄ°Ã–ÅÃœ].+\s*$",
            "Tablo": r"^\s*Tablo\s+\d+",
            "Åekil": r"^\s*Åekil\s+\d+",
            "Sayfa No": r"\bSayfa\s+\d+\b",
        }

=== __init__ ===
ModÃ¼l: guimindmap
SÄ±nÄ±f: MindMapGUI
Program: zapata_m6h

    def __init__(self, master):
        self.master = master
        self.master.title("Zotero & Zapata Zihin HaritasÄ±")
        self.create_widgets()
        self.server = None

=== __init__ ===
ModÃ¼l: Mind_Map_Visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def __init__(self, root):
        self.root = root
        self.root.title("Zihin HaritasÄ± - Zapata M6H")
        self.create_ui()

=== __init__ ===
ModÃ¼l: mindmap_visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def __init__(self):
        """Zotero ile baÄŸlantÄ±yÄ± kurar ve gÃ¶rselleÅŸtirme iÃ§in gerekli dizinleri oluÅŸturur."""
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.library_type = "user"
        self.zot = zotero.Zotero(self.user_id, self.library_type, self.api_key)
        self.output_folder = config.MINDMAP_OUTPUT_FOLDER  # GÃ¶rsellerin kaydedileceÄŸi klasÃ¶r

        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)

=== __init__ ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def __init__(self):
        """Ã‡oklu kaynaklÄ± arama motoru baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.sqlite = SQLiteStorage()
        self.redis = RedisQueue()
        self.chroma_client = PersistentClient(path=config.CHROMA_DB_PATH)
        self.faiss_index = self.load_faiss_index()
        self.query_expander = QueryExpansion()
        self.reranker = Reranker()
        self.retrieve_engine = RetrieveEngine()

=== __init__ ===
ModÃ¼l: pdfprocessing
SÄ±nÄ±f: PDFProcessor
Program: zapata_m6h

    def __init__(self):
        """PDF iÅŸleme sÄ±nÄ±fÄ±, yapÄ±landÄ±rma ayarlarÄ±nÄ± yÃ¼kler ve log sistemini baÅŸlatÄ±r."""
        self.text_extraction_method = config.PDF_TEXT_EXTRACTION_METHOD
        self.table_extraction_method = config.TABLE_EXTRACTION_METHOD
        self.logger = self.setup_logging()

=== __init__ ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def __init__(self):
        """
        Ä°ÅŸlem yÃ¶neticisi, Redis ve multiprocessing/threading desteÄŸi ile iÅŸlem yÃ¶netimini saÄŸlar.
        """
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.max_workers = config.MAX_WORKERS  # .env'den max iÅŸÃ§i sayÄ±sÄ±nÄ± al
        self.task_queue = multiprocessing.Queue()  # Yerel iÅŸlem kuyruÄŸu
        self.log_file = "process_manager.log"

        logging.basicConfig(
            filename=self.log_file,
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

=== __init__ ===
ModÃ¼l: query_expansion
SÄ±nÄ±f: QueryExpansion
Program: zapata_m6h

    def __init__(self):
        """Sorgu geniÅŸletme modÃ¼lÃ¼ baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()

=== __init__ ===
ModÃ¼l: rag_pipeline
SÄ±nÄ±f: RAGPipeline
Program: zapata_m6h

    def __init__(self):
        """RAG Pipeline baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()

=== __init__ ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def __init__(self):
        """Redis Ã¶nbellek yÃ¶netimi iÃ§in sÄ±nÄ±f."""
        self.logger = self.setup_logging()
        try:
            # decode_responses=False ile pickle iÃ§in binary mod, True ile JSON iÃ§in string mod
            self.client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
            self.redis_client_str = redis.StrictRedis(
                host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True
            )
            self.logger.info("âœ… Redis baÄŸlantÄ±sÄ± kuruldu.")
        except Exception as e:
            self.logger.error(f"âŒ Redis baÄŸlantÄ± hatasÄ±: {e}")

=== __init__ ===
ModÃ¼l: redisqueue
SÄ±nÄ±f: RedisQueue
Program: zapata_m6h

    def __init__(self, queue_name="task_queue", retry_limit=3):
        """Redis kuyruÄŸu yÃ¶neticisi."""
        self.logger = self.setup_logging()
        try:
            self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
            self.queue_name = queue_name
            self.retry_limit = retry_limit
            self.logger.info(f"âœ… Redis kuyruÄŸu ({queue_name}) baÅŸlatÄ±ldÄ±.")
        except Exception as e:
            self.logger.error(f"âŒ Redis kuyruÄŸu baÅŸlatÄ±lamadÄ±: {e}")

=== __init__ ===
ModÃ¼l: reranking_module
SÄ±nÄ±f: RerankingModule
Program: zapata_m6h

    def __init__(self):
        """Reranking modÃ¼lÃ¼ baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.faiss = FAISSIntegration()
        self.retriever = RetrieverIntegration()

=== __init__ ===
ModÃ¼l: retrieval_reranker
SÄ±nÄ±f: RetrievalReranker
Program: zapata_m6h

    def __init__(self, model_name="cross-encoder/ms-marco-MiniLM-L-6-v2"):
        """Reranking modÃ¼lÃ¼ baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()
        self.rag_pipeline = RAGPipeline()

        self.model = CrossEncoder(model_name)  # EÄŸitimli Cross-Encoder modeli yÃ¼kleniyor

=== __init__ ===
ModÃ¼l: retriever_integration
SÄ±nÄ±f: RetrieverIntegration
Program: zapata_m6h

    def __init__(self):
        """Retrieve entegrasyonu yÃ¶neticisi"""
        self.logger = self.setup_logging()
        self.retrieve_api_url = config.RETRIEVE_API_URL

=== __init__ ===
ModÃ¼l: robustembeddingmodule
SÄ±nÄ±f: RobustEmbeddingProcessor
Program: zapata_m6h

    def __init__(self):
        """Hata toleranslÄ± embedding iÅŸlemleri iÃ§in sÄ±nÄ±f."""
        self.embedding_models = {
            "openai": "text-embedding-ada-002",
            "contriever": "facebook/contriever",
            "specter": "allenai/specter",
            "minilm": "sentence-transformers/all-MiniLM-L6-v2",
            "scibert": "allenai/scibert_scivocab_uncased",
            "mpnet": "sentence-transformers/all-mpnet-base-v2",
            "gte": "thenlper/gte-base",
        }

        self.selected_model = config.EMBEDDING_MODEL.lower()
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
        self.logger = self.setup_logging()

        if self.selected_model != "openai":
            self.model = SentenceTransformer(
                self.embedding_models.get(self.selected_model, "sentence-transformers/all-MiniLM-L6-v2")
            )

=== __init__ ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def __init__(self, db_path=None):
        """SQLite veritabanÄ± baÄŸlantÄ±sÄ±nÄ± yÃ¶netir."""
        self.logger = self.setup_logging()
        self.db_path = db_path if db_path else config.SQLITE_DB_PATH
        self.connection = self.create_connection()
        self.create_tables()

=== __init__ ===
ModÃ¼l: scientific_mapping
SÄ±nÄ±f: ScientificMapper
Program: zapata_m6h

    def __init__(self):
        """Bilimsel makale haritalama yÃ¶neticisi."""
        self.logger = self.setup_logging()
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

        # BÃ¶lÃ¼m baÅŸlÄ±klarÄ± tespiti iÃ§in regex desenleri
        self.section_patterns = {
            "Ã–zet": r"\b(?:Ã–zet|Abstract)\b",
            "GiriÅŸ": r"\b(?:GiriÅŸ|Introduction)\b",
            "YÃ¶ntem": r"\b(?:Metodoloji|YÃ¶ntemler|Methods)\b",
            "Bulgular": r"\b(?:Bulgular|Results)\b",
            "TartÄ±ÅŸma": r"\b(?:TartÄ±ÅŸma|Discussion)\b",
            "SonuÃ§": r"\b(?:SonuÃ§|Conclusion)\b",
            "KaynakÃ§a": r"\b(?:KaynakÃ§a|References|Bibliography)\b",
        }

=== __init__ ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def __init__(self):
        """Arama motoru baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.sqlite = SQLiteStorage()
        self.redis = RedisQueue()
        self.chroma_client = PersistentClient(path="chroma_db")
        self.faiss_index = self.load_faiss_index()
        self.query_expander = QueryExpansion()

=== __init__ ===
ModÃ¼l: sync_faiss_chromadb
SÄ±nÄ±f: SyncFAISSChromaDB
Program: zapata_m6h

    def __init__(self):
        """FAISS & ChromaDB senkronizasyon modÃ¼lÃ¼ baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.chroma_client = PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis = RedisQueue()
        self.faiss_index = self.load_faiss_index()
        self.chroma_collection = self.chroma_client.get_collection("embeddings")

=== __init__ ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def __init__(self):
        self.stop_words = set(stopwords.words("english")) | set(
            stopwords.words("turkish")
        )  # TÃ¼rkÃ§e ve Ä°ngilizce stop-word listesi
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH

=== __init__ ===
ModÃ¼l: training_monitor
SÄ±nÄ±f: TrainingMonitor
Program: zapata_m6h

    def __init__(self, root):
        """EÄŸitim monitÃ¶rÃ¼nÃ¼ baÅŸlatÄ±r."""
        self.root = root
        self.root.title("EÄŸitim MonitÃ¶rÃ¼")
        self.root.geometry("500x300")

        self.setup_logging()
        self.create_widgets()

=== __init__ ===
ModÃ¼l: guimodule
SÄ±nÄ±f: ZapataGUI
Program: zapata_m6h

    def __init__(self, root):
        """GUI baÅŸlatma iÅŸlemi"""
        self.root = root
        self.root.title("Zapata M6H - Bilimsel Arama ve Ä°ÅŸleme Sistemi")
        self.root.geometry("800x600")

        self.setup_logging()
        self.create_widgets()

=== __init__ ===
ModÃ¼l: main
SÄ±nÄ±f: ZapataM6H
Program: zapata_m6h

    def __init__(self):
        """Ana programÄ±n baÅŸlatÄ±lmasÄ± ve ayarlanmasÄ±"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()
        self.rag_pipeline = RAGPipeline()
        self.reranker = RerankingModule()

=== __init__ ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def __init__(self):
        """Zotero ile baÄŸlantÄ±yÄ± kurar."""
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.library_type = "user"
        self.zot = zotero.Zotero(self.user_id, self.library_type, self.api_key)
        self.zapata_api_url = config.ZAPATA_REST_API_URL  # Zapata Rest API ile iletiÅŸim
        self.output_folder = config.ZOTERO_OUTPUT_FOLDER  # Zapata'ya gÃ¶nderilecek dosyalar iÃ§in dizin

        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)

=== __init__ ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def __init__(self):
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.api_url = config.ZOTERO_API_URL
        self.headers = {"Authorization": f"Bearer {self.api_key}"}

        # Redis baÄŸlantÄ±sÄ±
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)

        # SQLite baÄŸlantÄ±sÄ±
        self.sqlite_db = config.SQLITE_DB_PATH
        self.ensure_tables()

=== __init__ ===
ModÃ¼l: zoteromodule
SÄ±nÄ±f: ZoteroManager
Program: zapata_m6h

    def __init__(self):
        """Zotero API ile veri Ã§ekmek ve PDF indirmek iÃ§in yÃ¶netici sÄ±nÄ±fÄ±."""
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.api_url = config.ZOTERO_API_URL
        self.logger = self.setup_logging()

=== __len__ ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuningDataset
Program: zapata_m6h

    def __len__(self):
        return len(self.texts)

=== __len__ ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningDataset
Program: zapata_m6h

    def __len__(self):
        return len(self.texts)

=== _classify_block ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def _classify_block(self, block):
        """Blok sÄ±nÄ±flandÄ±rma"""
        block_type_map = {
            "Title": "title",
            "Text": "text",
            "Figure": "figure",
            "Table": "table",
            "Header": "header",
            "Footer": "footer",
        }

        return block_type_map.get(block.type, "text")

=== _extract_references_by_section ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def _extract_references_by_section(self, text):
        """BÃ¶lÃ¼m bazlÄ± referans Ã§Ä±karma"""
        sections = ["References", "Bibliography", "Works Cited"]
        references = []

        for section in sections:
            section_match = re.search(f"{section}(.*?)(\n\n|\Z)", text, re.IGNORECASE | re.DOTALL)
            if section_match:
                section_text = section_match.group(1)
                references.extend(re.findall(r"\[(\d+)\]\s*(.+?)(?=\[|\n\n|$)", section_text, re.DOTALL))

        return references

=== _load_layout_model ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def _load_layout_model(self):
        """Layout tespiti iÃ§in model"""
        return lp.Detectron2LayoutModel("lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config")

=== _load_reference_model ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def _load_reference_model(self):
        """Referans Ã§Ä±karma iÃ§in ML modeli"""
        return pipeline("token-classification", model="dslim/bert-base-NER")

=== add_embedding ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def add_embedding(self, doc_id, embedding):
        """Embedding verisini FAISS'e ekler."""
        try:
            embedding = np.array(embedding, dtype=np.float32).reshape(1, -1)
            self.index.add(embedding)

            # Redis'e Ã¶nbelleÄŸe kaydet
            self.redis_cache.cache_embedding(doc_id, embedding.tolist())

            # SQLite'e kaydet
            self.store_embedding_to_db(doc_id, embedding.tolist())

            self.logger.info(f"âœ… {doc_id} iÃ§in embedding FAISS'e eklendi.")
        except Exception as e:
            self.logger.error(f"âŒ FAISS embedding ekleme hatasÄ±: {e}")

=== cache_embedding ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def cache_embedding(self, doc_id, embedding, ttl=86400):
        """Embedding verisini Redisâ€™e kaydeder (JSON ile)."""
        try:
            key = f"embedding:{doc_id}"
            self.redis_client_str.setex(key, ttl, json.dumps(embedding))
            self.logger.info(f"âœ… Embedding verisi Redisâ€™e kaydedildi: {key}")
        except Exception as e:
            self.logger.error(f"âŒ Embedding kaydetme hatasÄ±: {e}")

=== cache_map_data ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def cache_map_data(self, doc_id, map_type, map_data, ttl=86400):
        """YapÄ±sal ve bilimsel haritalama verilerini Redisâ€™e kaydeder."""
        try:
            key = f"{map_type}_map:{doc_id}"
            self.redis_client_str.setex(key, ttl, json.dumps(map_data))
            self.logger.info(f"âœ… {map_type} haritasÄ± Redisâ€™e kaydedildi: {key}")
        except Exception as e:
            self.logger.error(f"âŒ {map_type} haritasÄ± kaydetme hatasÄ±: {e}")

=== cache_mindmap_data ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def cache_mindmap_data(self, key, mindmap_json, ttl=None):
        """Zihin haritasÄ± verisini Redisâ€™te saklar."""
        try:
            serialized = json.dumps(mindmap_json)
            if ttl:
                self.redis_client_str.setex(key, ttl, serialized)
            else:
                self.redis_client_str.set(key, serialized)
            self.logger.info(f"âœ… {key} iÃ§in zihin haritasÄ± verisi Redisâ€™e kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ Zihin haritasÄ± kaydetme hatasÄ±: {e}")

=== cache_references_to_redis ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def cache_references_to_redis(self, references):
        """KaynakÃ§a verilerini Redis Ã¶nbelleÄŸine kaydeder."""
        for ref in references:
            item_id = ref["key"]
            ref_data = json.dumps(ref["data"])
            self.redis_client.set(f"reference:{item_id}", ref_data)
        print("âœ… KaynakÃ§alar Redisâ€™e kaydedildi.")

=== clean_text ===
ModÃ¼l: helpermodule
SÄ±nÄ±f: HelperFunctions
Program: zapata_m6h

    def clean_text(self, text, remove_stopwords=True, language="turkish"):
        """Metni temizler, durdurma kelimelerini kaldÄ±rÄ±r, gereksiz boÅŸluklarÄ± temizler."""
        self.logger.info("ğŸ“ Metin temizleme iÅŸlemi baÅŸlatÄ±ldÄ±...")

        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()

        # Ã–zel karakterleri kaldÄ±r
        text = re.sub(r"[^\w\s]", "", text)

        # Fazla boÅŸluklarÄ± temizle
        text = re.sub(r"\s+", " ", text).strip()

        # Stopword temizleme
        if remove_stopwords:
            stopwords_list = self.turkish_stopwords if language == "turkish" else self.english_stopwords
            text = " ".join([word for word in text.split() if word not in stopwords_list])

        self.logger.info("âœ… Metin temizleme iÅŸlemi tamamlandÄ±.")
        return text

=== clean_text ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def clean_text(self, text):
        """Metni temizler: Ã¶zel karakterleri kaldÄ±rÄ±r, kÃ¼Ã§Ã¼k harfe Ã§evirir, fazla boÅŸluklarÄ± siler."""
        text = text.lower()
        text = re.sub(r"\s+", " ", text)  # Fazla boÅŸluklarÄ± sil
        text = re.sub(r"[^\w\s]", "", text)  # Noktalama iÅŸaretlerini kaldÄ±r
        return text.strip()

=== clear_cache ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def clear_cache(self):
        """Redisâ€™te saklanan tÃ¼m verileri temizler."""
        try:
            self.client.flushdb()
            self.logger.info("ğŸ—‘ï¸ Redis Ã¶nbelleÄŸi temizlendi.")
        except Exception as e:
            self.logger.error(f"âŒ Ã–nbellek temizleme hatasÄ±: {e}")

=== cluster_documents ===
ModÃ¼l: clustering_module
SÄ±nÄ±f: ClusteringProcessor
Program: zapata_m6h

    def cluster_documents(self, embeddings):
        """Belirtilen algoritmaya gÃ¶re kÃ¼meleme yapar."""
        self.logger.info(f"ğŸ” {self.method.upper()} yÃ¶ntemi ile kÃ¼meleme iÅŸlemi baÅŸlatÄ±ldÄ±...")

        if self.method == "kmeans":
            model = KMeans(n_clusters=self.num_clusters, random_state=42)
        elif self.method == "dbscan":
            model = DBSCAN(eps=0.5, min_samples=5)
        elif self.method == "hac":
            model = AgglomerativeClustering(n_clusters=self.num_clusters)
        else:
            self.logger.error("âŒ GeÃ§ersiz kÃ¼meleme yÃ¶ntemi!")
            return None

        cluster_labels = model.fit_predict(embeddings)
        self.logger.info(f"âœ… KÃ¼meleme tamamlandÄ±. {len(set(cluster_labels))} kÃ¼me oluÅŸturuldu.")
        return cluster_labels

=== create_connection ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def create_connection(self):
        """VeritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸturur."""
        try:
            conn = sqlite3.connect(self.db_path)
            self.logger.info(f"âœ… SQLite baÄŸlantÄ±sÄ± kuruldu: {self.db_path}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite baÄŸlantÄ± hatasÄ±: {e}")
            return None

=== create_db_connection ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"âœ… SQLite baÄŸlantÄ±sÄ± kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite baÄŸlantÄ± hatasÄ±: {e}")
            return None

=== create_db_connection ===
ModÃ¼l: veri_gorsellestirme
SÄ±nÄ±f: DataVisualizer
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"âœ… SQLite baÄŸlantÄ±sÄ± kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite baÄŸlantÄ± hatasÄ±: {e}")
            return None

=== create_db_connection ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"âœ… SQLite baÄŸlantÄ±sÄ± kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite baÄŸlantÄ± hatasÄ±: {e}")
            return None

=== create_db_connection ===
ModÃ¼l: layout_analysis
SÄ±nÄ±f: LayoutAnalyzer
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"âœ… SQLite baÄŸlantÄ±sÄ± kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite baÄŸlantÄ± hatasÄ±: {e}")
            return None

=== create_db_connection ===
ModÃ¼l: scientific_mapping
SÄ±nÄ±f: ScientificMapper
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanÄ± baÄŸlantÄ±sÄ±nÄ± oluÅŸturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"âœ… SQLite baÄŸlantÄ±sÄ± kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite baÄŸlantÄ± hatasÄ±: {e}")
            return None

=== create_tables ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def create_tables(self):
        """Gerekli tablolarÄ± oluÅŸturur."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS documents (
                    id TEXT PRIMARY KEY,
                    title TEXT,
                    authors TEXT,
                    abstract TEXT,
                    content TEXT,
                    metadata TEXT
                )
            """
            )
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS embeddings (
                    doc_id TEXT PRIMARY KEY,
                    embedding TEXT,
                    FOREIGN KEY(doc_id) REFERENCES documents(id)
                )
            """
            )
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS citations (
                    doc_id TEXT,
                    citation TEXT,
                    FOREIGN KEY(doc_id) REFERENCES documents(id)
                )
            """
            )
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS scientific_maps (
                    doc_id TEXT PRIMARY KEY,
                    map_data TEXT,
                    FOREIGN KEY(doc_id) REFERENCES documents(id)
                )
            """
            )
            self.connection.commit()
            self.logger.info("âœ… SQLite tablolarÄ± oluÅŸturuldu veya zaten mevcut.")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ Tablolar oluÅŸturulurken hata oluÅŸtu: {e}")

=== create_ui ===
ModÃ¼l: Mind_Map_Visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def create_ui(self):
        """
        KullanÄ±cÄ± arayÃ¼zÃ¼nÃ¼ oluÅŸturur.
        """
        self.tree_frame = ttk.Frame(self.root)
        self.tree_frame.pack(fill="both", expand=True)

        self.load_button = ttk.Button(self.root, text="HaritayÄ± YÃ¼kle", command=self.load_mind_map)
        self.load_button.pack()

=== create_widgets ===
ModÃ¼l: guimindmap
SÄ±nÄ±f: MindMapGUI
Program: zapata_m6h

    def create_widgets(self):
        """GUI bileÅŸenlerini oluÅŸturur."""
        self.label = ttk.Label(self.master, text="Zihin HaritasÄ± GÃ¶rselleÅŸtirme", font=("Arial", 14))
        self.label.pack(pady=10)

        self.load_button = ttk.Button(self.master, text="Veri YÃ¼kle", command=self.load_mindmap_data)
        self.load_button.pack(pady=5)

        self.open_map_button = ttk.Button(self.master, text="HaritayÄ± GÃ¶rÃ¼ntÃ¼le", command=self.open_mindmap)
        self.open_map_button.pack(pady=5)

=== create_widgets ===
ModÃ¼l: training_monitor
SÄ±nÄ±f: TrainingMonitor
Program: zapata_m6h

    def create_widgets(self):
        """GUI Ã¶ÄŸelerini oluÅŸturur."""
        self.progress_label = ctk.CTkLabel(self.root, text="EÄŸitim Durumu:")
        self.progress_label.pack(pady=10)

        self.progress_bar = ctk.CTkProgressBar(self.root, width=400)
        self.progress_bar.set(0)
        self.progress_bar.pack(pady=10)

        self.status_label = ctk.CTkLabel(self.root, text="Bekleniyor...")
        self.status_label.pack(pady=5)

        self.start_button = ctk.CTkButton(self.root, text="EÄŸitimi BaÅŸlat", command=self.start_training)
        self.start_button.pack(pady=10)

=== create_widgets ===
ModÃ¼l: guimodule
SÄ±nÄ±f: ZapataGUI
Program: zapata_m6h

    def create_widgets(self):
        """GUI Ã¶ÄŸelerini oluÅŸturur."""
        self.query_label = ctk.CTkLabel(self.root, text="Sorgu Girin:")
        self.query_label.pack(pady=5)

        self.query_entry = ctk.CTkEntry(self.root, width=400)
        self.query_entry.pack(pady=5)

        self.search_button = ctk.CTkButton(self.root, text="Arama Yap", command=self.run_search)
        self.search_button.pack(pady=10)

        self.result_text = ctk.CTkTextbox(self.root, width=600, height=300)
        self.result_text.pack(pady=10)

=== delete_cache ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def delete_cache(self, doc_id, data_type):
        """Redisâ€™teki belirli bir veriyi siler."""
        try:
            key = f"{data_type}:{doc_id}"
            self.redis_client_str.delete(key)
            self.logger.info(f"âœ… Redisâ€™ten veri silindi: {key}")
        except Exception as e:
            self.logger.error(f"âŒ Redis verisi silme hatasÄ±: {e}")

=== dequeue_task ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def dequeue_task(self):
        """
        Kuyruktan bir gÃ¶revi Ã§eker.
        """
        try:
            task_data = self.redis_client.rpop("task_queue")
            if task_data:
                logging.info(f"ğŸ”„ GÃ¶rev iÅŸlenmek Ã¼zere alÄ±ndÄ±: {task_data}")
            return task_data
        except Exception as e:
            logging.error(f"âŒ GÃ¶rev Ã§ekme hatasÄ±: {e}")
            return None

=== dequeue_task ===
ModÃ¼l: redisqueue
SÄ±nÄ±f: RedisQueue
Program: zapata_m6h

    def dequeue_task(self):
        """Kuyruktan bir gÃ¶revi Ã§eker ve JSON olarak dÃ¶ndÃ¼rÃ¼r."""
        try:
            task_json = self.redis_client.lpop(self.queue_name)
            if task_json:
                task_data = json.loads(task_json)
                self.logger.info(f"ğŸ“Œ GÃ¶rev alÄ±ndÄ±: {task_data}")
                return task_data
            else:
                self.logger.info("âš ï¸ Kuyruk boÅŸ.")
                return None
        except Exception as e:
            self.logger.error(f"âŒ GÃ¶rev alÄ±nÄ±rken hata oluÅŸtu: {e}")
            return None

=== detect_layout ===
ModÃ¼l: pdfprocessing
SÄ±nÄ±f: PDFProcessor
Program: zapata_m6h

    def detect_layout(self, pdf_path):
        """PDF'in sayfa yapÄ±sÄ±nÄ± analiz eder (baÅŸlÄ±klar, paragraflar, sÃ¼tunlar)."""
        self.logger.info(f"ğŸ“‘ PDF sayfa dÃ¼zeni analiz ediliyor: {pdf_path}")
        # TODO: Layout analiz iÃ§in PyMuPDF, LayoutParser veya Detectron2 entegrasyonu dÃ¼ÅŸÃ¼nÃ¼lebilir.
        return {"layout": "analyzed"}

=== detect_page_layout ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def detect_page_layout(self, pdf_path):
        """GeliÅŸmiÅŸ sayfa dÃ¼zeni tespiti"""
        doc = fitz.open(pdf_path)
        layouts = []

        # Layout Parser
        model = lp.Detectron2LayoutModel("lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config")

        for page_num, page in enumerate(doc):
            # Sayfa gÃ¶rÃ¼ntÃ¼sÃ¼
            pix = page.get_pixmap()
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

            # Layout tespiti
            detected_layout = model.detect(img)

            page_layout = {
                "page_number": page_num + 1,
                "elements": {
                    "text_blocks": [],
                    "titles": [],
                    "figures": [],
                    "tables": [],
                    "headers": [],
                    "footers": [],
                },
            }

            for block in detected_layout:
                block_type = self._classify_block(block)
                page_layout["elements"][f"{block_type}s"].append(block)

            layouts.append(page_layout)

        return layouts

=== download_pdf_from_doi ===
ModÃ¼l: zoteromodule
SÄ±nÄ±f: ZoteroManager
Program: zapata_m6h

    def download_pdf_from_doi(self, doi, save_path):
        """DOI kullanarak Sci-Hub Ã¼zerinden PDF indirir."""
        self.logger.info(f"ğŸ“¥ DOI ile PDF indiriliyor: {doi}")
        sci_hub_url = f"https://sci-hub.se/{doi}"

        try:
            response = requests.get(sci_hub_url, stream=True)
            if response.status_code == 200:
                with open(save_path, "wb") as pdf_file:
                    for chunk in response.iter_content(chunk_size=1024):
                        pdf_file.write(chunk)
                self.logger.info(f"âœ… PDF baÅŸarÄ±yla indirildi: {save_path}")
                return True
            else:
                self.logger.error(f"âŒ Sci-Hub Ã¼zerinden PDF indirilemedi: {response.status_code}")
                return False
        except Exception as e:
            self.logger.error(f"âŒ DOI ile PDF indirme hatasÄ±: {e}")
            return False

=== encode_queries ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def encode_queries(self, queries):
        """SorgularÄ± FAISS iÃ§in vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer("all-MiniLM-L6-v2")
        return model.encode(queries)

=== encode_queries ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def encode_queries(self, queries):
        """SorgularÄ± FAISS iÃ§in vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer("all-MiniLM-L6-v2")
        return model.encode(queries)

=== enqueue_task ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def enqueue_task(self, task_data):
        """
        GÃ¶revleri Redis kuyruÄŸuna ekler.
        """
        try:
            self.redis_client.lpush("task_queue", task_data)
            logging.info(f"âœ… GÃ¶rev kuyruÄŸa eklendi: {task_data}")
        except Exception as e:
            logging.error(f"âŒ GÃ¶rev ekleme hatasÄ±: {e}")

=== enqueue_task ===
ModÃ¼l: redisqueue
SÄ±nÄ±f: RedisQueue
Program: zapata_m6h

    def enqueue_task(self, task_data):
        """GÃ¶revi Redis kuyruÄŸuna ekler."""
        try:
            task_data["retry_count"] = 0  # BaÅŸlangÄ±Ã§ta sÄ±fÄ±r deneme
            self.redis_client.rpush(self.queue_name, json.dumps(task_data))
            self.logger.info(f"âœ… GÃ¶rev kuyruÄŸa eklendi: {task_data}")
        except Exception as e:
            self.logger.error(f"âŒ GÃ¶rev kuyruÄŸa eklenemedi: {e}")

=== ensure_directories ===
ModÃ¼l: configmodule
SÄ±nÄ±f: Config
Program: zapata_m6h

    def ensure_directories(self):
        """Gerekli dizinleri oluÅŸturur."""
        directories = [
            self.PDF_DIR,
            self.EMBEDDING_PARCA_DIR,
            self.HEDEF_DIZIN,
            self.TEMIZ_TABLO_DIZIN,
            self.TEMIZ_KAYNAKCA_DIZIN,
            self.CITATIONS_DIR,
            self.TABLES_DIR,
        ]
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)

=== ensure_tables ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def ensure_tables(self):
        """SQLite iÃ§inde kaynakÃ§a verilerini saklamak iÃ§in gerekli tablolarÄ± oluÅŸturur."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS references (
                id TEXT PRIMARY KEY,
                title TEXT,
                authors TEXT,
                year TEXT,
                journal TEXT,
                doi TEXT,
                file_path TEXT
            )
        """
        )
        conn.commit()
        conn.close()

=== evaluate_model ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningManager
Program: zapata_m6h

    def evaluate_model(self):
        """EÄŸitilmiÅŸ modelin test seti Ã¼zerindeki performansÄ±nÄ± deÄŸerlendirir."""
        dataset = self.load_dataset()
        trainer = Trainer(model=self.model, tokenizer=self.tokenizer)
        results = trainer.evaluate(eval_dataset=dataset["test"])
        return results

=== expand_query ===
ModÃ¼l: query_expansion
SÄ±nÄ±f: QueryExpansion
Program: zapata_m6h

    def expand_query(self, query, method="synonyms", max_expansions=5):
        """
        Sorguyu geniÅŸletir.
        - method: "synonyms" (EÅŸ anlamlÄ± kelimeler), "stems" (KÃ¶k kelime), "combined" (Her ikisi)
        - max_expansions: Eklenen kelime sayÄ±sÄ±
        """
        expanded_query = set()
        query_words = query.lower().split()

        try:
            if method in ["synonyms", "combined"]:
                for word in query_words:
                    synonyms = self.get_synonyms(word, max_expansions)
                    expanded_query.update(synonyms)

            if method in ["stems", "combined"]:
                stemmed_words = self.get_stems(query_words)
                expanded_query.update(stemmed_words)

            final_query = list(expanded_query)
            self.logger.info(f"âœ… GeniÅŸletilmiÅŸ sorgu: {final_query}")
            return final_query

        except Exception as e:
            self.logger.error(f"âŒ Sorgu geniÅŸletme hatasÄ±: {e}")
            return query_words  # Hata durumunda orijinal sorguyu dÃ¶ndÃ¼r

=== export_graph_json ===
ModÃ¼l: mindmap_visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def export_graph_json(self):
        """
        Zotero atÄ±f aÄŸÄ±nÄ± D3.js uyumlu bir JSON formatÄ±nda dÄ±ÅŸa aktarÄ±r.
        """
        graph = self.extract_citation_network()
        nodes = [{"id": node, "label": data["label"]} for node, data in graph.nodes(data=True)]
        links = [{"source": u, "target": v} for u, v in graph.edges()]

        graph_data = {"nodes": nodes, "links": links}
        output_path = os.path.join(self.output_folder, "citation_network.json")

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(graph_data, f, indent=4)

        print(f"âœ… Zihin haritasÄ± JSON olarak kaydedildi: {output_path}")

=== export_references ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def export_references(self, format="ris"):
        """KaynakÃ§alarÄ± farklÄ± formatlarda dÄ±ÅŸa aktarÄ±r (RIS, BibTeX, CSV, Pajek, VOSviewer)."""
        references = self.load_cached_references()
        export_path = os.path.join(config.TEMIZ_KAYNAKCA_DIZIN, f"references.{format}")

        if format == "ris":
            with open(export_path, "w", encoding="utf-8") as f:
                for ref in references:
                    f.write(
                        f"TY  - JOUR\nTI  - {ref.get('title', '')}\nAU  - {ref.get('authors', '')}\nPY  - {ref.get('year', '')}\nJO  - {ref.get('journal', '')}\nDO  - {ref.get('doi', '')}\nER  -\n\n"
                    )
        elif format == "bib":
            with open(export_path, "w", encoding="utf-8") as f:
                for ref in references:
                    f.write(
                        f"@article{{{ref.get('doi', '')},\ntitle = {{{ref.get('title', '')}}},\nauthor = {{{ref.get('authors', '')}}},\nyear = {{{ref.get('year', '')}}},\njournal = {{{ref.get('journal', '')}}},\ndoi = {{{ref.get('doi', '')}}}\n}}\n\n"
                    )
        elif format == "csv":
            with open(export_path, "w", encoding="utf-8") as f:
                f.write("Title,Authors,Year,Journal,DOI\n")
                for ref in references:
                    f.write(
                        f"{ref.get('title', '')},{ref.get('authors', '')},{ref.get('year', '')},{ref.get('journal', '')},{ref.get('doi', '')}\n"
                    )

        print(f"âœ… KaynakÃ§alar {format.upper()} formatÄ±nda dÄ±ÅŸa aktarÄ±ldÄ±: {export_path}")

=== extract_citation_network ===
ModÃ¼l: mindmap_visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def extract_citation_network(self):
        """
        Zoteroâ€™daki atÄ±f iliÅŸkilerini Ã§Ä±kararak bir network grafiÄŸi oluÅŸturur.
        """
        references = self.fetch_references()
        citation_graph = nx.DiGraph()

        for ref in references:
            ref_id = ref["key"]
            title = ref["data"]["title"]
            citation_graph.add_node(ref_id, label=title)

            if "relations" in ref["data"] and "dc:relation" in ref["data"]["relations"]:
                cited_refs = ref["data"]["relations"]["dc:relation"]
                for cited in cited_refs:
                    cited_id = cited.split("/")[-1]
                    citation_graph.add_edge(ref_id, cited_id)

        return citation_graph

=== extract_citations ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def extract_citations(self, document_text):
        """Metin iÃ§indeki atÄ±flarÄ± tespit eder."""
        try:
            citations = []
            lines = document_text.split("\n")
            for line in lines:
                if "[" in line and "]" in line:  # Basit kÃ¶ÅŸeli parantez atÄ±f algÄ±lama
                    citations.append(line.strip())
            self.logger.info(f"âœ… {len(citations)} atÄ±f tespit edildi.")
            return citations
        except Exception as e:
            self.logger.error(f"âŒ AtÄ±f tespit hatasÄ±: {e}")
            return []

=== extract_notes ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def extract_notes(self, item_id):
        """
        Zotero'daki belirli bir Ã¶ÄŸeye ait notlarÄ± Ã§eker.
        """
        try:
            notes = self.zot.item(item_id, "notes")
            return notes
        except Exception as e:
            print(f"âŒ Zotero notlarÄ±nÄ± Ã§ekerken hata oluÅŸtu: {e}")
            return []

=== extract_references ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def extract_references(self, pdf_path) -> List[str]:
        """GeliÅŸmiÅŸ referans Ã§Ä±karma"""
        text = self.extract_text(pdf_path)
        references = []

        # Regex TabanlÄ±
        if self.reference_method in ["regex", "multi"]:
            regex_patterns = [
                r"\[(\d+)\]\s*(.+?)(?=\[|\n\n|$)",  # SayÄ±sal referans
                r"([A-Z][a-z]+ et al\., \d{4})",  # Yazar stili
                r"(\w+,\s\d{4}[a-z]?)",  # APA stili
            ]
            for pattern in regex_patterns:
                references.extend(re.findall(pattern, text, re.DOTALL))

        # ML TabanlÄ±
        if self.reference_method in ["ml", "multi"]:
            ml_references = self.reference_model(text)
            references.extend([entity["word"] for entity in ml_references if entity["entity"] == "B-MISC"])

        # BÃ¶lÃ¼m BazlÄ±
        if self.reference_method in ["section_based", "multi"]:
            section_references = self._extract_references_by_section(text)
            references.extend(section_references)

        return list(set(references))

=== extract_references ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def extract_references(self, text):
        """Ham metindeki atÄ±flarÄ± ve kaynakÃ§alarÄ± tespit eder (40 popÃ¼ler atÄ±f stili)."""
        self.logger.info("ğŸ” AtÄ±flar ham metinden Ã§Ä±karÄ±lÄ±yor...")

        # En sÄ±k kullanÄ±lan 40 atÄ±f stilini kapsayan regex desenleri
        citation_patterns = [
            r"\(([^)]+, \d{4})\)",  # (Smith, 2020)
            r"\[\d+\]",  # [1]
            r"\[(\d+,\s*)*\d+\]",  # [1, 2, 3]
            r"\b(\w+,\s*\d{4})\b",  # Smith, 2020
            r"\b(\w+\s+et\s+al\.,\s*\d{4})\b",  # Smith et al., 2020
            r"\((\w+,\s*\d{4};\s*)+(\w+,\s*\d{4})\)",  # (Smith, 2020; Doe, 2021)
            r"\b(\w+\s+\d{4})\b",  # Smith 2020
            r"\((\w+\s+et\s+al\.,\s*\d{4})\)",  # (Smith et al., 2020)
            r"\[\w+,\s*\d{4}\]",  # [Smith, 2020]
            r"\[(\d+;\s*)*\d+\]",  # [1; 2; 3]
            r"\b(\d{4})\b",  # 2020 (yalnÄ±zca yÄ±l)
            r"\((\w+,\s*\d{4},\s*p\.\s*\d+)\)",  # (Smith, 2020, p. 45)
            r"\b(\w+\s+and\s+\w+,\s*\d{4})\b",  # Smith and Doe, 2020
            r"\b(\w+\s+&\s+\w+,\s*\d{4})\b",  # Smith & Doe, 2020
            r"\((\d{4})\)",  # (2020)
            r"\b(\w+,\s*\d{4},\s*\d{4})\b",  # Smith, 2020, 2021
            r"\[\w+\s+et\s+al\.,\s*\d{4}\]",  # [Smith et al., 2020]
            r"\b(\w+,\s*\d{4},\s*[a-z])\b",  # Smith, 2020a
            r"\((\w+,\s*\d{4}[a-z])\)",  # (Smith, 2020a)
            r"\b(\w+\s+et\s+al\.\s+\d{4})\b",  # Smith et al. 2020
            # Yeni 20+ desen
            r"\((\w+,\s*\w+,\s*&\s*\w+,\s*\d{4})\)",  # APA: (Smith, Jones, & Doe, 2020)
            r"\[(\d+â€“\d+)\]",  # Nature: [1â€“3]
            r"\b(\d+)\b",  # Science: 1
            r"\((\w+\s+et\s+al\.\s*\d{4})\)",  # PNAS: (Smith et al. 2020)
            r"\b(\w+,\s*\d{4},\s*vol\.\s*\d+)\b",  # WOS: Smith, 2020, vol. 5
            r"\b(\w+,\s*\d{4},\s*\d+:\d+â€“\d+)\b",  # JBC: Smith, 2020, 45:123â€“130
            r"\b(\w+,\s*\w+\.\s*\w+\.,\s*\d{4})\b",  # ACS: Smith, J. A., 2020
            r"\((\w+\s+\d{4})\)",  # Chicago: (Smith 2020)
            r"\b(\w+\s+\d+)\b",  # MLA: Smith 123
            r"\((\w+\s+et\s+al\.,\s*\d{4},\s*Cell)\)",  # Cell: (Smith et al., 2020, Cell)
            r"\[\d+:\d+\]",  # BMJ: [1:5]
            r"\((\w+,\s*\d{4},\s*doi:\S+)\)",  # PLOS: (Smith, 2020, doi:10.1000/xyz)
            r"\b(\w+\s+et\s+al\.\s*\d{4},\s*\d+)\b",  # Ecology Letters: Smith et al. 2020, 15
            r"\b(\w+,\s*\d{4},\s*Geophys\.\s*Res\.\s*Lett\.)\b",  # AGU: Smith, 2020, Geophys. Res. Lett.
            r"\[\d+;\s*\d+\]",  # JAMA: [1; 2]
            r"\b(\w+,\s*\d{4},\s*ApJ,\s*\d+)\b",  # ApJ: Smith, 2020, ApJ, 875
            r"\((\w+,\s*\d{4},\s*Environ\.\s*Sci\.\s*Technol\.)\)",  # ES&T: (Smith, 2020, Environ. Sci. Technol.)
            r"\b(\w+,\s*\d{4},\s*J\.\s*Appl\.\s*Phys\.\s*\d+)\b",  # JAP: Smith, 2020, J. Appl. Phys. 128
        ]

        references = []
        for pattern in citation_patterns:
            matches = re.findall(pattern, text)
            references.extend(matches)

        # TekrarlarÄ± kaldÄ±r
        references = list(set(references))
        self.logger.info(f"âœ… {len(references)} atÄ±f tespit edildi.")
        return references

=== extract_references_parallel ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def extract_references_parallel(self, texts):
        """Ã‡oklu iÅŸlem kullanarak birden fazla metinden atÄ±f Ã§Ä±karÄ±r."""
        self.logger.info("ğŸ” Paralel iÅŸlemle atÄ±flar Ã§Ä±karÄ±lÄ±yor...")

        def extract(text):
            return self.extract_references(text)

        with concurrent.futures.ProcessPoolExecutor() as executor:
            results = list(executor.map(extract, texts))

        self.logger.info("âœ… Paralel atÄ±f Ã§Ä±karma tamamlandÄ±.")
        return results

=== extract_tables ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def extract_tables(self, pdf_path) -> List[pd.DataFrame]:
        """Ã‡oklu kÃ¼tÃ¼phane ile tablo Ã§Ä±karma"""
        all_tables = []

        # PyMuPDF
        if "pymupdf" in self.table_method or self.table_method == "multi":
            doc = fitz.open(pdf_path)
            for page in doc:
                pymupdf_tables = page.find_tables()
                all_tables.extend(pymupdf_tables)

        # PDFPlumber
        if "pdfplumber" in self.table_method or self.table_method == "multi":
            with pdfplumber.open(pdf_path) as pdf:
                pdfplumber_tables = [pd.DataFrame(page.extract_table()) for page in pdf.pages if page.extract_table()]
                all_tables.extend(pdfplumber_tables)

        # Tabula
        if "tabula" in self.table_method or self.table_method == "multi":
            tabula_tables = tabula.read_pdf(pdf_path, pages="all")
            all_tables.extend(tabula_tables)

        # Camelot
        if "camelot" in self.table_method or self.table_method == "multi":
            camelot_tables = camelot.read_pdf(pdf_path)
            all_tables.extend([table.df for table in camelot_tables])

        return all_tables

=== extract_tables_from_pdf ===
ModÃ¼l: pdfprocessing
SÄ±nÄ±f: PDFProcessor
Program: zapata_m6h

    def extract_tables_from_pdf(self, pdf_path):
        """PDF'ten tablo Ã§Ä±karÄ±r, belirlenen yÃ¶nteme gÃ¶re Ã§alÄ±ÅŸÄ±r."""
        self.logger.info(f"ğŸ“Š PDF'ten tablolar Ã§Ä±karÄ±lÄ±yor: {pdf_path}")

        tables = []
        if self.table_extraction_method == "pdfplumber":
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    extracted_tables = page.extract_tables()
                    if extracted_tables:
                        tables.extend(extracted_tables)
        elif self.table_extraction_method == "pymupdf":
            doc = fitz.open(pdf_path)
            for page in doc:
                tables.append(page.get_text("blocks"))  # Alternatif tablo iÅŸleme yÃ¶ntemi
        else:
            self.logger.error("âŒ Desteklenmeyen PDF tablo Ã§Ä±karma yÃ¶ntemi!")

        return tables

=== extract_text ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def extract_text(self, pdf_path) -> str:
        """Ã‡oklu kÃ¼tÃ¼phane ile metin Ã§Ä±karma"""
        texts = []

        # PDFPlumber
        if "pdfplumber" in self.text_method or self.text_method == "multi":
            with pdfplumber.open(pdf_path) as pdf:
                texts.append(" ".join([page.extract_text() for page in pdf.pages]))

        # PyMuPDF
        if "pymupdf" in self.text_method or self.text_method == "multi":
            doc = fitz.open(pdf_path)
            texts.append(" ".join([page.get_text() for page in doc]))

        # Borb
        if "borb" in self.text_method or self.text_method == "multi":
            with open(pdf_path, "rb") as file:
                doc = borb.pdf.DocumentFromBytes(file.read())
                borb_text = " ".join([page.extract_text() for page in doc.pages])
                texts.append(borb_text)

        # Tika
        if "tika" in self.text_method or self.text_method == "multi":
            raw = tika.parser.from_file(pdf_path)
            texts.append(raw.get("content", ""))

        # PDFMiner
        if "pdfminer" in self.text_method or self.text_method == "multi":
            from pdfminer.high_level import extract_text

            pdfminer_text = extract_text(pdf_path)
            texts.append(pdfminer_text)

        # En uzun metni seÃ§ veya birleÅŸtir
        return max(texts, key=len) if texts else ""

=== extract_text_from_pdf ===
ModÃ¼l: pdfprocessing
SÄ±nÄ±f: PDFProcessor
Program: zapata_m6h

    def extract_text_from_pdf(self, pdf_path):
        """PDF'ten metin Ã§Ä±karÄ±r, belirlenen yÃ¶nteme gÃ¶re Ã§alÄ±ÅŸÄ±r."""
        self.logger.info(f"ğŸ“„ PDF'ten metin Ã§Ä±karÄ±lÄ±yor: {pdf_path}")

        text = ""
        if self.text_extraction_method == "pdfplumber":
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() + "\n"
        elif self.text_extraction_method == "pymupdf":
            doc = fitz.open(pdf_path)
            text = "\n".join([page.get_text("text") for page in doc])
        else:
            self.logger.error("âŒ Desteklenmeyen PDF metin Ã§Ä±karma yÃ¶ntemi!")

        return text

=== faiss_search ===
ModÃ¼l: retrieve_with_faiss
SÄ±nÄ±f: 
Program: zapata_m6h

def faiss_search(query_text, top_k=3):
    """
    FAISS kullanarak vektÃ¶r aramasÄ± yapar.
    """
    try:
        query_embedding = sentence_model.encode(query_text).reshape(1, -1)
        distances, indices = index.search(query_embedding, top_k)

        results = []
        for idx in indices[0]:
            doc_data = redis_client.get(f"faiss_doc:{idx}")
            if doc_data:
                results.append(json.loads(doc_data))

        return results

    except Exception as e:
        logging.error(f"âŒ FAISS aramasÄ± baÅŸarÄ±sÄ±z oldu: {str(e)}")
        return []

=== fetch_all_references ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def fetch_all_references(self):
        """
        Zotero'dan tÃ¼m referanslarÄ± getirir.
        """
        try:
            references = self.zot.items()
            return references
        except Exception as e:
            print(f"âŒ Zotero referanslarÄ±nÄ± Ã§ekerken hata oluÅŸtu: {e}")
            return []

=== fetch_citation_network ===
ModÃ¼l: veri_gorsellestirme
SÄ±nÄ±f: DataVisualizer
Program: zapata_m6h

    def fetch_citation_network(self, doc_id):
        """Belge iÃ§in atÄ±f aÄŸÄ±nÄ± SQLite veritabanÄ±ndan Ã§eker."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT citation FROM citations WHERE doc_id = ?", (doc_id,))
            references = cursor.fetchall()
            citation_network = []
            for ref in references:
                citation_network.append(json.loads(ref[0]))

            self.logger.info(f"âœ… {len(citation_network)} atÄ±f aÄŸÄ± dÃ¼ÄŸÃ¼mÃ¼ alÄ±ndÄ±.")
            return citation_network
        except sqlite3.Error as e:
            self.logger.error(f"âŒ AtÄ±f aÄŸÄ± verisi alÄ±namadÄ±: {e}")
            return None

=== fetch_from_redis ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def fetch_from_redis(self, doc_id):
        """Redisâ€™ten iÅŸlenmiÅŸ metni alÄ±r."""
        return self.redis_client.get(f"text:{doc_id}")

=== fetch_from_sqlite ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def fetch_from_sqlite(self, doc_id):
        """SQLiteâ€™ten iÅŸlenmiÅŸ metni alÄ±r."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT text FROM processed_texts WHERE id=?", (doc_id,))
        result = cursor.fetchone()
        conn.close()
        return result[0] if result else None

=== fetch_pdf_files ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def fetch_pdf_files(self):
        """
        Zotero'daki tÃ¼m PDF dosyalarÄ±nÄ± Ã§eker.
        """
        try:
            pdf_files = []
            items = self.zot.items()
            for item in items:
                if "data" in item and "attachments" in item["data"]:
                    for attachment in item["data"]["attachments"]:
                        if attachment["contentType"] == "application/pdf":
                            pdf_files.append(attachment["path"])
            return pdf_files
        except Exception as e:
            print(f"âŒ Zotero PDF dosyalarÄ±nÄ± Ã§ekerken hata oluÅŸtu: {e}")
            return []

=== fetch_pdf_from_scihub ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def fetch_pdf_from_scihub(self, doi):
        """DOIâ€™ye gÃ¶re Sci-Hub Ã¼zerinden makale PDF dosyasÄ±nÄ± indirir."""
        sci_hub_url = f"https://sci-hub.se/{doi}"
        response = requests.get(sci_hub_url, stream=True)
        if response.status_code == 200:
            pdf_path = os.path.join(config.PDF_DIR, f"{doi}.pdf")
            with open(pdf_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=1024):
                    f.write(chunk)
            print(f"âœ… PDF indirildi: {pdf_path}")
            return pdf_path
        else:
            print(f"âŒ Sci-Hub'tan PDF indirilemedi: {response.status_code}")
            return None

=== fetch_references ===
ModÃ¼l: mindmap_visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def fetch_references(self):
        """
        Zotero'dan tÃ¼m referanslarÄ± Ã§eker.
        """
        try:
            references = self.zot.items()
            return references
        except Exception as e:
            print(f"âŒ Zotero referanslarÄ±nÄ± Ã§ekerken hata oluÅŸtu: {e}")
            return []

=== fetch_references_from_zotero ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def fetch_references_from_zotero(self):
        """Zoteroâ€™dan tÃ¼m kaynakÃ§a verilerini Ã§eker ve JSON formatÄ±nda kaydeder."""
        response = requests.get(f"{self.api_url}/items", headers=self.headers)
        if response.status_code == 200:
            references = response.json()
            with open(os.path.join(config.TEMIZ_KAYNAKCA_DIZIN, "zotero_references.json"), "w", encoding="utf-8") as f:
                json.dump(references, f, indent=4)
            print("âœ… Zotero'dan kaynakÃ§a verileri alÄ±ndÄ± ve kaydedildi.")
            return references
        else:
            print(f"âŒ Zotero'dan veri alÄ±namadÄ±: {response.status_code}")
            return None

=== fetch_references_from_zotero ===
ModÃ¼l: zoteromodule
SÄ±nÄ±f: ZoteroManager
Program: zapata_m6h

    def fetch_references_from_zotero(self, limit=10):
        """Zotero'dan en son eklenen kaynakÃ§alarÄ± Ã§eker."""
        self.logger.info(f"ğŸ“š Zotero'dan son {limit} kaynak getiriliyor...")
        headers = {"Zotero-API-Key": self.api_key, "Content-Type": "application/json"}
        response = requests.get(f"{self.api_url}?limit={limit}", headers=headers)

        if response.status_code == 200:
            self.logger.info("âœ… Zotero kaynaklarÄ± baÅŸarÄ±yla Ã§ekildi.")
            return response.json()
        else:
            self.logger.error(f"âŒ Zotero API hatasÄ±: {response.status_code}")
            return None

=== fetch_results ===
ModÃ¼l: fetch_top_k_results
SÄ±nÄ±f: FetchTopKResults
Program: zapata_m6h

    def fetch_results(self, query):
        """
        En iyi K sonucu getirir ve sÄ±ralar.
        - query: KullanÄ±cÄ±nÄ±n arama sorgusu.
        """
        try:
            self.logger.info(f"ğŸ” Arama sorgusu: {query}")

            # Ã‡oklu kaynaktan sonuÃ§larÄ± getir
            raw_results = self.search_engine.multi_source_search(query, top_k=self.top_k)

            if not raw_results:
                self.logger.warning("âš ï¸ HiÃ§ sonuÃ§ bulunamadÄ±.")
                self.log_error(query, "SonuÃ§ bulunamadÄ±.")
                return []

            # Reranking iÅŸlemi
            sorted_results = self.reranker.rank_results(raw_results)

            self.logger.info(f"âœ… {len(sorted_results)} sonuÃ§ bulundu ve sÄ±ralandÄ±.")
            return sorted_results[: self.top_k]

        except Exception as e:
            self.logger.error(f"âŒ En iyi K sonucu getirme hatasÄ±: {e}")
            self.log_error(query, str(e))
            return []

=== fetch_results_from_zapata ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def fetch_results_from_zapata(self, query):
        """
        Zapata M6H'dan Zotero'ya sorgu yaparak sonuÃ§larÄ± getirir.
        """
        try:
            response = requests.get(f"{self.zapata_api_url}/search", params={"query": query})
            if response.status_code == 200:
                results = response.json()
                return results
            else:
                print(f"âŒ Zapata'dan veri alÄ±rken hata oluÅŸtu: {response.text}")
                return []
        except Exception as e:
            print(f"âŒ Zapata'dan veri alÄ±rken hata oluÅŸtu: {e}")
            return []

=== fetch_training_data ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def fetch_training_data(self):
        """SQLite veritabanÄ±ndan eÄŸitim verisini Ã§eker"""
        conn = sqlite3.connect(config.SQLITE_DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT text, label FROM training_data")
        rows = cursor.fetchall()
        conn.close()

        texts = [row[0] for row in rows]
        labels = [row[1] for row in rows]
        return texts, labels

=== fetch_training_data ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def fetch_training_data(self):
        """
        SQLite veritabanÄ±ndan eÄŸitim verisini Ã§eker.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT text, label FROM training_data")
        rows = cursor.fetchall()
        conn.close()
        texts = [row[0] for row in rows]
        labels = [row[1] for row in rows]
        return texts, labels

=== full_sync ===
ModÃ¼l: sync_faiss_chromadb
SÄ±nÄ±f: SyncFAISSChromaDB
Program: zapata_m6h

    def full_sync(self):
        """FAISS ve ChromaDB arasÄ±nda Ã§ift yÃ¶nlÃ¼ senkronizasyon yapar."""
        self.logger.info("ğŸ”„ FAISS â†” ChromaDB tam senkronizasyon baÅŸlatÄ±ldÄ±.")
        self.sync_from_chromadb_to_faiss()
        self.sync_from_faiss_to_chromadb()
        self.logger.info("âœ… FAISS â†” ChromaDB senkronizasyonu tamamlandÄ±.")

=== generate_embedding ===
ModÃ¼l: alternativeembeddingmodule
SÄ±nÄ±f: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def generate_embedding(self, text):
        """Metni seÃ§ilen modelle embedding vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
        self.logger.info("ğŸ§  Alternatif model ile embedding iÅŸlemi baÅŸlatÄ±ldÄ±.")

        if self.selected_model:
            embedding_vector = self.selected_model.encode(text, convert_to_numpy=True)
            return embedding_vector
        else:
            self.logger.error(
                "âŒ SeÃ§ilen model bulunamadÄ±! LÃ¼tfen .env dosyasÄ±ndaki EMBEDDING_MODEL deÄŸerini kontrol edin."
            )
            return None

=== generate_embedding ===
ModÃ¼l: embeddingmodule
SÄ±nÄ±f: EmbeddingProcessor
Program: zapata_m6h

    def generate_embedding(self, text):
        """Metni embedding vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
        self.logger.info("ğŸ§  Metin embedding iÅŸlemi baÅŸlatÄ±ldÄ±.")

        if self.embedding_model.startswith("text-embedding-ada"):
            try:
                response = openai.Embedding.create(input=text, model=self.embedding_model)
                embedding_vector = response["data"][0]["embedding"]
                return np.array(embedding_vector)
            except Exception as e:
                self.logger.error(f"âŒ OpenAI embedding hatasÄ±: {e}")
                return None
        else:
            self.logger.warning("âš  Alternatif embedding modelleri desteklenmelidir!")
            return None

=== generate_embedding ===
ModÃ¼l: robustembeddingmodule
SÄ±nÄ±f: RobustEmbeddingProcessor
Program: zapata_m6h

    def generate_embedding(self, text):
        """Metni embedding vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, hata toleransÄ± saÄŸlar."""
        self.logger.info("ğŸ§  Hata toleranslÄ± embedding iÅŸlemi baÅŸlatÄ±ldÄ±.")

        if not text.strip():
            self.logger.warning("âš  BoÅŸ metin verildi, embedding yapÄ±lmadÄ±.")
            return None

        try:
            if self.selected_model == "openai":
                response = openai.Embedding.create(input=text, model=self.embedding_models["openai"])
                embedding_vector = response["data"][0]["embedding"]
            else:
                embedding_vector = self.model.encode(text, convert_to_numpy=True)
            return np.array(embedding_vector)
        except Exception as e:
            self.logger.error(f"âŒ Embedding iÅŸlemi baÅŸarÄ±sÄ±z oldu: {e}")
            return None

=== generate_html ===
ModÃ¼l: d3js_visualizer
SÄ±nÄ±f: D3Visualizer
Program: zapata_m6h

    def generate_html(self, json_data):
        """
        JSON verisini D3.js kullanarak interaktif bir HTML dosyasÄ± oluÅŸturur.
        """
        json_string = json.dumps(json_data).replace("'", "&#39;")
        html_content = self.html_template.replace("%DATA%", json_string)

        html_path = os.path.join(config.OUTPUT_DIR, "mindmap.html")
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        return html_path

=== generate_response ===
ModÃ¼l: rag_pipeline
SÄ±nÄ±f: RAGPipeline
Program: zapata_m6h

    def generate_response(self, query):
        """RAG modeli ile en iyi yanÄ±tÄ± Ã¼retir."""
        retrieved_data = self.retrieve_data(query)

        # Burada RAG modeli Ã§alÄ±ÅŸtÄ±rÄ±labilir (Ã¶rneÄŸin LlamaIndex veya LangChain ile)
        response = f"ğŸ” {query} iÃ§in en uygun sonuÃ§: {retrieved_data[0] if retrieved_data else 'SonuÃ§ bulunamadÄ±'}"
        self.logger.info(f"âœ… RAG yanÄ±tÄ± Ã¼retildi: {response}")
        return response

=== get_api_status ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def get_api_status():
    return jsonify({"status": "API Ã§alÄ±ÅŸÄ±yor"}), 200

=== get_cached_embedding ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def get_cached_embedding(self, doc_id):
        """Redisâ€™ten embedding verisini alÄ±r (JSON ile)."""
        try:
            key = f"embedding:{doc_id}"
            cached_embedding = self.redis_client_str.get(key)
            if cached_embedding:
                self.logger.info(f"âœ… Redisâ€™ten embedding alÄ±ndÄ±: {key}")
                return json.loads(cached_embedding)
            self.logger.warning(f"âš ï¸ Redisâ€™te embedding bulunamadÄ±: {key}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Embedding alma hatasÄ±: {e}")
            return None

=== get_cached_map ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def get_cached_map(self, doc_id, map_type):
        """Redisâ€™ten haritalama verisini alÄ±r."""
        try:
            key = f"{map_type}_map:{doc_id}"
            cached_map = self.redis_client_str.get(key)
            if cached_map:
                self.logger.info(f"âœ… Redisâ€™ten {map_type} haritasÄ± alÄ±ndÄ±: {key}")
                return json.loads(cached_map)
            self.logger.warning(f"âš ï¸ Redisâ€™te {map_type} haritasÄ± bulunamadÄ±: {key}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Harita alma hatasÄ±: {e}")
            return None

=== get_citation_network ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def get_citation_network(self, doc_id):
        """Saklanan atÄ±f verilerini gÃ¶rselleÅŸtirme/analiz iÃ§in alÄ±r."""
        self.logger.info(f"ğŸ” AtÄ±f haritasÄ± getiriliyor: {doc_id}")

        try:
            # Ã–nce Redis'ten kontrol et
            citation_data = self.redis_client.get(f"citations:{doc_id}")
            if citation_data:
                self.logger.info("âœ… Redis'ten atÄ±f haritasÄ± alÄ±ndÄ±.")
                return json.loads(citation_data)

            # Redis'te yoksa SQLite'ten Ã§ek
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT citation, reference, text_parametre FROM citations WHERE doc_id=?", (doc_id,))
            results = cursor.fetchall()
            conn.close()

            if results:
                citation_map = {row[0]: {"reference": row[1], "text_parametre": row[2]} for row in results}
                self.logger.info("âœ… SQLite'ten atÄ±f haritasÄ± alÄ±ndÄ±.")
                return citation_map

            self.logger.warning(f"âš ï¸ {doc_id} iÃ§in atÄ±f haritasÄ± bulunamadÄ±.")
            return {}
        except Exception as e:
            self.logger.error(f"âŒ AtÄ±f haritasÄ± getirilirken hata: {str(e)}")
            return {}

=== get_db_connection ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def get_db_connection():
    return sqlite3.connect(config.SQLITE_DB_PATH)

=== get_env_variable ===
ModÃ¼l: configmodule
SÄ±nÄ±f: Config
Program: zapata_m6h

    def get_env_variable(self, var_name, default=None):
        """Belirtilen deÄŸiÅŸkeni .env dosyasÄ±ndan okur."""
        return os.getenv(var_name, default)

=== get_max_workers ===
ModÃ¼l: configmodule
SÄ±nÄ±f: Config
Program: zapata_m6h

    def get_max_workers(self):
        """Maksimum iÅŸlemci iÅŸÃ§i sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
        return self.MAX_WORKERS

=== get_mindmap_data ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def get_mindmap_data(self, key):
        """Zihin haritasÄ± verisini Redisâ€™ten alÄ±r."""
        try:
            data = self.redis_client_str.get(key)
            if data:
                self.logger.info(f"âœ… Redisâ€™ten zihin haritasÄ± alÄ±ndÄ±: {key}")
                return json.loads(data)
            self.logger.warning(f"âš ï¸ Redisâ€™te zihin haritasÄ± bulunamadÄ±: {key}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Zihin haritasÄ± alma hatasÄ±: {e}")
            return None

=== get_query_result ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def get_query_result(self, query):
        """Ã–nbelleÄŸe alÄ±nmÄ±ÅŸ sorgu sonucunu alÄ±r."""
        try:
            data = self.redis_client_str.get(query)
            if data:
                self.logger.info(f"âœ… Redisâ€™ten sorgu sonucu alÄ±ndÄ±: {query}")
                return json.loads(data)
            self.logger.warning(f"âš ï¸ Redisâ€™te sorgu sonucu bulunamadÄ±: {query}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Sorgu sonucu alma hatasÄ±: {e}")
            return None

=== get_stems ===
ModÃ¼l: query_expansion
SÄ±nÄ±f: QueryExpansion
Program: zapata_m6h

    def get_stems(self, words):
        """Kelime kÃ¶klerini dÃ¶ndÃ¼rÃ¼r (Porter Stemmer)."""
        from nltk.stem import PorterStemmer

        ps = PorterStemmer()
        return {ps.stem(word) for word in words}

=== get_synonyms ===
ModÃ¼l: query_expansion
SÄ±nÄ±f: QueryExpansion
Program: zapata_m6h

    def get_synonyms(self, word, max_expansions):
        """Bir kelimenin eÅŸ anlamlÄ±larÄ±nÄ± getirir."""
        synonyms = set()
        for syn in wordnet.synsets(word):
            for lemma in syn.lemmas():
                synonyms.add(lemma.name().replace("_", " "))
                if len(synonyms) >= max_expansions:
                    break
        return synonyms

=== get_training_results ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def get_training_results():
    results = redis_client.get("training_results")
    if results:
        return jsonify({"training_results": results}), 200
    else:
        return jsonify({"error": "HenÃ¼z eÄŸitim tamamlanmadÄ± veya sonuÃ§ bulunamadÄ±."}), 404

=== get_training_status ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def get_training_status():
    status = redis_client.get("training_status")
    return jsonify({"training_status": status or "Bilinmiyor"}), 200

=== highlight_references ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def highlight_references(self, query):
        """
        Zotero'da bir sorguya uygun referanslarÄ± iÅŸaretler.
        """
        try:
            results = self.fetch_results_from_zapata(query)
            for result in results:
                item_id = result["id"]
                self.zot.update_item(item_id, {"tags": ["Zapata Highlight"]})
                print(f"âœ… {result['title']} iÅŸaretlendi.")
        except Exception as e:
            print(f"âŒ Zotero'da referans iÅŸaretleme hatasÄ±: {e}")

=== home ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def home():
    return jsonify({"message": "Zapata M6H REST API Ã‡alÄ±ÅŸÄ±yor ğŸš€"}), 200

=== init_sqlite_log_table ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def init_sqlite_log_table(self):
        """
        SQLite veritabanÄ±nda hata log tablosunu oluÅŸturur.
        """
        try:
            conn = sqlite3.connect(self.sqlite_db_path)
            cursor = conn.cursor()
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS error_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    level TEXT,
                    message TEXT,
                    module TEXT,
                    function TEXT,
                    details TEXT
                )
            """
            )
            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"SQLite log tablosu oluÅŸturulurken hata: {e}")

=== load_cached_references ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def load_cached_references(self):
        """Redis'ten kaynakÃ§a verilerini yÃ¼kler."""
        keys = self.redis_client.keys("reference:*")
        references = [json.loads(self.redis_client.get(key)) for key in keys]
        return references

=== load_dataset ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningManager
Program: zapata_m6h

    def load_dataset(self):
        """Veri kÃ¼mesini yÃ¼kleyip tokenizasyon yapar."""
        dataset = load_dataset("csv", data_files=self.dataset_path)
        dataset = dataset.map(lambda x: self.tokenizer(x["text"], truncation=True, padding="max_length"), batched=True)
        return dataset

=== load_embeddings_from_chromadb ===
ModÃ¼l: clustering_module
SÄ±nÄ±f: ClusteringProcessor
Program: zapata_m6h

    def load_embeddings_from_chromadb(self):
        """ChromaDB'den tÃ¼m embedding vektÃ¶rlerini Ã§eker."""
        self.logger.info("ğŸ“¥ ChromaDB'den embedding verileri yÃ¼kleniyor...")
        collection = self.chroma_client.get_or_create_collection(name="embeddings")
        results = collection.get(include=["embeddings", "ids"])

        embeddings = np.array(results["embeddings"])
        doc_ids = results["ids"]

        self.logger.info(f"âœ… {len(embeddings)} adet embedding yÃ¼klendi.")
        return embeddings, doc_ids

=== load_faiss_index ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def load_faiss_index(self):
        """FAISS dizinini yÃ¼kler veya yeni oluÅŸturur."""
        try:
            if faiss.read_index("faiss_index.idx"):
                index = faiss.read_index("faiss_index.idx")
                self.logger.info("âœ… FAISS dizini yÃ¼klendi.")
                return index
            else:
                index = faiss.IndexFlatL2(768)
                self.logger.warning("âš ï¸ Yeni FAISS dizini oluÅŸturuldu.")
                return index
        except Exception as e:
            self.logger.error(f"âŒ FAISS yÃ¼kleme hatasÄ±: {e}")
            return None

=== load_faiss_index ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def load_faiss_index(self):
        """FAISS dizinini yÃ¼kler."""
        try:
            index = faiss.read_index("faiss_index.idx")
            self.logger.info("âœ… FAISS dizini yÃ¼klendi.")
            return index
        except Exception as e:
            self.logger.error(f"âŒ FAISS yÃ¼kleme hatasÄ±: {e}")
            return None

=== load_faiss_index ===
ModÃ¼l: sync_faiss_chromadb
SÄ±nÄ±f: SyncFAISSChromaDB
Program: zapata_m6h

    def load_faiss_index(self):
        """FAISS dizinini yÃ¼kler veya yeni oluÅŸturur."""
        try:
            if os.path.exists("faiss_index.idx"):
                index = faiss.read_index("faiss_index.idx")
                self.logger.info("âœ… FAISS dizini yÃ¼klendi.")
                return index
            else:
                index = faiss.IndexFlatL2(768)  # Ã–ntanÄ±mlÄ± boyut (768)
                self.logger.warning("âš ï¸ Yeni FAISS dizini oluÅŸturuldu.")
                return index
        except Exception as e:
            self.logger.error(f"âŒ FAISS yÃ¼kleme hatasÄ±: {e}")
            return None

=== load_json ===
ModÃ¼l: helpermodule
SÄ±nÄ±f: HelperFunctions
Program: zapata_m6h

    def load_json(self, file_path):
        """JSON dosyasÄ±nÄ± yÃ¼kler."""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            self.logger.info(f"âœ… JSON dosyasÄ± yÃ¼klendi: {file_path}")
            return data
        except Exception as e:
            self.logger.error(f"âŒ JSON yÃ¼kleme hatasÄ±: {e}")
            return None

=== load_mind_map ===
ModÃ¼l: Mind_Map_Visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def load_mind_map(self):
        """
        JSON formatÄ±nda saklanan zihin haritasÄ±nÄ± yÃ¼kler ve gÃ¶rÃ¼ntÃ¼ler.
        """
        try:
            with open(config.MINDMAP_JSON_PATH, "r", encoding="utf-8") as f:
                mind_map_data = json.load(f)
            d3js_visualizer.display_mind_map(mind_map_data)
        except Exception as e:
            print(f"âŒ Hata: {e}")

=== load_mindmap_data ===
ModÃ¼l: guimindmap
SÄ±nÄ±f: MindMapGUI
Program: zapata_m6h

    def load_mindmap_data(self):
        """Zotero ve Zapataâ€™dan verileri Ã§ekerek JSON formatÄ±nda kaydeder."""
        zotero_data = fetch_zotero_data()
        zapata_data = fetch_mindmap_data()

        mindmap_data = {"nodes": [], "links": []}

        # Zoteroâ€™dan gelen kaynakÃ§a verileri
        for item in zotero_data:
            mindmap_data["nodes"].append({"id": item["title"], "group": "zotero"})

        # Zapataâ€™dan gelen atÄ±f ve baÄŸlantÄ±lar
        for link in zapata_data["links"]:
            mindmap_data["links"].append({"source": link["source"], "target": link["target"], "type": "citation"})

        with open("mindmap_data.json", "w", encoding="utf-8") as f:
            json.dump(mindmap_data, f, indent=4)
        print("âœ… Zihin haritasÄ± verileri baÅŸarÄ±yla yÃ¼klendi!")

=== load_model_from_redis ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def load_model_from_redis(self):
        """Redis'ten modeli yÃ¼kler"""
        model_data = redis_client.get(f"fine_tuned_model:{self.model_name}")
        if model_data:
            with open(os.path.join(self.output_dir, "pytorch_model.bin"), "wb") as f:
                f.write(model_data)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.output_dir)
            logging.info(f"ğŸ“Œ {self.model_name} modeli Redisâ€™ten alÄ±ndÄ± ve belleÄŸe yÃ¼klendi.")
        else:
            logging.error(f"âŒ {self.model_name} iÃ§in Redisâ€™te kayÄ±tlÄ± model bulunamadÄ±.")

=== load_model_from_redis ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def load_model_from_redis(self):
        """
        Redis'ten modeli alÄ±r ve belleÄŸe yÃ¼kler.
        """
        model_data = self.redis_client.get(f"fine_tuned_model_{self.model_name}")
        if model_data:
            with open(os.path.join(self.output_dir, "pytorch_model.bin"), "wb") as f:
                f.write(model_data)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.output_dir)
            logger.info("ğŸ“Œ Model Redisâ€™ten alÄ±ndÄ± ve belleÄŸe yÃ¼klendi.")
        else:
            logger.error("âŒ Redisâ€™te kayÄ±tlÄ± model bulunamadÄ±.")

=== log_error ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def log_error(self, message, level="ERROR", module="Unknown", function="Unknown", details=""):
        """
        Hata mesajlarÄ±nÄ± Ã¼Ã§ farklÄ± formata (TXT, JSON, SQLite) kaydeder.
        """
        error_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "level": level,
            "message": message,
            "module": module,
            "function": function,
            "details": details,
        }

        self.log_to_file(message, level)
        self.log_to_json(error_data)
        self.log_to_sqlite(message, level, module, function, details)

        print(f"âŒ Hata kaydedildi: {message}")

=== log_error ===
ModÃ¼l: fetch_top_k_results
SÄ±nÄ±f: FetchTopKResults
Program: zapata_m6h

    def log_error(self, query, error_message):
        """HatalarÄ± JSON formatÄ±nda log dosyasÄ±na kaydeder."""
        error_data = {
            "timestamp": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            "query": query,
            "error": error_message,
        }
        try:
            with open(self.error_log_file, "a", encoding="utf-8") as log_file:
                json.dump(error_data, log_file, ensure_ascii=False)
                log_file.write("\n")
            self.logger.error(f"âŒ Hata kaydedildi: {error_message}")
        except Exception as e:
            self.logger.critical(f"âš ï¸ Hata logu kaydedilemedi: {e}")

=== log_test_result ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def log_test_result(self, test_name, status, details=""):
        """
        Test sonuÃ§larÄ±nÄ± JSON ve SQLite formatÄ±nda kaydeder.
        """
        test_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "test_name": test_name,
            "status": status,
            "details": details,
        }

        # JSON kaydÄ±
        try:
            if not os.path.exists(self.test_log_file):
                with open(self.test_log_file, "w", encoding="utf-8") as f:
                    json.dump([], f, indent=4)

            with open(self.test_log_file, "r+", encoding="utf-8") as f:
                logs = json.load(f)
                logs.append(test_data)
                f.seek(0)
                json.dump(logs, f, indent=4)
        except Exception as e:
            logging.error(f"Test sonucu JSON'a kaydedilemedi: {e}")

        # SQLite kaydÄ±
        try:
            conn = sqlite3.connect(self.sqlite_db_path)
            cursor = conn.cursor()
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS test_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    test_name TEXT,
                    status TEXT,
                    details TEXT
                )
            """
            )
            cursor.execute(
                """
                INSERT INTO test_results (timestamp, test_name, status, details)
                VALUES (?, ?, ?, ?)
            """,
                (test_data["timestamp"], test_data["test_name"], test_data["status"], test_data["details"]),
            )
            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"Test sonucu SQLite'a kaydedilemedi: {e}")

=== log_to_file ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def log_to_file(self, message, level="ERROR"):
        """
        Hata mesajlarÄ±nÄ± TXT dosyasÄ±na kaydeder.
        """
        logging.log(getattr(logging, level, logging.ERROR), message)

=== log_to_json ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def log_to_json(self, error_data):
        """
        Hata mesajlarÄ±nÄ± JSON dosyasÄ±na kaydeder.
        """
        try:
            if not os.path.exists(self.json_log_file):
                with open(self.json_log_file, "w", encoding="utf-8") as f:
                    json.dump([], f, indent=4)

            with open(self.json_log_file, "r+", encoding="utf-8") as f:
                logs = json.load(f)
                logs.append(error_data)
                f.seek(0)
                json.dump(logs, f, indent=4)
        except Exception as e:
            logging.error(f"JSON log kaydÄ± sÄ±rasÄ±nda hata: {e}")

=== log_to_sqlite ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def log_to_sqlite(self, message, level="ERROR", module="Unknown", function="Unknown", details=""):
        """
        Hata mesajlarÄ±nÄ± SQLite veritabanÄ±na kaydeder.
        """
        try:
            conn = sqlite3.connect(self.sqlite_db_path)
            cursor = conn.cursor()
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            cursor.execute(
                """
                INSERT INTO error_logs (timestamp, level, message, module, function, details)
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (timestamp, level, message, module, function, details),
            )

            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"SQLite hata kaydÄ± sÄ±rasÄ±nda hata: {e}")

=== map_citations_to_references ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def map_citations_to_references(self, doc_id):
        """AtÄ±flarÄ± kaynakÃ§a ile eÅŸleÅŸtirir ve ChromaDB'ye kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT citation FROM citations WHERE doc_id = ?", (doc_id,))
            references = cursor.fetchall()
            mapped_citations = []

            for ref in references:
                ref_text = json.loads(ref[0])
                for citation in ref_text:
                    mapped_citations.append({"doc_id": doc_id, "citation": citation, "reference": ref_text})

            self.chroma_db.store_data(doc_id, mapped_citations)
            self.logger.info(f"âœ… {len(mapped_citations)} atÄ±f ChromaDB'ye kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ AtÄ±f eÅŸleÅŸtirme hatasÄ±: {e}")

=== map_citations_to_references ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def map_citations_to_references(self, citations, reference_list):
        """AtÄ±flarÄ± kaynakÃ§alarla eÅŸleÅŸtirir."""
        self.logger.info("ğŸ“Œ AtÄ±flar kaynakÃ§alarla eÅŸleÅŸtiriliyor...")

        citation_map = {}
        for citation in citations:
            for ref in reference_list:
                if citation in ref:
                    citation_map[citation] = ref
                    break

        self.logger.info(f"âœ… {len(citation_map)} atÄ±f eÅŸleÅŸmesi yapÄ±ldÄ±.")
        return citation_map

=== map_document_structure ===
ModÃ¼l: layout_analysis
SÄ±nÄ±f: LayoutAnalyzer
Program: zapata_m6h

    def map_document_structure(self, doc_id, document_text):
        """Makale yapÄ±sÄ±nÄ± belirler ve iÅŸaretler."""
        try:
            mapped_layout = {}
            for element, pattern in self.layout_patterns.items():
                matches = re.finditer(pattern, document_text, re.IGNORECASE)
                mapped_layout[element] = [match.start() for match in matches]

            self.redis_cache.cache_map_data(doc_id, "layout_mapping", mapped_layout)
            self.store_mapping_to_db(doc_id, mapped_layout)

            self.logger.info(f"âœ… {len(mapped_layout)} yapÄ±sal Ã¶ÄŸe tespit edildi ve kaydedildi.")
            return mapped_layout
        except Exception as e:
            self.logger.error(f"âŒ YapÄ±sal haritalama hatasÄ±: {e}")
            return None

=== map_scientific_sections ===
ModÃ¼l: scientific_mapping
SÄ±nÄ±f: ScientificMapper
Program: zapata_m6h

    def map_scientific_sections(self, doc_id, document_text):
        """Makale bÃ¶lÃ¼mlerini belirler ve iÅŸaretler."""
        try:
            mapped_sections = {}
            for section, pattern in self.section_patterns.items():
                match = re.search(pattern, document_text, re.IGNORECASE)
                if match:
                    mapped_sections[section] = match.start()

            sorted_sections = sorted(mapped_sections.items(), key=lambda x: x[1])
            structured_sections = {k: document_text[v:] for k, v in sorted_sections}

            # Redis'e kaydet
            self.redis_cache.cache_map_data(doc_id, "scientific_mapping", structured_sections)
            # SQLite'e kaydet
            self.store_mapping_to_db(doc_id, structured_sections)

            self.logger.info(f"âœ… {len(structured_sections)} bÃ¶lÃ¼m tespit edildi ve kaydedildi.")
            return structured_sections
        except Exception as e:
            self.logger.error(f"âŒ Bilimsel haritalama hatasÄ±: {e}")
            return None

=== multi_source_search ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def multi_source_search(self, query, top_k=5):
        """
        AynÄ± anda FAISS, ChromaDB, SQLite, Redis ve Retrieve Ã¼zerinde arama yapar.
        - query: KullanÄ±cÄ±nÄ±n arama sorgusu.
        - top_k: En iyi eÅŸleÅŸme sayÄ±sÄ±.
        """
        try:
            expanded_query = self.query_expander.expand_query(query, method="combined", max_expansions=3)
            self.logger.info(f"ğŸ” GeniÅŸletilmiÅŸ sorgu: {expanded_query}")

            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [
                    executor.submit(self.search_faiss, expanded_query, top_k),
                    executor.submit(self.search_chromadb, expanded_query, top_k),
                    executor.submit(self.search_sqlite, expanded_query, top_k),
                    executor.submit(self.search_redis, expanded_query, top_k),
                    executor.submit(self.search_retrieve, expanded_query, top_k),
                ]
                results = [future.result() for future in futures]

            combined_results = sum(results, [])  # SonuÃ§larÄ± dÃ¼z liste haline getir
            reranked_results = self.reranker.rank_results(combined_results)

            self.logger.info(f"âœ… {len(reranked_results)} sonuÃ§ bulundu ve sÄ±ralandÄ±.")
            return reranked_results[:top_k]

        except Exception as e:
            self.logger.error(f"âŒ Multi-Source arama hatasÄ±: {e}")
            return []

=== multi_source_search ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def multi_source_search(self, query, top_k=5):
        """
        AynÄ± anda FAISS, ChromaDB, SQLite ve Redis Ã¼zerinden arama yapar.
        - query: KullanÄ±cÄ±nÄ±n arama sorgusu.
        - top_k: En iyi eÅŸleÅŸme sayÄ±sÄ±.
        """
        try:
            expanded_query = self.query_expander.expand_query(query, method="combined", max_expansions=3)
            self.logger.info(f"ğŸ” GeniÅŸletilmiÅŸ sorgu: {expanded_query}")

            faiss_results = self.search_faiss(expanded_query, top_k)
            chroma_results = self.search_chromadb(expanded_query, top_k)
            sqlite_results = self.search_sqlite(expanded_query, top_k)
            redis_results = self.search_redis(expanded_query, top_k)

            combined_results = faiss_results + chroma_results + sqlite_results + redis_results
            sorted_results = sorted(combined_results, key=lambda x: x[1], reverse=True)

            self.logger.info(f"âœ… {len(sorted_results)} sonuÃ§ bulundu ve sÄ±ralandÄ±.")
            return sorted_results[:top_k]

        except Exception as e:
            self.logger.error(f"âŒ Arama hatasÄ±: {e}")
            return []

=== open_mindmap ===
ModÃ¼l: guimindmap
SÄ±nÄ±f: MindMapGUI
Program: zapata_m6h

    def open_mindmap(self):
        """Zihin haritasÄ±nÄ± gÃ¶rÃ¼ntÃ¼lemek iÃ§in yerel bir HTML sunucusu baÅŸlatÄ±r."""
        file_path = os.path.abspath("mindmap.html")
        webbrowser.open("file://" + file_path)

        if self.server is None:
            self.server = HTTPServer(("localhost", 8080), SimpleHTTPRequestHandler)
            print("ğŸŒ Mind Map Server baÅŸlatÄ±ldÄ±: http://localhost:8080")
            self.server.serve_forever()

=== optimize_memory ===
ModÃ¼l: helpermodule
SÄ±nÄ±f: HelperFunctions
Program: zapata_m6h

    def optimize_memory(self):
        """Bellek optimizasyonu iÃ§in Ã§Ã¶p toplayÄ±cÄ±yÄ± Ã§alÄ±ÅŸtÄ±rÄ±r."""
        self.logger.info("ğŸ”„ Bellek optimizasyonu baÅŸlatÄ±lÄ±yor...")
        gc.collect()
        self.logger.info("âœ… Bellek optimizasyonu tamamlandÄ±.")

=== parallel_finetune ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: 
Program: zapata_m6h

def parallel_finetune(model_name):
    """SeÃ§ilen modeli paralel olarak eÄŸitir"""
    fine_tuner = FineTuner(model_name)
    fine_tuner.train_model()
    fine_tuner.save_model_to_redis()

=== parallel_training ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: 
Program: zapata_m6h

def parallel_training(selected_models):
    """
    SeÃ§ilen modellerin **paralel olarak** eÄŸitilmesini saÄŸlar.
    """
    with ProcessPoolExecutor(max_workers=len(selected_models)) as executor:
        futures = [executor.submit(FineTuner(model).train_model) for model in selected_models]
        for future in futures:
            future.result()  # Ä°ÅŸlemlerin tamamlanmasÄ±nÄ± bekle

=== parallel_training ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: 
Program: zapata_m6h

def parallel_training(selected_models):
    """
    SeÃ§ilen modellerin **paralel olarak** eÄŸitilmesini saÄŸlar.
    """
    with ProcessPoolExecutor(max_workers=len(selected_models)) as executor:
        futures = [executor.submit(FineTuner(model).train_model) for model in selected_models]
        for future in futures:
            future.result()  # Ä°ÅŸlemlerin tamamlanmasÄ±nÄ± bekle

=== parse_pdf ===
ModÃ¼l: document_parser
SÄ±nÄ±f: DocumentParser
Program: zapata_m6h

    def parse_pdf(self, pdf_path):
        """
        PDF dosyasÄ±ndan iÃ§erik ve metadata Ã§Ä±kartÄ±r.
        """
        try:
            self.logger.info(f"ğŸ“‚ PDF iÅŸleniyor: {pdf_path}")
            doc = fitz.open(pdf_path)

            metadata = {
                "title": doc.metadata.get("title", "Bilinmeyen BaÅŸlÄ±k"),
                "author": doc.metadata.get("author", "Bilinmeyen Yazar"),
                "doi": None,  # DOI bilgisi metin iÃ§inden Ã§ekilecek
                "date": doc.metadata.get("creationDate", "Bilinmeyen Tarih"),
            }

            raw_text = ""
            for page in doc:
                raw_text += page.get_text("text") + "\n"

            # YapÄ±sal ve bilimsel haritalama
            structure_map = self.layout_analyzer.analyze_layout(raw_text)
            science_map = self.scientific_mapper.map_scientific_sections(raw_text)

            result = {
                "metadata": metadata,
                "text": raw_text,
                "structure_map": structure_map,
                "science_map": science_map,
            }

            # Redis ve SQLite'e kaydet
            self.queue.enqueue_task(json.dumps(result))
            self.db.store_document_metadata(metadata)

            self.logger.info(f"âœ… PDF iÅŸleme tamamlandÄ±: {pdf_path}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ PDF iÅŸleme hatasÄ±: {e}")
            return None

=== parse_ris ===
ModÃ¼l: document_parser
SÄ±nÄ±f: DocumentParser
Program: zapata_m6h

    def parse_ris(self, ris_path):
        """
        RIS formatÄ±ndaki kaynakÃ§a dosyalarÄ±nÄ± iÅŸler ve metadata Ã§Ä±kartÄ±r.
        """
        try:
            self.logger.info(f"ğŸ“‚ RIS iÅŸleniyor: {ris_path}")
            with open(ris_path, "r", encoding="utf-8") as f:
                ris_data = f.readlines()

            metadata = {}
            for line in ris_data:
                if line.startswith("TY  -"):
                    metadata["type"] = line.split("-")[1].strip()
                elif line.startswith("TI  -"):
                    metadata["title"] = line.split("-")[1].strip()
                elif line.startswith("AU  -"):
                    metadata.setdefault("authors", []).append(line.split("-")[1].strip())
                elif line.startswith("DO  -"):
                    metadata["doi"] = line.split("-")[1].strip()
                elif line.startswith("PY  -"):
                    metadata["year"] = line.split("-")[1].strip()

            self.db.store_document_metadata(metadata)

            self.logger.info(f"âœ… RIS iÅŸleme tamamlandÄ±: {ris_path}")
            return metadata

        except Exception as e:
            self.logger.error(f"âŒ RIS iÅŸleme hatasÄ±: {e}")
            return None

=== parse_txt ===
ModÃ¼l: document_parser
SÄ±nÄ±f: DocumentParser
Program: zapata_m6h

    def parse_txt(self, txt_path):
        """
        TXT dosyasÄ±ndan iÃ§erik Ã§Ä±karÄ±r ve analiz eder.
        """
        try:
            self.logger.info(f"ğŸ“‚ TXT iÅŸleniyor: {txt_path}")

            with open(txt_path, "r", encoding="utf-8") as f:
                raw_text = f.read()

            structure_map = self.layout_analyzer.analyze_layout(raw_text)
            science_map = self.scientific_mapper.map_scientific_sections(raw_text)

            result = {
                "metadata": {"title": Path(txt_path).stem, "author": "Bilinmeyen"},
                "text": raw_text,
                "structure_map": structure_map,
                "science_map": science_map,
            }

            self.queue.enqueue_task(json.dumps(result))
            self.db.store_document_metadata(result["metadata"])

            self.logger.info(f"âœ… TXT iÅŸleme tamamlandÄ±: {txt_path}")
            return result

        except Exception as e:
            self.logger.error(f"âŒ TXT iÅŸleme hatasÄ±: {e}")
            return None

=== perform_search ===
ModÃ¼l: guimodule
SÄ±nÄ±f: ZapataGUI
Program: zapata_m6h

    def perform_search(self, query):
        """Retrieve, FAISS ve RAG pipeline Ã¼zerinden arama yapar."""
        retriever = RetrieverIntegration()
        faiss = FAISSIntegration()
        rag = RAGPipeline()

        retrieve_results = retriever.send_query(query)
        faiss_results, _ = faiss.search_similar(query, top_k=5)
        rag_results = rag.generate_response(query)

        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", f"ğŸ“Œ Retrieve SonuÃ§larÄ±: {retrieve_results}\n")
        self.result_text.insert("end", f"ğŸ“Œ FAISS SonuÃ§larÄ±: {faiss_results}\n")
        self.result_text.insert("end", f"ğŸ“Œ RAG CevabÄ±: {rag_results}\n")

=== plot_citation_network ===
ModÃ¼l: veri_gorsellestirme
SÄ±nÄ±f: DataVisualizer
Program: zapata_m6h

    def plot_citation_network(self, doc_id):
        """AtÄ±f aÄŸÄ±nÄ± Ã§izerek gÃ¶sterir."""
        citation_data = self.fetch_citation_network(doc_id)
        if not citation_data:
            self.logger.warning(f"âš ï¸ AtÄ±f aÄŸÄ± verisi bulunamadÄ±: {doc_id}")
            return

        G = nx.DiGraph()
        for citation in citation_data:
            for ref in citation:
                G.add_edge(doc_id, ref)

        plt.figure(figsize=(10, 6))
        pos = nx.spring_layout(G)
        nx.draw(
            G,
            pos,
            with_labels=True,
            node_size=3000,
            node_color="skyblue",
            edge_color="gray",
            font_size=10,
            font_weight="bold",
        )
        plt.title(f"ğŸ“Š AtÄ±f AÄŸÄ± GÃ¶rselleÅŸtirmesi: {doc_id}")
        plt.show()
        self.logger.info(f"âœ… AtÄ±f aÄŸÄ± gÃ¶rselleÅŸtirildi: {doc_id}")

=== plot_clustering_results ===
ModÃ¼l: veri_gorsellestirme
SÄ±nÄ±f: DataVisualizer
Program: zapata_m6h

    def plot_clustering_results(self, clustering_data):
        """KÃ¼melenme sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirir."""
        try:
            plt.figure(figsize=(10, 6))
            sns.scatterplot(
                x=clustering_data[:, 0], y=clustering_data[:, 1], hue=clustering_data[:, 2], palette="viridis"
            )
            plt.title("ğŸ“Š Embedding KÃ¼meleme SonuÃ§larÄ±")
            plt.xlabel("Ã–zellik 1")
            plt.ylabel("Ã–zellik 2")
            plt.show()
            self.logger.info("âœ… Embedding kÃ¼meleme sonuÃ§larÄ± gÃ¶rselleÅŸtirildi.")
        except Exception as e:
            self.logger.error(f"âŒ KÃ¼meleme gÃ¶rselleÅŸtirme hatasÄ±: {e}")

=== process_and_store ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def process_and_store(self, text, doc_id, apply_stemming=False):
        """Metni iÅŸler ve SQLite + Redisâ€™e kaydeder."""
        processed_text = self.process_text(text, apply_stemming)
        self.save_to_sqlite(processed_text, doc_id)
        self.save_to_redis(processed_text, doc_id)
        return processed_text

=== process_citation_data ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def process_citation_data():
    thread = threading.Thread(target=process_citations)
    thread.start()

    logging.info("ğŸ“Œ AtÄ±f zinciri analizi baÅŸlatÄ±ldÄ±.")
    return jsonify({"status": "AtÄ±f zinciri analizi baÅŸlatÄ±ldÄ±."}), 200

=== process_document ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def process_document(self, doc_id, document_text):
        """Belgeyi analiz eder ve atÄ±f eÅŸleÅŸtirmesi yapar."""
        citations = self.extract_citations(document_text)
        if citations:
            self.redis_cache.cache_map_data(doc_id, "citation", citations)
            self.map_citations_to_references(doc_id)
        else:
            self.logger.warning(f"âš ï¸ Belge iÃ§inde atÄ±f bulunamadÄ±: {doc_id}")

=== process_pdf ===
ModÃ¼l: pdfkutuphane
SÄ±nÄ±f: AdvancedPDFProcessor
Program: zapata_m6h

    def process_pdf(self, pdf_path):
        """TÃ¼m Ã¶zellikleri birleÅŸtirilmiÅŸ PDF iÅŸleme"""
        return {
            "text": self.extract_text(pdf_path),
            "tables": self.extract_tables(pdf_path),
            "references": self.extract_references(pdf_path),
            "layout": self.detect_page_layout(pdf_path),
        }

=== process_task ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def process_task(self, task_data):
        """
        Bir gÃ¶revi iÅŸler (dummy iÅŸlem).
        """
        try:
            logging.info(f"ğŸš€ Ä°ÅŸlem baÅŸlatÄ±ldÄ±: {task_data}")
            time.sleep(2)  # SimÃ¼lasyon iÃ§in bekletme
            logging.info(f"âœ… Ä°ÅŸlem tamamlandÄ±: {task_data}")
        except Exception as e:
            logging.error(f"âŒ Ä°ÅŸlem sÄ±rasÄ±nda hata oluÅŸtu: {e}")

=== process_text ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def process_text(self, text, apply_stemming=False):
        """Tam metin iÅŸleme sÃ¼recini uygular."""
        text = self.clean_text(text)
        text = self.remove_stopwords(text)
        if apply_stemming:
            text = self.stem_words(text)
        return text

=== reflow_columns ===
ModÃ¼l: pdfprocessing
SÄ±nÄ±f: PDFProcessor
Program: zapata_m6h

    def reflow_columns(self, text):
        """Ã‡ok sÃ¼tunlu metni dÃ¼zene sokar."""
        self.logger.info("ğŸ“ Metin sÃ¼tun dÃ¼zenleme iÅŸlemi baÅŸlatÄ±ldÄ±.")
        cleaned_text = text.replace("\n", " ")  # Basit sÃ¼tun birleÅŸtirme iÅŸlemi
        return cleaned_text

=== remove_stopwords ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def remove_stopwords(self, text):
        """Metinden stop-wordâ€™leri kaldÄ±rÄ±r."""
        words = word_tokenize(text)
        filtered_words = [word for word in words if word not in self.stop_words]
        return " ".join(filtered_words)

=== rerank_results ===
ModÃ¼l: retrieve_with_reranking
SÄ±nÄ±f: 
Program: zapata_m6h

def rerank_results(query, documents, method="bert", top_n=3):
    """
    Retrieve edilen metinleri re-rank eder.
    :param query: KullanÄ±cÄ±nÄ±n sorgusu
    :param documents: Retrieve edilen metinler
    :param method: "bert" veya "tfidf" (re-ranking yÃ¶ntemi)
    :param top_n: En iyi kaÃ§ sonuÃ§ dÃ¶ndÃ¼rÃ¼lecek
    :return: En iyi sÄ±ralanmÄ±ÅŸ metinler
    """
    try:
        if method == "bert":
            query_embedding = bert_model.encode(query, convert_to_tensor=True)
            doc_embeddings = bert_model.encode([doc["text"] for doc in documents], convert_to_tensor=True)
            cosine_scores = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]
            ranked_indices = cosine_scores.argsort(descending=True)[:top_n]

        elif method == "tfidf":
            vectorizer = TfidfVectorizer()
            all_texts = [query] + [doc["text"] for doc in documents]
            tfidf_matrix = vectorizer.fit_transform(all_texts)
            query_vec = tfidf_matrix[0]
            doc_vectors = tfidf_matrix[1:]
            scores = np.dot(doc_vectors, query_vec.T).toarray().flatten()
            ranked_indices = np.argsort(scores)[::-1][:top_n]

        else:
            logging.error(f"âŒ GeÃ§ersiz re-ranking yÃ¶ntemi: {method}")
            return documents[:top_n]

        return [documents[i] for i in ranked_indices]

    except Exception as e:
        logging.error(f"âŒ Re-ranking iÅŸlemi baÅŸarÄ±sÄ±z oldu: {str(e)}")
        return documents[:top_n]

=== rerank_results ===
ModÃ¼l: reranking_module
SÄ±nÄ±f: RerankingModule
Program: zapata_m6h

    def rerank_results(self, query, retrieve_results, faiss_results, weights=(0.5, 0.5)):
        """
        Retrieve ve FAISS sonuÃ§larÄ±nÄ± tekrar sÄ±ralar.
        - retrieve_results: Retrieve API'den gelen sonuÃ§lar
        - faiss_results: FAISS tarafÄ±ndan dÃ¶ndÃ¼rÃ¼len benzerlik sonuÃ§larÄ±
        - weights: (retrieve_weight, faiss_weight) - SonuÃ§larÄ±n aÄŸÄ±rlÄ±k katsayÄ±larÄ±
        """
        try:
            if not retrieve_results and not faiss_results:
                self.logger.warning("âš ï¸ Reranking iÃ§in yeterli veri bulunamadÄ±.")
                return []

            # AÄŸÄ±rlÄ±klÄ± skorlama yaparak sÄ±ralama oluÅŸtur
            retrieve_weight, faiss_weight = weights
            combined_results = {}

            for idx, result in enumerate(retrieve_results):
                combined_results[result] = retrieve_weight * (1.0 / (idx + 1))  # Ä°lk sonuÃ§lara daha fazla Ã¶nem ver

            for idx, (doc_id, similarity) in enumerate(faiss_results):
                if doc_id in combined_results:
                    combined_results[doc_id] += faiss_weight * similarity
                else:
                    combined_results[doc_id] = faiss_weight * similarity

            # SkorlarÄ± bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe sÄ±rala
            sorted_results = sorted(combined_results.items(), key=lambda x: x[1], reverse=True)

            self.logger.info(f"âœ… {len(sorted_results)} sonuÃ§ tekrar sÄ±ralandÄ±.")
            return sorted_results

        except Exception as e:
            self.logger.error(f"âŒ Reranking sÄ±rasÄ±nda hata oluÅŸtu: {e}")
            return []

=== rerank_results ===
ModÃ¼l: retrieval_reranker
SÄ±nÄ±f: RetrievalReranker
Program: zapata_m6h

    def rerank_results(self, query, retrieve_results, faiss_results, weights=(0.5, 0.5)):
        """
        Retrieve ve FAISS sonuÃ§larÄ±nÄ± yeniden sÄ±ralar.
        - retrieve_results: Retrieve API'den gelen sonuÃ§lar
        - faiss_results: FAISS tarafÄ±ndan dÃ¶ndÃ¼rÃ¼len benzerlik sonuÃ§larÄ±
        - weights: (retrieve_weight, faiss_weight) - SonuÃ§larÄ±n aÄŸÄ±rlÄ±k katsayÄ±larÄ±
        """
        try:
            if not retrieve_results and not faiss_results:
                self.logger.warning("âš ï¸ Reranking iÃ§in yeterli veri bulunamadÄ±.")
                return []

            combined_results = []
            for doc_id, text in retrieve_results.items():
                combined_results.append((doc_id, text, "retrieve"))

            for doc_id, similarity in faiss_results:
                combined_results.append((doc_id, similarity, "faiss"))

            reranked_scores = []
            for doc_id, text_or_score, source in combined_results:
                input_pair = [(query, text_or_score)] if source == "retrieve" else [(query, "")]
                score = self.model.predict(input_pair)[0]
                reranked_scores.append((doc_id, score))

            sorted_results = sorted(reranked_scores, key=lambda x: x[1], reverse=True)

            self.logger.info(f"âœ… {len(sorted_results)} sonuÃ§ yeniden sÄ±ralandÄ±.")
            return sorted_results

        except Exception as e:
            self.logger.error(f"âŒ Reranking sÄ±rasÄ±nda hata oluÅŸtu: {e}")
            return []

=== retrieve_and_rerank ===
ModÃ¼l: retrieve_with_reranking
SÄ±nÄ±f: 
Program: zapata_m6h

def retrieve_and_rerank(query, source="faiss", method="bert", top_k=5, top_n=3):
    """
    Retrieve edilen verileri alÄ±r, re-rank eder ve en iyi sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r.
    :param query: KullanÄ±cÄ±nÄ±n sorgusu
    :param source: FAISS veya ChromaDB
    :param method: Re-ranking yÃ¶ntemi ("bert" veya "tfidf")
    :param top_k: Retrieve edilecek toplam sonuÃ§ sayÄ±sÄ±
    :param top_n: En iyi dÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
    :return: En iyi sÄ±ralanmÄ±ÅŸ metinler
    """
    try:
        documents = retrieve_from_source(query, source, top_k)
        return rerank_results(query, documents, method, top_n)

    except Exception as e:
        logging.error(f"âŒ Retrieve + Re-Ranking baÅŸarÄ±sÄ±z oldu: {str(e)}")
        return []

=== retrieve_and_rerank_parallel ===
ModÃ¼l: retrieve_and_rerank_parallel
SÄ±nÄ±f: 
Program: zapata_m6h

def retrieve_and_rerank_parallel(query, source="faiss", method="bert", top_k=5, top_n=3):
    """
    Retrieve edilen verileri Ã§oklu iÅŸlem desteÄŸiyle re-rank eder.
    """
    try:
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_retrieve = executor.submit(retrieve_from_source, query, source, top_k)
            documents = future_retrieve.result()

            future_rerank = executor.submit(rerank_results, query, documents, method, top_n)
            ranked_documents = future_rerank.result()

        return ranked_documents

    except Exception as e:
        logging.error(f"âŒ Paralel Retrieve + Re-Ranking baÅŸarÄ±sÄ±z oldu: {str(e)}")
        return []

=== retrieve_citation_network ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def retrieve_citation_network(self, doc_id):
        """Belge iÃ§in atÄ±f aÄŸÄ±nÄ± oluÅŸturur."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT citation FROM citations WHERE doc_id = ?", (doc_id,))
            references = cursor.fetchall()
            if references:
                citation_network = []
                for ref in references:
                    citation_network.append(json.loads(ref[0]))
                self.logger.info(f"âœ… {len(citation_network)} atÄ±f aÄŸÄ± dÃ¼ÄŸÃ¼mÃ¼ oluÅŸturuldu.")
                return citation_network
            else:
                self.logger.warning(f"âš ï¸ AtÄ±f aÄŸÄ± verisi bulunamadÄ±: {doc_id}")
                return None
        except Exception as e:
            self.logger.error(f"âŒ AtÄ±f aÄŸÄ± oluÅŸturma hatasÄ±: {e}")
            return None

=== retrieve_data ===
ModÃ¼l: rag_pipeline
SÄ±nÄ±f: RAGPipeline
Program: zapata_m6h

    def retrieve_data(self, query):
        """Retrieve ve FAISS Ã¼zerinden veri Ã§eker."""
        retrieve_results = self.retriever.send_query(query)
        faiss_results, _ = self.faiss.search_similar(query, top_k=5)

        combined_results = retrieve_results + faiss_results
        self.logger.info(f"âœ… Retrieve ve FAISS sonuÃ§larÄ± birleÅŸtirildi: {combined_results}")
        return combined_results

=== retrieve_document ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def retrieve_document(self, doc_id):
        """Belgeyi SQLite veritabanÄ±ndan alÄ±r."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                SELECT * FROM documents WHERE id = ?
            """,
                (doc_id,),
            )
            row = cursor.fetchone()
            if row:
                self.logger.info(f"âœ… Belge SQLite'ten alÄ±ndÄ±: {doc_id}")
                return {
                    "id": row[0],
                    "title": row[1],
                    "authors": row[2],
                    "abstract": row[3],
                    "content": row[4],
                    "metadata": json.loads(row[5]),
                }
            else:
                self.logger.warning(f"âš ï¸ Belge SQLite'te bulunamadÄ±: {doc_id}")
                return None
        except sqlite3.Error as e:
            self.logger.error(f"âŒ Belge alÄ±nÄ±rken hata oluÅŸtu: {e}")
            return None

=== retrieve_documents_api ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def retrieve_documents_api():
    data = request.json
    query = data.get("query", "")
    if not query:
        return jsonify({"error": "Sorgu metni belirtilmedi."}), 400

    results = retrieve_documents(query)
    return jsonify({"results": results}), 200

=== retrieve_embedding ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def retrieve_embedding(self, key):
        """Redisâ€™ten embedding verisini Ã§eker (pickle ile)."""
        try:
            data = self.client.get(key)
            if data:
                self.logger.info(f"âœ… Redisâ€™ten embedding alÄ±ndÄ±: {key}")
                return pickle.loads(data)
            self.logger.warning(f"âš ï¸ Redisâ€™te embedding bulunamadÄ±: {key}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Embedding alma hatasÄ±: {e}")
            return None

=== retrieve_from_source ===
ModÃ¼l: retrieve_with_reranking
SÄ±nÄ±f: 
Program: zapata_m6h

def retrieve_from_source(query, source="faiss", top_k=5):
    """
    FAISS veya ChromaDB Ã¼zerinden veri retrieve eder.
    :param query: KullanÄ±cÄ±nÄ±n sorgusu
    :param source: "faiss" veya "chroma" (veri kaynaÄŸÄ±)
    :param top_k: DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
    :return: Retrieve edilen belgeler listesi
    """
    try:
        if source == "faiss":
            return faiss_search(query, top_k=top_k)
        elif source == "chroma":
            return chroma_search(query, top_k=top_k)
        else:
            logging.error(f"âŒ GeÃ§ersiz veri kaynaÄŸÄ±: {source}")
            return []
    except Exception as e:
        logging.error(f"âŒ Retrieve iÅŸlemi baÅŸarÄ±sÄ±z oldu: {str(e)}")
        return []

=== retrieve_logs ===
ModÃ¼l: error_logging
SÄ±nÄ±f: ErrorLogger
Program: zapata_m6h

    def retrieve_logs(self, log_type="sqlite"):
        """
        KayÄ±tlÄ± hatalarÄ± SQLite, JSON veya TXT formatÄ±ndan Ã§eker.
        """
        if log_type == "sqlite":
            try:
                conn = sqlite3.connect(self.sqlite_db_path)
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM error_logs ORDER BY timestamp DESC")
                logs = cursor.fetchall()
                conn.close()
                return logs
            except Exception as e:
                logging.error(f"SQLite hata loglarÄ± alÄ±nÄ±rken hata: {e}")
                return []

        elif log_type == "json":
            try:
                with open(self.json_log_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"JSON hata loglarÄ± okunurken hata: {e}")
                return []

        elif log_type == "txt":
            try:
                with open(self.log_file, "r", encoding="utf-8") as f:
                    return f.readlines()
            except Exception as e:
                logging.error(f"TXT hata loglarÄ± okunurken hata: {e}")
                return []

        return []

=== retrieve_mapping ===
ModÃ¼l: layout_analysis
SÄ±nÄ±f: LayoutAnalyzer
Program: zapata_m6h

    def retrieve_mapping(self, doc_id):
        """Redis veya SQLite'den yapÄ±sal haritalamayÄ± getirir."""
        mapping = self.redis_cache.get_cached_map(doc_id, "layout_mapping")
        if mapping:
            self.logger.info(f"âœ… Redis'ten getirildi: {doc_id}")
            return mapping

        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT mapping FROM layout_mapping WHERE doc_id = ?", (doc_id,))
            result = cursor.fetchone()
            if result:
                self.logger.info(f"âœ… SQLite'ten getirildi: {doc_id}")
                return json.loads(result[0])
        except sqlite3.Error as e:
            self.logger.error(f"âŒ VeritabanÄ±ndan veri Ã§ekme hatasÄ±: {e}")

        self.logger.warning(f"âš ï¸ {doc_id} iÃ§in yapÄ±sal haritalama verisi bulunamadÄ±.")
        return None

=== retrieve_mapping ===
ModÃ¼l: scientific_mapping
SÄ±nÄ±f: ScientificMapper
Program: zapata_m6h

    def retrieve_mapping(self, doc_id):
        """Redis veya SQLite'den bilimsel haritalamayÄ± getirir."""
        mapping = self.redis_cache.get_cached_map(doc_id, "scientific_mapping")
        if mapping:
            self.logger.info(f"âœ… Redis'ten getirildi: {doc_id}")
            return mapping

        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT mapping FROM scientific_mapping WHERE doc_id = ?", (doc_id,))
            result = cursor.fetchone()
            if result:
                self.logger.info(f"âœ… SQLite'ten getirildi: {doc_id}")
                return json.loads(result[0])
        except sqlite3.Error as e:
            self.logger.error(f"âŒ VeritabanÄ±ndan veri Ã§ekme hatasÄ±: {e}")

        self.logger.warning(f"âš ï¸ {doc_id} iÃ§in bilimsel haritalama verisi bulunamadÄ±.")
        return None

=== retry_failed_tasks ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def retry_failed_tasks(self, max_attempts=3):
        """
        BaÅŸarÄ±sÄ±z olan gÃ¶revleri tekrar kuyruÄŸa ekler.
        """
        for attempt in range(max_attempts):
            task = self.dequeue_task()
            if task:
                try:
                    self.process_task(task)
                    logging.info(f"âœ… Yeniden iÅŸlem baÅŸarÄ±lÄ±: {task}")
                except Exception as e:
                    logging.error(f"âŒ Yeniden iÅŸlem hatasÄ±: {e}")
                    self.enqueue_task(task)  # BaÅŸarÄ±sÄ±z olursa tekrar kuyruÄŸa ekle
            else:
                logging.info("ğŸ“Œ Bekleyen hata iÅŸlemi bulunamadÄ±.")

=== retry_failed_tasks ===
ModÃ¼l: redisqueue
SÄ±nÄ±f: RedisQueue
Program: zapata_m6h

    def retry_failed_tasks(self):
        """BaÅŸarÄ±sÄ±z gÃ¶revleri tekrar kuyruÄŸa ekler."""
        MAX_RETRY = int(config.get_env_variable("MAX_TASK_RETRY", 3))
        failed_tasks = self.redis_client.lrange("failed_tasks", 0, -1)

        def process_task(task_json):
            task_data = json.loads(task_json)
            retry_count = task_data.get("retry_count", 0)
            failure_reason = task_data.get("failure_reason", "Bilinmeyen hata")

            if retry_count < MAX_RETRY:
                task_data["retry_count"] += 1
                self.enqueue_task(task_data)
                self.redis_client.lrem("failed_tasks", 1, task_json)
                self.logger.info(f"ğŸ”„ GÃ¶rev tekrar kuyruÄŸa alÄ±ndÄ±: {task_data}")
            else:
                self.logger.error(f"âŒ GÃ¶rev {MAX_RETRY} kez denendi ve baÅŸarÄ±sÄ±z oldu: {task_data}")
                self.save_failure_reason(task_data["task_id"], failure_reason)
                self.redis_client.rpush("permanently_failed_tasks", task_json)

        threads = [threading.Thread(target=process_task, args=(task,)) for task in failed_tasks]
        for t in threads:
            t.start()
        for t in threads:
            t.join()

=== run_console_mode ===
ModÃ¼l: main
SÄ±nÄ±f: ZapataM6H
Program: zapata_m6h

    def run_console_mode(self, query):
        """Konsol Ã¼zerinden Ã§alÄ±ÅŸtÄ±rma modu"""
        self.logger.info("âœ… Konsol Modu BaÅŸlatÄ±ldÄ±.")
        retrieve_results = self.retriever.send_query(query)
        faiss_results, _ = self.faiss.search_similar(query, top_k=5)
        rag_results = self.rag_pipeline.generate_response(query)

        reranked_results = self.reranker.rerank_results(query, retrieve_results, faiss_results)

        print("\nğŸ“„ Retrieve SonuÃ§larÄ±:", retrieve_results)
        print("ğŸ“„ FAISS SonuÃ§larÄ±:", faiss_results)
        print("ğŸ“„ RAG YanÄ±tÄ±:", rag_results)
        print("ğŸ“„ Yeniden SÄ±ralanmÄ±ÅŸ SonuÃ§lar:", reranked_results)

=== run_gui ===
ModÃ¼l: guimindmap
SÄ±nÄ±f: 
Program: zapata_m6h

def run_gui():
    root = tk.Tk()
    app = MindMapGUI(root)
    root.mainloop()

=== run_gui_mode ===
ModÃ¼l: main
SÄ±nÄ±f: ZapataM6H
Program: zapata_m6h

    def run_gui_mode(self):
        """GUI Ã¼zerinden Ã§alÄ±ÅŸtÄ±rma modu"""
        self.logger.info("âœ… GUI Modu BaÅŸlatÄ±ldÄ±.")
        root = ctk.CTk()
        app = ZapataGUI(root)
        root.mainloop()

=== run_multiprocessing ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def run_multiprocessing(self):
        """
        Paralel iÅŸlemcilerle gÃ¶revleri Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            while True:
                task = self.dequeue_task()
                if task:
                    executor.submit(self.process_task, task)
                else:
                    time.sleep(1)

=== run_search ===
ModÃ¼l: guimodule
SÄ±nÄ±f: ZapataGUI
Program: zapata_m6h

    def run_search(self):
        """Retrieve ve FAISS aramasÄ± yapar."""
        query = self.query_entry.get()
        if not query:
            self.logger.warning("âš ï¸ LÃ¼tfen bir sorgu girin.")
            return

        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", "Arama yapÄ±lÄ±yor...\n")

        threading.Thread(target=self.perform_search, args=(query,)).start()

=== run_threading ===
ModÃ¼l: process_manager
SÄ±nÄ±f: ProcessManager
Program: zapata_m6h

    def run_threading(self):
        """
        Paralel threading ile gÃ¶revleri Ã§alÄ±ÅŸtÄ±rÄ±r.
        """
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            while True:
                task = self.dequeue_task()
                if task:
                    executor.submit(self.process_task, task)
                else:
                    time.sleep(1)

=== run_training ===
ModÃ¼l: training_monitor
SÄ±nÄ±f: TrainingMonitor
Program: zapata_m6h

    def run_training(self):
        """EÄŸitim ilerlemesini simÃ¼le eder ve GUI'yi gÃ¼nceller."""
        num_epochs = 10  # Ã–rnek epoch sayÄ±sÄ±
        for epoch in range(1, num_epochs + 1):
            time.sleep(2)  # EÄŸitimi simÃ¼le etmek iÃ§in bekleme sÃ¼resi
            progress = epoch / num_epochs
            self.progress_bar.set(progress)
            self.status_label.configure(text=f"Epoch {epoch}/{num_epochs} - Ä°lerleme: %{int(progress * 100)}")
            self.logger.info(f"âœ… Epoch {epoch} tamamlandÄ±. Ä°lerleme: %{int(progress * 100)}")

        self.status_label.configure(text="âœ… EÄŸitim TamamlandÄ±!")
        self.logger.info("ğŸš€ EÄŸitim baÅŸarÄ±yla tamamlandÄ±.")

=== run_training_monitor ===
ModÃ¼l: main
SÄ±nÄ±f: ZapataM6H
Program: zapata_m6h

    def run_training_monitor(self):
        """EÄŸitim monitÃ¶rÃ¼nÃ¼ baÅŸlatÄ±r."""
        self.logger.info("âœ… EÄŸitim MonitÃ¶rÃ¼ BaÅŸlatÄ±ldÄ±.")
        root = ctk.CTk()
        monitor = TrainingMonitor(root)
        root.mainloop()

=== save_citation_map_to_chromadb ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_chromadb(self, doc_id, citation_map, text):
        """AtÄ±f haritasÄ±nÄ± ChromaDB'ye kaydeder."""
        self.logger.info(f"ğŸ’¾ AtÄ±f haritasÄ± ChromaDB'ye kaydediliyor: {doc_id}")

        try:
            collection = self.chroma_client.get_or_create_collection(name="citation_mappings")
            for citation, reference in citation_map.items():
                collection.add(
                    ids=[f"{doc_id}_{citation}"],
                    metadatas=[
                        {"doc_id": doc_id, "citation": citation, "reference": reference, "text_parametre": text}
                    ],
                )
            self.logger.info("âœ… AtÄ±f haritasÄ± ChromaDB'ye baÅŸarÄ±yla kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ ChromaDB'ye kayÄ±t baÅŸarÄ±sÄ±z: {str(e)}")

=== save_citation_map_to_json ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_json(self, doc_id, citation_map, text):
        """AtÄ±f haritasÄ±nÄ± JSON dosyasÄ±na kaydeder."""
        self.logger.info(f"ğŸ’¾ AtÄ±f haritasÄ± JSON dosyasÄ±na kaydediliyor: {doc_id}")

        try:
            json_data = {
                citation: {"reference": reference, "text_parametre": text}
                for citation, reference in citation_map.items()
            }
            with open(f"{config.CHROMA_DB_PATH}/{doc_id}_citations.json", "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=4)
            self.logger.info("âœ… AtÄ±f haritasÄ± JSON'a baÅŸarÄ±yla kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ JSON'a kayÄ±t baÅŸarÄ±sÄ±z: {str(e)}")

=== save_citation_map_to_redis ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_redis(self, doc_id, citation_map, text):
        """AtÄ±f haritasÄ±nÄ± Redis'e kaydeder."""
        self.logger.info(f"ğŸ’¾ AtÄ±f haritasÄ± Redis'e kaydediliyor: {doc_id}")

        try:
            redis_data = {
                citation: {"reference": reference, "text_parametre": text}
                for citation, reference in citation_map.items()
            }
            self.redis_client.set(f"citations:{doc_id}", json.dumps(redis_data))
            self.logger.info("âœ… AtÄ±f haritasÄ± Redis'e baÅŸarÄ±yla kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ Redis'e kayÄ±t baÅŸarÄ±sÄ±z: {str(e)}")

=== save_citation_map_to_sqlite ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_sqlite(self, doc_id, citation_map, text):
        """AtÄ±f haritasÄ±nÄ± SQLite veritabanÄ±na kaydeder."""
        self.logger.info(f"ğŸ’¾ AtÄ±f haritasÄ± SQLite veritabanÄ±na kaydediliyor: {self.db_path}")

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS citations (
                    doc_id TEXT,
                    citation TEXT,
                    reference TEXT,
                    text_parametre TEXT
                )
            """
            )

            for citation, reference in citation_map.items():
                cursor.execute(
                    "INSERT INTO citations (doc_id, citation, reference, text_parametre) VALUES (?, ?, ?, ?)",
                    (doc_id, citation, reference, text),
                )

            conn.commit()
            conn.close()
            self.logger.info("âœ… AtÄ±f haritasÄ± SQLite'e baÅŸarÄ±yla kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ SQLite'e kayÄ±t baÅŸarÄ±sÄ±z: {str(e)}")

=== save_clusters_to_chromadb ===
ModÃ¼l: clustering_module
SÄ±nÄ±f: ClusteringProcessor
Program: zapata_m6h

    def save_clusters_to_chromadb(self, doc_ids, cluster_labels):
        """KÃ¼meleme sonuÃ§larÄ±nÄ± ChromaDB'ye kaydeder."""
        self.logger.info(f"ğŸ’¾ KÃ¼meleme sonuÃ§larÄ± ChromaDB'ye kaydediliyor...")

        collection = self.chroma_client.get_or_create_collection(name="document_clusters")
        for doc_id, cluster_id in zip(doc_ids, cluster_labels):
            collection.add(ids=[doc_id], metadatas=[{"cluster_id": int(cluster_id)}])

        self.logger.info("âœ… KÃ¼meleme verileri ChromaDB'ye baÅŸarÄ±yla kaydedildi.")

=== save_clusters_to_sqlite ===
ModÃ¼l: clustering_module
SÄ±nÄ±f: ClusteringProcessor
Program: zapata_m6h

    def save_clusters_to_sqlite(self, doc_ids, cluster_labels):
        """KÃ¼meleme sonuÃ§larÄ±nÄ± SQLite veritabanÄ±na kaydeder."""
        self.logger.info(f"ğŸ’¾ KÃ¼meleme sonuÃ§larÄ± SQLite veritabanÄ±na kaydediliyor: {self.db_path}")

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS document_clusters (
                doc_id TEXT,
                cluster_id INTEGER
            )
        """
        )

        for doc_id, cluster_id in zip(doc_ids, cluster_labels):
            cursor.execute(
                "INSERT INTO document_clusters (doc_id, cluster_id) VALUES (?, ?)", (doc_id, int(cluster_id))
            )

        conn.commit()
        conn.close()
        self.logger.info("âœ… KÃ¼meleme verileri SQLite'e baÅŸarÄ±yla kaydedildi.")

=== save_embedding_to_chromadb ===
ModÃ¼l: alternativeembeddingmodule
SÄ±nÄ±f: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_chromadb(self, doc_id, embedding):
        """Embedding vektÃ¶rÃ¼nÃ¼ ChromaDB'ye kaydeder."""
        self.logger.info(f"ğŸ’¾ Alternatif embedding ChromaDB'ye kaydediliyor: {doc_id}")
        collection = self.chroma_client.get_or_create_collection(name="alt_embeddings")
        collection.add(ids=[doc_id], embeddings=[embedding.tolist()])
        self.logger.info("âœ… Alternatif embedding baÅŸarÄ±yla kaydedildi.")

=== save_embedding_to_chromadb ===
ModÃ¼l: embeddingmodule
SÄ±nÄ±f: EmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_chromadb(self, doc_id, embedding):
        """Embedding vektÃ¶rÃ¼nÃ¼ ChromaDB'ye kaydeder."""
        self.logger.info(f"ğŸ’¾ Embedding ChromaDB'ye kaydediliyor: {doc_id}")
        collection = self.chroma_client.get_or_create_collection(name="embeddings")
        collection.add(ids=[doc_id], embeddings=[embedding.tolist()])
        self.logger.info("âœ… Embedding baÅŸarÄ±yla kaydedildi.")

=== save_embedding_to_chromadb ===
ModÃ¼l: robustembeddingmodule
SÄ±nÄ±f: RobustEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_chromadb(self, doc_id, embedding):
        """Embedding vektÃ¶rÃ¼nÃ¼ ChromaDB'ye kaydeder."""
        if embedding is None:
            self.logger.error(f"âŒ {doc_id} iÃ§in geÃ§ersiz embedding, ChromaDB'ye kaydedilmedi.")
            return

        self.logger.info(f"ğŸ’¾ Embedding ChromaDB'ye kaydediliyor: {doc_id}")
        collection = self.chroma_client.get_or_create_collection(name="robust_embeddings")
        collection.add(ids=[doc_id], embeddings=[embedding.tolist()])
        self.logger.info("âœ… Embedding baÅŸarÄ±yla kaydedildi.")

=== save_embedding_to_redis ===
ModÃ¼l: alternativeembeddingmodule
SÄ±nÄ±f: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_redis(self, doc_id, embedding):
        """Embedding vektÃ¶rÃ¼nÃ¼ Redis'e kaydeder."""
        self.logger.info(f"ğŸ’¾ Alternatif embedding Redis'e kaydediliyor: {doc_id}")
        self.redis_client.set(doc_id, np.array(embedding).tobytes())
        self.logger.info("âœ… Alternatif embedding Redis'e baÅŸarÄ±yla kaydedildi.")

=== save_embedding_to_redis ===
ModÃ¼l: embeddingmodule
SÄ±nÄ±f: EmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_redis(self, doc_id, embedding):
        """Embedding vektÃ¶rÃ¼nÃ¼ Redis'e kaydeder."""
        self.logger.info(f"ğŸ’¾ Embedding Redis'e kaydediliyor: {doc_id}")
        self.redis_client.set(doc_id, np.array(embedding).tobytes())
        self.logger.info("âœ… Embedding Redis'e baÅŸarÄ±yla kaydedildi.")

=== save_embedding_to_redis ===
ModÃ¼l: robustembeddingmodule
SÄ±nÄ±f: RobustEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_redis(self, doc_id, embedding):
        """Embedding vektÃ¶rÃ¼nÃ¼ Redis'e kaydeder."""
        if embedding is None:
            self.logger.error(f"âŒ {doc_id} iÃ§in geÃ§ersiz embedding, Redis'e kaydedilmedi.")
            return

        self.logger.info(f"ğŸ’¾ Embedding Redis'e kaydediliyor: {doc_id}")
        self.redis_client.set(doc_id, np.array(embedding).tobytes())
        self.logger.info("âœ… Embedding Redis'e baÅŸarÄ±yla kaydedildi.")

=== save_json ===
ModÃ¼l: helpermodule
SÄ±nÄ±f: HelperFunctions
Program: zapata_m6h

    def save_json(self, data, file_path):
        """Veriyi JSON dosyasÄ±na kaydeder."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=4)
            self.logger.info(f"âœ… JSON dosyasÄ± kaydedildi: {file_path}")
        except Exception as e:
            self.logger.error(f"âŒ JSON kaydetme hatasÄ±: {e}")

=== save_model_to_redis ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def save_model_to_redis(self):
        """EÄŸitilmiÅŸ modeli Redis'e kaydeder"""
        with open(os.path.join(self.output_dir, "pytorch_model.bin"), "rb") as f:
            model_data = f.read()
            redis_client.set(f"fine_tuned_model:{self.model_name}", model_data)
        logging.info(f"ğŸ“Œ {self.model_name} modeli Redis'e kaydedildi.")

=== save_model_to_redis ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def save_model_to_redis(self):
        """
        EÄŸitilen modeli Redis iÃ§inde saklar.
        """
        with open(os.path.join(self.output_dir, "pytorch_model.bin"), "rb") as f:
            model_data = f.read()
            self.redis_client.set(f"fine_tuned_model_{self.model_name}", model_data)
        logger.info("ğŸ“Œ EÄŸitilmiÅŸ model Redis'e kaydedildi.")

=== save_references ===
ModÃ¼l: zoteromodule
SÄ±nÄ±f: ZoteroManager
Program: zapata_m6h

    def save_references(self, references, save_path):
        """KaynakÃ§alarÄ± JSON formatÄ±nda kaydeder."""
        import json

        self.logger.info(f"ğŸ’¾ KaynakÃ§alar {save_path} dosyasÄ±na kaydediliyor...")
        try:
            with open(save_path, "w", encoding="utf-8") as file:
                json.dump(references, file, indent=4, ensure_ascii=False)
            self.logger.info("âœ… KaynakÃ§alar baÅŸarÄ±yla kaydedildi.")
            return True
        except Exception as e:
            self.logger.error(f"âŒ KaynakÃ§a kaydetme hatasÄ±: {e}")
            return False

=== save_references_to_sqlite ===
ModÃ¼l: zotero_integration
SÄ±nÄ±f: ZoteroIntegration
Program: zapata_m6h

    def save_references_to_sqlite(self, references):
        """KaynakÃ§alarÄ± SQLite veritabanÄ±na kaydeder."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        for ref in references:
            item_id = ref["key"]
            title = ref["data"].get("title", "Bilinmiyor")
            authors = ", ".join([creator["lastName"] for creator in ref["data"].get("creators", [])])
            year = ref["data"].get("date", "Bilinmiyor")
            journal = ref["data"].get("publicationTitle", "Bilinmiyor")
            doi = ref["data"].get("DOI", None)
            file_path = ref["data"].get("filePath", None)

            cursor.execute(
                """
                INSERT OR REPLACE INTO references (id, title, authors, year, journal, doi, file_path)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (item_id, title, authors, year, journal, doi, file_path),
            )

        conn.commit()
        conn.close()
        print("âœ… Zotero kaynakÃ§alarÄ± SQLite veritabanÄ±na kaydedildi.")

=== save_to_redis ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def save_to_redis(self, text, doc_id):
        """TemizlenmiÅŸ metni Redis Ã¶nbelleÄŸine kaydeder."""
        self.redis_client.set(f"text:{doc_id}", text)

=== save_to_sqlite ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def save_to_sqlite(self, text, doc_id):
        """TemizlenmiÅŸ metni SQLite'e kaydeder."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS processed_texts (
                id TEXT PRIMARY KEY,
                text TEXT
            )
        """
        )
        cursor.execute("INSERT OR REPLACE INTO processed_texts (id, text) VALUES (?, ?)", (doc_id, text))
        conn.commit()
        conn.close()

=== search_chromadb ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def search_chromadb(self, queries, top_k=5):
        """ChromaDB Ã¼zerinde arama yapar."""
        try:
            collection = self.chroma_client.get_collection("embeddings")
            results = collection.query(query_texts=queries, n_results=top_k)
            return [(doc["id"], doc["score"]) for doc in results["documents"]]
        except Exception as e:
            self.logger.error(f"âŒ ChromaDB arama hatasÄ±: {e}")
            return []

=== search_chromadb ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def search_chromadb(self, queries, top_k=5):
        """ChromaDB Ã¼zerinde arama yapar."""
        try:
            collection = self.chroma_client.get_collection("embeddings")
            results = collection.query(query_texts=queries, n_results=top_k)
            return [(doc["id"], doc["score"]) for doc in results["documents"]]
        except Exception as e:
            self.logger.error(f"âŒ ChromaDB arama hatasÄ±: {e}")
            return []

=== search_faiss ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def search_faiss(self, queries, top_k=5):
        """FAISS Ã¼zerinden arama yapar."""
        try:
            if self.faiss_index:
                query_vec = self.encode_queries(queries)
                distances, indices = self.faiss_index.search(query_vec, top_k)
                results = [(idx, 1 - dist) for idx, dist in zip(indices[0], distances[0])]
                return results
            return []
        except Exception as e:
            self.logger.error(f"âŒ FAISS arama hatasÄ±: {e}")
            return []

=== search_faiss ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def search_faiss(self, queries, top_k=5):
        """FAISS Ã¼zerinden arama yapar."""
        try:
            if self.faiss_index:
                query_vec = self.encode_queries(queries)
                distances, indices = self.faiss_index.search(query_vec, top_k)
                results = [(idx, 1 - dist) for idx, dist in zip(indices[0], distances[0])]
                return results
            return []
        except Exception as e:
            self.logger.error(f"âŒ FAISS arama hatasÄ±: {e}")
            return []

=== search_in_chromadb ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def search_in_chromadb():
    data = request.json
    query = data.get("query", "")
    if not query:
        return jsonify({"error": "Sorgu metni belirtilmedi."}), 400

    results = search_chromadb(query)
    return jsonify({"results": results}), 200

=== search_in_faiss ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def search_in_faiss():
    data = request.json
    query = data.get("query", "")
    if not query:
        return jsonify({"error": "Sorgu metni belirtilmedi."}), 400

    results = search_faiss(query)
    return jsonify({"results": results}), 200

=== search_redis ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def search_redis(self, queries, top_k=5):
        """Redis Ã¼zerinde anahtar kelime bazlÄ± arama yapar."""
        try:
            results = self.redis.search(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ Redis arama hatasÄ±: {e}")
            return []

=== search_redis ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def search_redis(self, queries, top_k=5):
        """Redis Ã¼zerinde anahtar kelime bazlÄ± arama yapar."""
        try:
            results = self.redis.search(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ Redis arama hatasÄ±: {e}")
            return []

=== search_retrieve ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def search_retrieve(self, queries, top_k=5):
        """Retrieve API kullanarak arama yapar."""
        try:
            results = self.retrieve_engine.retrieve_documents(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ Retrieve arama hatasÄ±: {e}")
            return []

=== search_similar ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def search_similar(self, query_embedding, top_k=5):
        """Verilen embedding iÃ§in FAISS Ã¼zerinde en benzer vektÃ¶rleri arar."""
        try:
            query_embedding = np.array(query_embedding, dtype=np.float32).reshape(1, -1)
            distances, indices = self.index.search(query_embedding, top_k)

            self.logger.info(f"ğŸ” FAISS arama tamamlandÄ±. En yakÄ±n {top_k} sonuÃ§ dÃ¶ndÃ¼.")
            return indices.tolist(), distances.tolist()
        except Exception as e:
            self.logger.error(f"âŒ FAISS arama hatasÄ±: {e}")
            return None, None

=== search_sqlite ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def search_sqlite(self, queries, top_k=5):
        """SQLite Ã¼zerinde tam metin arama yapar."""
        try:
            results = self.sqlite.search_full_text(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ SQLite arama hatasÄ±: {e}")
            return []

=== search_sqlite ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def search_sqlite(self, queries, top_k=5):
        """SQLite Ã¼zerinde tam metin arama yapar."""
        try:
            results = self.sqlite.search_full_text(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ SQLite arama hatasÄ±: {e}")
            return []

=== send_query ===
ModÃ¼l: retriever_integration
SÄ±nÄ±f: RetrieverIntegration
Program: zapata_m6h

    def send_query(self, query):
        """Retrieve API'ye sorgu gÃ¶nderir."""
        try:
            response = requests.post(f"{self.retrieve_api_url}/query", json={"query": query})
            response.raise_for_status()
            self.logger.info(f"âœ… Retrieve sorgusu baÅŸarÄ±yla gÃ¶nderildi: {query}")
            return response.json()
        except requests.RequestException as e:
            self.logger.error(f"âŒ Retrieve API hatasÄ±: {e}")
            return None

=== send_to_zapata ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def send_to_zapata(self, item_id):
        """
        Zotero'dan belirli bir makaleyi alÄ±p Zapata'ya gÃ¶nderir.
        """
        try:
            item = self.zot.item(item_id)
            data = {
                "title": item["data"]["title"],
                "abstract": item["data"].get("abstractNote", ""),
                "authors": item["data"].get("creators", []),
                "publication": item["data"].get("publicationTitle", ""),
                "year": item["data"].get("date", ""),
                "doi": item["data"].get("DOI", ""),
                "pdf_path": item["data"].get("attachments", []),
            }

            response = requests.post(f"{self.zapata_api_url}/analyze", json=data)
            if response.status_code == 200:
                print(f"âœ… {item['data']['title']} baÅŸarÄ±yla Zapata'ya gÃ¶nderildi.")
            else:
                print(f"âŒ Zapata'ya gÃ¶nderirken hata oluÅŸtu: {response.text}")
        except Exception as e:
            print(f"âŒ Zotero'dan Zapata'ya veri gÃ¶nderirken hata oluÅŸtu: {e}")

=== setUpClass ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def setUpClass(cls):
        """
        Test Ã¶ncesi gerekli kurulumlarÄ± yapar.
        """
        cls.error_logger = ErrorLogger()
        cls.process_manager = ProcessManager()
        cls.fine_tuner = FineTuner()
        cls.test_log_file = os.path.join(config.LOG_DIR, "test_results.json")
        cls.sqlite_db_path = config.SQLITE_DB_PATH

        logging.basicConfig(
            filename=os.path.join(config.LOG_DIR, "test_log.txt"),
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

=== setup_logging ===
ModÃ¼l: alternativeembeddingmodule
SÄ±nÄ±f: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("alternative_embedding_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: veri_isleme
SÄ±nÄ±f: CitationAnalyzer
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("veri_isleme.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: citationmappingmodule
SÄ±nÄ±f: CitationMapper
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar (colorlog ile konsol ve dosya loglamasÄ±)."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("citation_mapping.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: clustering_module
SÄ±nÄ±f: ClusteringProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("clustering.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: configmodule
SÄ±nÄ±f: Config
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("pdf_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(getattr(logging, self.LOG_LEVEL.upper(), logging.DEBUG))
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)

=== setup_logging ===
ModÃ¼l: veri_gorsellestirme
SÄ±nÄ±f: DataVisualizer
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("veri_gorsellestirme.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: document_parser
SÄ±nÄ±f: DocumentParser
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("document_parser.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: embeddingmodule
SÄ±nÄ±f: EmbeddingProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("embedding_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("faiss_integration.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: fetch_top_k_results
SÄ±nÄ±f: FetchTopKResults
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("fetch_top_k_results.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: helpermodule
SÄ±nÄ±f: HelperFunctions
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("helpermodule.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: layout_analysis
SÄ±nÄ±f: LayoutAnalyzer
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("layout_analysis.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: multi_source_search
SÄ±nÄ±f: MultiSourceSearch
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("multi_source_search.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: pdfprocessing
SÄ±nÄ±f: PDFProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("pdf_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: query_expansion
SÄ±nÄ±f: QueryExpansion
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("query_expansion.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: rag_pipeline
SÄ±nÄ±f: RAGPipeline
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("rag_pipeline.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("rediscache.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: redisqueue
SÄ±nÄ±f: RedisQueue
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("redisqueue.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: reranking_module
SÄ±nÄ±f: RerankingModule
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("reranking_module.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: retrieval_reranker
SÄ±nÄ±f: RetrievalReranker
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("retrieval_reranker.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: retriever_integration
SÄ±nÄ±f: RetrieverIntegration
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("retriever_integration.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: robustembeddingmodule
SÄ±nÄ±f: RobustEmbeddingProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("robust_embedding.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("sqlite_storage.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: scientific_mapping
SÄ±nÄ±f: ScientificMapper
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("scientific_mapping.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: search_engine
SÄ±nÄ±f: SearchEngine
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("search_engine.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: sync_faiss_chromadb
SÄ±nÄ±f: SyncFAISSChromaDB
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("sync_faiss_chromadb.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: training_monitor
SÄ±nÄ±f: TrainingMonitor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(console_handler)

=== setup_logging ===
ModÃ¼l: guimodule
SÄ±nÄ±f: ZapataGUI
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(console_handler)

=== setup_logging ===
ModÃ¼l: main
SÄ±nÄ±f: ZapataM6H
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("zapata_m6h.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
ModÃ¼l: zoteromodule
SÄ±nÄ±f: ZoteroManager
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("zotero_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== show_mindmap ===
ModÃ¼l: d3js_visualizer
SÄ±nÄ±f: D3Visualizer
Program: zapata_m6h

    def show_mindmap(self, json_data):
        """
        Zihin haritasÄ±nÄ± oluÅŸturup varsayÄ±lan tarayÄ±cÄ±da aÃ§ar.
        """
        html_file = self.generate_html(json_data)
        webbrowser.open("file://" + html_file)

=== split_text ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def split_text(self, text, method="paragraph"):
        """Metni cÃ¼mle bazlÄ± veya paragraf bazlÄ± ayÄ±rÄ±r."""
        if method == "sentence":
            return sent_tokenize(text)
        elif method == "paragraph":
            return text.split("\n\n")  # Ã‡ift newline karakteriyle paragraf bÃ¶lme
        return [text]

=== start_training ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def start_training():
    data = request.json
    models = data.get("models", [])
    if not models:
        return jsonify({"error": "EÄŸitim iÃ§in model seÃ§ilmedi."}), 400

    thread = threading.Thread(target=train_selected_models, args=(models,))
    thread.start()

    logging.info(f"ğŸ“Œ EÄŸitim baÅŸlatÄ±ldÄ±: {models}")
    return jsonify({"status": "EÄŸitim baÅŸlatÄ±ldÄ±.", "models": models}), 200

=== start_training ===
ModÃ¼l: training_monitor
SÄ±nÄ±f: TrainingMonitor
Program: zapata_m6h

    def start_training(self):
        """EÄŸitim sÃ¼recini baÅŸlatÄ±r."""
        self.status_label.configure(text="EÄŸitim BaÅŸlatÄ±ldÄ±...")
        self.progress_bar.set(0)

        threading.Thread(target=self.run_training).start()

=== stem_words ===
ModÃ¼l: text_processing
SÄ±nÄ±f: TextProcessor
Program: zapata_m6h

    def stem_words(self, text):
        """Kelime kÃ¶klerine ayÄ±rma iÅŸlemi (Stemming)."""
        from nltk.stem import PorterStemmer

        stemmer = PorterStemmer()
        words = word_tokenize(text)
        stemmed_words = [stemmer.stem(word) for word in words]
        return " ".join(stemmed_words)

=== stop_training ===
ModÃ¼l: rest_api
SÄ±nÄ±f: 
Program: zapata_m6h

def stop_training():
    redis_client.set("training_status", "Durduruldu")
    logging.info("ğŸ“Œ Model eÄŸitimi durduruldu.")
    return jsonify({"status": "EÄŸitim sÃ¼reci durduruldu."}), 200

=== store_citation ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def store_citation(self, doc_id, citation):
        """KaynakÃ§ayÄ± SQLite veritabanÄ±na kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO citations (doc_id, citation) 
                VALUES (?, ?)
            """,
                (doc_id, json.dumps(citation)),
            )
            self.connection.commit()
            self.logger.info(f"âœ… Citation SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ Citation SQLite'e kaydedilemedi: {e}")

=== store_document ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def store_document(self, doc_id, title, authors, abstract, content, metadata):
        """Belgeyi SQLite veritabanÄ±na kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO documents (id, title, authors, abstract, content, metadata) 
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (doc_id, title, authors, abstract, content, json.dumps(metadata)),
            )
            self.connection.commit()
            self.logger.info(f"âœ… Belge SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ Belge SQLite'e kaydedilemedi: {e}")

=== store_embedding ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def store_embedding(self, key, embedding, ttl=None):
        """Embedding vektÃ¶rÃ¼nÃ¼ Redisâ€™e kaydeder (pickle ile)."""
        try:
            serialized = pickle.dumps(embedding)
            if ttl:
                self.client.setex(key, ttl, serialized)
            else:
                self.client.set(key, serialized)
            self.logger.info(f"âœ… {key} iÃ§in embedding Redisâ€™e kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ Embedding kaydetme hatasÄ±: {e}")

=== store_embedding ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def store_embedding(self, doc_id, embedding):
        """Embedding verisini SQLite veritabanÄ±na kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO embeddings (doc_id, embedding) 
                VALUES (?, ?)
            """,
                (doc_id, json.dumps(embedding)),
            )
            self.connection.commit()
            self.logger.info(f"âœ… Embedding SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ Embedding SQLite'e kaydedilemedi: {e}")

=== store_embedding_to_db ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def store_embedding_to_db(self, doc_id, embedding):
        """Embedding verisini SQLite veritabanÄ±na kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                "INSERT INTO faiss_embeddings (doc_id, embedding) VALUES (?, ?)", (doc_id, json.dumps(embedding))
            )
            self.connection.commit()
            self.logger.info(f"âœ… {doc_id} iÃ§in embedding SQLite'e kaydedildi.")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite embedding kaydetme hatasÄ±: {e}")

=== store_mapping_to_db ===
ModÃ¼l: layout_analysis
SÄ±nÄ±f: LayoutAnalyzer
Program: zapata_m6h

    def store_mapping_to_db(self, doc_id, mapped_layout):
        """YapÄ±sal haritalamayÄ± SQLite'e kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                "INSERT INTO layout_mapping (doc_id, mapping) VALUES (?, ?)", (doc_id, json.dumps(mapped_layout))
            )
            self.connection.commit()
            self.logger.info(f"âœ… {doc_id} iÃ§in yapÄ±sal haritalama SQLite'e kaydedildi.")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite'e kaydetme hatasÄ±: {e}")

=== store_mapping_to_db ===
ModÃ¼l: scientific_mapping
SÄ±nÄ±f: ScientificMapper
Program: zapata_m6h

    def store_mapping_to_db(self, doc_id, structured_sections):
        """Bilimsel haritalamayÄ± SQLite'e kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                "INSERT INTO scientific_mapping (doc_id, mapping) VALUES (?, ?)",
                (doc_id, json.dumps(structured_sections)),
            )
            self.connection.commit()
            self.logger.info(f"âœ… {doc_id} iÃ§in bilimsel haritalama SQLite'e kaydedildi.")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ SQLite'e kaydetme hatasÄ±: {e}")

=== store_query_result ===
ModÃ¼l: rediscache
SÄ±nÄ±f: RedisCache
Program: zapata_m6h

    def store_query_result(self, query, result, ttl=3600):
        """Sorgu sonuÃ§larÄ±nÄ± Redisâ€™e kaydeder."""
        try:
            self.redis_client_str.setex(query, ttl, json.dumps(result))
            self.logger.info(f"âœ… {query} iÃ§in sorgu sonucu Redisâ€™e kaydedildi.")
        except Exception as e:
            self.logger.error(f"âŒ Sorgu sonucu kaydetme hatasÄ±: {e}")

=== store_scientific_map ===
ModÃ¼l: sqlite_storage
SÄ±nÄ±f: SQLiteStorage
Program: zapata_m6h

    def store_scientific_map(self, doc_id, map_data):
        """Bilimsel haritalama verisini SQLite veritabanÄ±na kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO scientific_maps (doc_id, map_data) 
                VALUES (?, ?)
            """,
                (doc_id, json.dumps(map_data)),
            )
            self.connection.commit()
            self.logger.info(f"âœ… Bilimsel haritalama SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"âŒ Bilimsel haritalama SQLite'e kaydedilemedi: {e}")

=== sync_from_chromadb_to_faiss ===
ModÃ¼l: sync_faiss_chromadb
SÄ±nÄ±f: SyncFAISSChromaDB
Program: zapata_m6h

    def sync_from_chromadb_to_faiss(self):
        """ChromaDBâ€™de olup FAISSâ€™te olmayan embeddingâ€™leri FAISSâ€™e ekler."""
        try:
            chroma_embeddings = self.chroma_collection.get()
            if not chroma_embeddings:
                self.logger.warning("âš ï¸ ChromaDBâ€™de senkronize edilecek embedding bulunamadÄ±.")
                return

            faiss_existing_ids = self.redis.get_all_faiss_ids()
            new_embeddings = []
            new_ids = []

            for doc in chroma_embeddings["documents"]:
                doc_id = doc["id"]
                embedding = np.array(doc["embedding"], dtype=np.float32)

                if doc_id not in faiss_existing_ids:
                    new_embeddings.append(embedding)
                    new_ids.append(int(doc_id))

            if new_embeddings:
                self.faiss_index.add_with_ids(np.array(new_embeddings), np.array(new_ids))
                faiss.write_index(self.faiss_index, "faiss_index.idx")
                self.redis.store_faiss_ids(new_ids)
                self.logger.info(f"âœ… {len(new_embeddings)} yeni embedding FAISS'e eklendi.")
            else:
                self.logger.info("âœ… FAISS zaten gÃ¼ncel, yeni embedding eklenmedi.")

        except Exception as e:
            self.logger.error(f"âŒ FAISS senkronizasyon hatasÄ±: {e}")

=== sync_from_faiss_to_chromadb ===
ModÃ¼l: sync_faiss_chromadb
SÄ±nÄ±f: SyncFAISSChromaDB
Program: zapata_m6h

    def sync_from_faiss_to_chromadb(self):
        """FAISSâ€™te olup ChromaDBâ€™de olmayan embeddingâ€™leri ChromaDBâ€™ye ekler."""
        try:
            faiss_existing_ids = self.redis.get_all_faiss_ids()
            chroma_existing_ids = self.chroma_collection.get()["ids"]

            missing_in_chroma = set(faiss_existing_ids) - set(chroma_existing_ids)
            if not missing_in_chroma:
                self.logger.info("âœ… ChromaDB zaten gÃ¼ncel, FAISS'ten eksik veri yok.")
                return

            embeddings_to_add = []
            for doc_id in missing_in_chroma:
                embedding_vector = self.faiss_index.reconstruct(int(doc_id))
                embeddings_to_add.append({"id": str(doc_id), "embedding": embedding_vector.tolist()})

            self.chroma_collection.add(embeddings_to_add)
            self.logger.info(f"âœ… {len(embeddings_to_add)} embedding ChromaDB'ye eklendi.")

        except Exception as e:
            self.logger.error(f"âŒ ChromaDB senkronizasyon hatasÄ±: {e}")

=== sync_with_chromadb ===
ModÃ¼l: faiss_integration
SÄ±nÄ±f: FAISSIntegration
Program: zapata_m6h

    def sync_with_chromadb(self, chroma_embeddings):
        """FAISS indeksini ChromaDB'den alÄ±nan verilerle senkronize eder."""
        try:
            for doc_id, embedding in chroma_embeddings.items():
                self.add_embedding(doc_id, embedding)
            self.logger.info("âœ… FAISS ile ChromaDB senkronizasyonu tamamlandÄ±.")
        except Exception as e:
            self.logger.error(f"âŒ FAISS-ChromaDB senkronizasyon hatasÄ±: {e}")

=== sync_with_zapata ===
ModÃ¼l: zotero_extension
SÄ±nÄ±f: ZoteroExtension
Program: zapata_m6h

    def sync_with_zapata(self):
        """
        Zotero'daki tÃ¼m referanslarÄ± Zapata ile senkronize eder.
        """
        try:
            references = self.fetch_all_references()
            for ref in references:
                self.send_to_zapata(ref["key"])
        except Exception as e:
            print(f"âŒ Zotero senkronizasyonunda hata oluÅŸtu: {e}")

=== tearDownClass ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def tearDownClass(cls):
        """
        Testler tamamlandÄ±ktan sonra yapÄ±lacak iÅŸlemler.
        """
        print("âœ… TÃ¼m testler tamamlandÄ±.")

=== test_citation_mapping ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def test_citation_mapping(self):
        """
        Metin iÃ§i atÄ±f analizinin dÃ¼zgÃ¼n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test eder.
        """
        try:
            test_text = "Bu bir test cÃ¼mlesidir [1]."
            references = ["Kaynak 1"]
            mapped = map_citations_to_references(test_text, references)
            self.assertTrue("[1]" in mapped)
            self.log_test_result("test_citation_mapping", "PASS")
        except Exception as e:
            self.log_test_result("test_citation_mapping", "FAIL", str(e))
            self.fail(f"AtÄ±f eÅŸleme testi baÅŸarÄ±sÄ±z oldu: {e}")

=== test_error_logging ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def test_error_logging(self):
        """
        Hata loglama sisteminin dÃ¼zgÃ¼n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test eder.
        """
        try:
            self.error_logger.log_error(
                "Test hatasÄ±", "ERROR", "test_module", "test_function", "DetaylÄ± hata aÃ§Ä±klamasÄ±"
            )
            self.log_test_result("test_error_logging", "PASS")
        except Exception as e:
            self.log_test_result("test_error_logging", "FAIL", str(e))
            self.fail(f"Hata loglama testi baÅŸarÄ±sÄ±z oldu: {e}")

=== test_fetch_results ===
ModÃ¼l: fetch_top_k_results
SÄ±nÄ±f: FetchTopKResults
Program: zapata_m6h

    def test_fetch_results(self):
        """Otomatik test mekanizmasÄ±"""
        test_queries = [
            "Bilimsel makale analizleri",
            "Makine Ã¶ÄŸrenmesi modelleri",
            "DoÄŸal dil iÅŸleme teknikleri",
            "Veri madenciliÄŸi algoritmalarÄ±",
            "Hata loglama sistemleri",
        ]

        for query in test_queries:
            self.logger.info(f"ğŸ›  Test ediliyor: {query}")
            results = self.fetch_results(query)
            if results:
                self.logger.info(f"âœ… Test baÅŸarÄ±lÄ±: {len(results)} sonuÃ§ bulundu.")
            else:
                self.logger.warning(f"âš ï¸ Test baÅŸarÄ±sÄ±z: SonuÃ§ bulunamadÄ±.")

=== test_fine_tuning ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def test_fine_tuning(self):
        """
        Fine-tuning modelinin baÅŸlatÄ±labilir olup olmadÄ±ÄŸÄ±nÄ± test eder.
        """
        try:
            texts, labels = self.fine_tuner.fetch_training_data()
            self.assertIsInstance(texts, list)
            self.assertIsInstance(labels, list)
            self.log_test_result("test_fine_tuning", "PASS")
        except Exception as e:
            self.log_test_result("test_fine_tuning", "FAIL", str(e))
            self.fail(f"Fine-tuning testi baÅŸarÄ±sÄ±z oldu: {e}")

=== test_pdf_processing ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def test_pdf_processing(self):
        """
        PDF'den metin Ã§Ä±karma iÅŸlemini test eder.
        """
        try:
            test_pdf_path = "test_papers/sample.pdf"
            extracted_text = extract_text_from_pdf(test_pdf_path)
            self.assertTrue(isinstance(extracted_text, str) and len(extracted_text) > 0)
            self.log_test_result("test_pdf_processing", "PASS")
        except Exception as e:
            self.log_test_result("test_pdf_processing", "FAIL", str(e))
            self.fail(f"PDF iÅŸleme testi baÅŸarÄ±sÄ±z oldu: {e}")

=== test_process_manager ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def test_process_manager(self):
        """
        GÃ¶rev kuyruÄŸu yÃ¶netiminin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test eder.
        """
        try:
            self.process_manager.enqueue_task("test_task")
            task = self.process_manager.dequeue_task()
            self.assertEqual(task, "test_task")
            self.log_test_result("test_process_manager", "PASS")
        except Exception as e:
            self.log_test_result("test_process_manager", "FAIL", str(e))
            self.fail(f"Process Manager testi baÅŸarÄ±sÄ±z oldu: {e}")

=== test_save_clean_text ===
ModÃ¼l: test_suite
SÄ±nÄ±f: TestZapataModules
Program: zapata_m6h

    def test_save_clean_text(self):
        """
        Temiz metinlerin kaydedildiÄŸini test eder.
        """
        try:
            test_text = "Bu bir test metnidir."
            save_clean_text(test_text, "test_output.txt")
            self.assertTrue(os.path.exists("test_output.txt"))
            self.log_test_result("test_save_clean_text", "PASS")
        except Exception as e:
            self.log_test_result("test_save_clean_text", "FAIL", str(e))
            self.fail(f"Temiz metin kaydetme testi baÅŸarÄ±sÄ±z oldu: {e}")

=== train_model ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def train_model(self):
        """Modeli eÄŸitir ve kaydeder"""
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch",
        )

        trainer = Trainer(model=self.model, args=training_args, train_dataset=dataset, tokenizer=self.tokenizer)

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        logging.info(f"âœ… {self.model_name} modeli eÄŸitildi ve {self.output_dir} dizinine kaydedildi.")

=== train_model ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuner
Program: zapata_m6h

    def train_model(self):
        """
        Modeli fine-tune ederek eÄŸitir.
        """
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch",
        )

        trainer = Trainer(model=self.model, args=training_args, train_dataset=dataset, tokenizer=self.tokenizer)

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        logger.info(f"âœ… Model {self.model_name} eÄŸitildi ve {self.output_dir} dizinine kaydedildi.")

=== train_model ===
ModÃ¼l: yapay_zeka_finetuning
SÄ±nÄ±f: FineTuningManager
Program: zapata_m6h

    def train_model(self):
        """
        Modeli fine-tune ederek eÄŸitir.
        """
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch",
        )

        trainer = Trainer(model=self.model, args=training_args, train_dataset=dataset, tokenizer=self.tokenizer)

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        logger.info(f"âœ… Model {self.model_name} eÄŸitildi ve {self.output_dir} dizinine kaydedildi.")

=== train_selected_models ===
ModÃ¼l: FineTuning
SÄ±nÄ±f: 
Program: zapata_m6h

def train_selected_models(model_list):
    """SeÃ§ilen modelleri multiprocessing ile eÄŸitir"""
    with ProcessPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
        executor.map(parallel_finetune, model_list)

=== visualize_citation_network ===
ModÃ¼l: mindmap_visualizer
SÄ±nÄ±f: MindMapVisualizer
Program: zapata_m6h

    def visualize_citation_network(self):
        """
        Zoteroâ€™daki atÄ±f iliÅŸkilerini bir zihin haritasÄ± olarak gÃ¶rselleÅŸtirir.
        """
        graph = self.extract_citation_network()
        plt.figure(figsize=(12, 8))

        pos = nx.spring_layout(graph, seed=42)
        labels = {node: data["label"] for node, data in graph.nodes(data=True)}

        nx.draw(graph, pos, with_labels=True, node_size=3000, node_color="lightblue", edge_color="gray", font_size=10)
        nx.draw_networkx_labels(graph, pos, labels, font_size=8, font_weight="bold")

        output_path = os.path.join(self.output_folder, "citation_network.png")
        plt.savefig(output_path)
        plt.show()

        print(f"âœ… Zihin haritasÄ± oluÅŸturuldu: {output_path}")

