=== __getitem__ ===
Modül: FineTuning
Sınıf: FineTuningDataset
Program: zapata_m6h

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx], truncation=True, padding="max_length", max_length=self.max_length, return_tensors="pt"
        )
        encoding = {key: val.squeeze() for key, val in encoding.items()}
        encoding["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return encoding

=== __getitem__ ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningDataset
Program: zapata_m6h

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx], truncation=True, padding="max_length", max_length=self.max_length, return_tensors="pt"
        )
        encoding = {key: val.squeeze() for key, val in encoding.items()}
        encoding["labels"] = torch.tensor(self.labels[idx], dtype=torch.long)
        return encoding

=== __init__ ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def __init__(self, text_method="multi", table_method="multi", reference_method="advanced", debug_mode=False):
        self.text_methods = ["pdfplumber", "pymupdf", "pdfminer", "borb", "tika"]
        self.table_methods = ["pymupdf", "pdfplumber", "tabula", "camelot"]
        self.reference_methods = ["regex", "ml", "section_based"]

        self.text_method = text_method
        self.table_method = table_method
        self.reference_method = reference_method
        self.debug_mode = debug_mode

        # ML Modelleri
        self.reference_model = self._load_reference_model()
        self.layout_model = self._load_layout_model()

=== __init__ ===
Modül: alternativeembeddingmodule
Sınıf: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def __init__(self):
        """Alternatif embedding modellerini yöneten sınıf."""
        self.embedding_models = {
            "contriever": SentenceTransformer("facebook/contriever"),
            "specter": SentenceTransformer("allenai/specter"),
            "minilm": SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2"),
            "scibert": SentenceTransformer("allenai/scibert_scivocab_uncased"),
            "mpnet": SentenceTransformer("sentence-transformers/all-mpnet-base-v2"),
            "gte": SentenceTransformer("thenlper/gte-base"),
        }
        self.selected_model = self.embedding_models.get(config.EMBEDDING_MODEL, None)

        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
        self.logger = self.setup_logging()

=== __init__ ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def __init__(self):
        """Atıf zinciri analizi ve veri işleme yöneticisi."""
        self.logger = self.setup_logging()
        self.chroma_db = ChromaDB()
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

=== __init__ ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def __init__(self):
        """Atıf haritalama işlemleri için sınıf."""
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, db=4, decode_responses=True)
        self.db_path = config.SQLITE_DB_PATH
        self.logger = self.setup_logging()

=== __init__ ===
Modül: clustering_module
Sınıf: ClusteringProcessor
Program: zapata_m6h

    def __init__(self, method="kmeans", num_clusters=5):
        """Embedding tabanlı kümeleme işlemleri için sınıf."""
        self.method = method.lower()
        self.num_clusters = num_clusters
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.db_path = config.SQLITE_DB_PATH
        self.logger = self.setup_logging()

=== __init__ ===
Modül: configmodule
Sınıf: Config
Program: zapata_m6h

    def __init__(self):
        """Konfigürasyon sınıfı, tüm sistem ayarlarını yükler ve yönetir."""

        # .env dosyasını yükle
        load_dotenv()

        # 📌 Dizin Ayarları
        self.KAYNAK_DIZIN = Path(os.getenv("KAYNAK_DIZIN", r"C:\Users\mete\Zotero\zotai"))
        self.STORAGE_DIR = Path(os.getenv("STORAGE_DIR", r"C:\Users\mete\Zotero\storage"))
        self.SUCCESS_DIR = Path(os.getenv("SUCCESS_DIR", r"C:\Users\mete\Zotero\zotai"))
        self.HEDEF_DIZIN = Path(self.KAYNAK_DIZIN / "TemizMetin")
        self.TEMIZ_TABLO_DIZIN = Path(self.KAYNAK_DIZIN / "TemizTablo")
        self.TEMIZ_KAYNAKCA_DIZIN = Path(self.KAYNAK_DIZIN / "TemizKaynakca")
        self.PDF_DIR = Path(self.SUCCESS_DIR / "pdfler")
        self.EMBEDDING_PARCA_DIR = Path(self.SUCCESS_DIR / "embedingparca")
        self.CITATIONS_DIR = Path(self.SUCCESS_DIR / "citations")
        self.TABLES_DIR = Path(self.KAYNAK_DIZIN / "TemizTablo")
        self.CHROMA_DB_PATH = Path(os.getenv("CHROMA_DB_PATH", r"C:\Users\mete\Zotero\zotai\chroma_db"))

        # 📌 API Ayarları
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your_openai_api_key")
        self.ZOTERO_API_KEY = os.getenv("ZOTERO_API_KEY", "your_zotero_api_key")
        self.ZOTERO_USER_ID = os.getenv("ZOTERO_USER_ID", "your_zotero_user_id")
        self.ZOTERO_API_URL = f"https://api.zotero.org/users/{self.ZOTERO_USER_ID}/items"

        # 📌 PDF İşleme Ayarları
        self.PDF_TEXT_EXTRACTION_METHOD = os.getenv("PDF_TEXT_EXTRACTION_METHOD", "pdfplumber").lower()
        self.TABLE_EXTRACTION_METHOD = os.getenv("TABLE_EXTRACTION_METHOD", "pymupdf").lower()
        self.COLUMN_DETECTION = os.getenv("COLUMN_DETECTION", "True").lower() == "true"

        # 📌 Embedding & NLP Ayarları
        self.EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")
        self.CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "256"))
        self.PARAGRAPH_BASED_SPLIT = os.getenv("PARAGRAPH_BASED_SPLIT", "True").lower() == "true"
        self.MULTI_PROCESSING = os.getenv("MULTI_PROCESSING", "True").lower() == "true"
        self.MAX_WORKERS = int(os.getenv("MAX_WORKERS", "4"))

        # 📌 Citation Mapping & Analiz Ayarları
        self.ENABLE_CITATION_MAPPING = os.getenv("ENABLE_CITATION_MAPPING", "True").lower() == "true"
        self.ENABLE_TABLE_EXTRACTION = os.getenv("ENABLE_TABLE_EXTRACTION", "True").lower() == "true"
        self.ENABLE_CLUSTERING = os.getenv("ENABLE_CLUSTERING", "True").lower() == "true"

        # 📌 Loglama & Debug Ayarları
        self.LOG_LEVEL = os.getenv("LOG_LEVEL", "DEBUG")
        self.ENABLE_ERROR_LOGGING = os.getenv("ENABLE_ERROR_LOGGING", "True").lower() == "true"
        self.DEBUG_MODE = os.getenv("DEBUG_MODE", "False").lower() == "true"

        # 📌 Çalışma Modu Seçimi (GUI veya Konsol)
        self.RUN_MODE = os.getenv("RUN_MODE", os.getenv("runGUI", "gui")).lower()

        # 📌 Veritabanı Ayarları (SQLite & Redis)
        self.USE_SQLITE = os.getenv("USE_SQLITE", "True").lower() == "true"
        self.SQLITE_DB_PATH = Path(self.SUCCESS_DIR / "database.db")
        self.REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
        self.REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))

        # 📌 Layout Algılama Yöntemi
        self.LAYOUT_DETECTION_METHOD = os.getenv("LAYOUT_DETECTION_METHOD", "regex").lower()

        # 📌 Gerekli dizinleri oluştur
        self.ensure_directories()

        # 📌 Loglama sistemini başlat
        self.setup_logging()

        # 📌 ChromaDB bağlantısını oluştur
        self.chroma_client = chromadb.PersistentClient(path=str(self.CHROMA_DB_PATH))

        # 📌 Redis bağlantısını oluştur
        self.redis_client = redis.StrictRedis(host=self.REDIS_HOST, port=self.REDIS_PORT, decode_responses=True)

        # 📌 SQLite bağlantısını oluştur
        if self.USE_SQLITE:
            self.sqlite_connection = sqlite3.connect(str(self.SQLITE_DB_PATH))

=== __init__ ===
Modül: d3js_visualizer
Sınıf: D3Visualizer
Program: zapata_m6h

    def __init__(self):
        self.html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <script src="https://d3js.org/d3.v7.min.js"></script>
            <style>
                .node circle {
                    fill: steelblue;
                    stroke: white;
                    stroke-width: 2px;
                }
                .node text {
                    font-size: 14px;
                    fill: black;
                }
                .link {
                    fill: none;
                    stroke: #ccc;
                    stroke-width: 2px;
                }
            </style>
        </head>
        <body>
            <svg width="960" height="600"></svg>
            <script>
                var treeData = JSON.parse('%DATA%');

                var margin = {{top: 20, right: 90, bottom: 30, left: 90}},
                    width = 960 - margin.left - margin.right,
                    height = 600 - margin.top - margin.bottom;

                var svg = d3.select("svg")
                    .attr("width", width + margin.left + margin.right)
                    .attr("height", height + margin.top + margin.bottom)
                    .append("g")
                    .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

                var treeLayout = d3.tree().size([height, width]);

                var root = d3.hierarchy(treeData);
                treeLayout(root);

                var link = svg.selectAll(".link")
                    .data(root.links())
                    .enter().append("path")
                    .attr("class", "link")
                    .attr("d", d3.linkHorizontal()
                        .x(function(d) { return d.y; })
                        .y(function(d) { return d.x; }));

                var node = svg.selectAll(".node")
                    .data(root.descendants())
                    .enter().append("g")
                    .attr("class", "node")
                    .attr("transform", function(d) { return "translate(" + d.y + "," + d.x + ")"; });

                node.append("circle")
                    .attr("r", 10);

                node.append("text")
                    .attr("dy", ".35em")
                    .attr("x", function(d) { return d.children ? -13 : 13; })
                    .style("text-anchor", function(d) { return d.children ? "end" : "start"; })
                    .text(function(d) { return d.data.name; });
            </script>
        </body>
        </html>
        """

=== __init__ ===
Modül: veri_gorsellestirme
Sınıf: DataVisualizer
Program: zapata_m6h

    def __init__(self):
        """Atıf ağı ve veri görselleştirme yöneticisi."""
        self.logger = self.setup_logging()
        self.connection = self.create_db_connection()

=== __init__ ===
Modül: document_parser
Sınıf: DocumentParser
Program: zapata_m6h

    def __init__(self):
        """Döküman analiz modülünü başlatır"""
        self.logger = self.setup_logging()
        self.queue = RedisQueue()
        self.db = SQLiteStorage()
        self.layout_analyzer = LayoutAnalyzer()
        self.scientific_mapper = ScientificMapper()

=== __init__ ===
Modül: embeddingmodule
Sınıf: EmbeddingProcessor
Program: zapata_m6h

    def __init__(self):
        """Embedding işlemleri için sınıf. OpenAI veya alternatif embedding modellerini kullanır."""
        self.embedding_model = config.EMBEDDING_MODEL
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
        self.logger = self.setup_logging()

=== __init__ ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def __init__(self):
        """
        Hata loglama sistemini başlatır.
        """
        self.log_dir = config.LOG_DIR
        self.sqlite_db_path = config.SQLITE_DB_PATH
        self.log_file = os.path.join(self.log_dir, "error_logs.txt")
        self.json_log_file = os.path.join(self.log_dir, "error_logs.json")

        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)

        logging.basicConfig(
            filename=self.log_file,
            level=logging.ERROR,
            format="%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        self.init_sqlite_log_table()

=== __init__ ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def __init__(self, dimension=768):
        """FAISS Entegrasyonu"""
        self.logger = self.setup_logging()
        self.dimension = dimension  # Vektör boyutu
        self.index = faiss.IndexFlatL2(self.dimension)  # L2 mesafesiyle FAISS indeksi
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

=== __init__ ===
Modül: fetch_top_k_results
Sınıf: FetchTopKResults
Program: zapata_m6h

    def __init__(self, top_k=5):
        """En iyi K sonucu getirme modülü başlatma işlemi"""
        self.logger = self.setup_logging()
        self.search_engine = MultiSourceSearch()
        self.reranker = Reranker()
        self.top_k = top_k
        self.error_log_file = "error_logs.json"

=== __init__ ===
Modül: FineTuning
Sınıf: FineTuner
Program: zapata_m6h

    def __init__(self, model_name):
        """Fine-Tuning işlemlerini yöneten sınıf"""
        self.model_name = model_name
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name.replace("/", "_"))

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)

=== __init__ ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuner
Program: zapata_m6h

    def __init__(self, model_name):
        self.model_name = AVAILABLE_MODELS[model_name]
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR

=== __init__ ===
Modül: FineTuning
Sınıf: FineTuningDataset
Program: zapata_m6h

    def __init__(self, model_name):
        """Fine-Tuning işlemlerini yöneten sınıf"""
        self.model_name = model_name
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name.replace("/", "_"))

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)

=== __init__ ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningDataset
Program: zapata_m6h

    def __init__(self, model_name):
        self.model_name = AVAILABLE_MODELS[model_name]
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR

=== __init__ ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningManager
Program: zapata_m6h

    def __init__(self, model_name):
        self.model_name = AVAILABLE_MODELS[model_name]
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=2)
        self.output_dir = os.path.join(config.FINETUNE_OUTPUT_DIR, model_name)
        self.sqlite_db = config.SQLITE_DB_PATH
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.batch_size = config.FINETUNE_BATCH_SIZE
        self.epochs = config.FINETUNE_EPOCHS
        self.learning_rate = config.FINETUNE_LR

=== __init__ ===
Modül: helpermodule
Sınıf: HelperFunctions
Program: zapata_m6h

    def __init__(self):
        """Yardımcı fonksiyonlar sınıfı."""
        self.logger = self.setup_logging()
        self.turkish_stopwords = set(stopwords.words("turkish"))
        self.english_stopwords = set(stopwords.words("english"))

=== __init__ ===
Modül: layout_analysis
Sınıf: LayoutAnalyzer
Program: zapata_m6h

    def __init__(self):
        """Yapısal analiz yöneticisi"""
        self.logger = self.setup_logging()
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

        # Yapısal öğeleri belirlemek için regex desenleri
        self.layout_patterns = {
            "Başlık": r"^\s*[A-ZÇĞİÖŞÜ].+\s*$",
            "Alt Başlık": r"^\s*[A-ZÇĞİÖŞÜ].+\s*$",
            "Tablo": r"^\s*Tablo\s+\d+",
            "Şekil": r"^\s*Şekil\s+\d+",
            "Sayfa No": r"\bSayfa\s+\d+\b",
        }

=== __init__ ===
Modül: guimindmap
Sınıf: MindMapGUI
Program: zapata_m6h

    def __init__(self, master):
        self.master = master
        self.master.title("Zotero & Zapata Zihin Haritası")
        self.create_widgets()
        self.server = None

=== __init__ ===
Modül: Mind_Map_Visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def __init__(self, root):
        self.root = root
        self.root.title("Zihin Haritası - Zapata M6H")
        self.create_ui()

=== __init__ ===
Modül: mindmap_visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def __init__(self):
        """Zotero ile bağlantıyı kurar ve görselleştirme için gerekli dizinleri oluşturur."""
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.library_type = "user"
        self.zot = zotero.Zotero(self.user_id, self.library_type, self.api_key)
        self.output_folder = config.MINDMAP_OUTPUT_FOLDER  # Görsellerin kaydedileceği klasör

        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)

=== __init__ ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def __init__(self):
        """Çoklu kaynaklı arama motoru başlatma işlemi"""
        self.logger = self.setup_logging()
        self.sqlite = SQLiteStorage()
        self.redis = RedisQueue()
        self.chroma_client = PersistentClient(path=config.CHROMA_DB_PATH)
        self.faiss_index = self.load_faiss_index()
        self.query_expander = QueryExpansion()
        self.reranker = Reranker()
        self.retrieve_engine = RetrieveEngine()

=== __init__ ===
Modül: pdfprocessing
Sınıf: PDFProcessor
Program: zapata_m6h

    def __init__(self):
        """PDF işleme sınıfı, yapılandırma ayarlarını yükler ve log sistemini başlatır."""
        self.text_extraction_method = config.PDF_TEXT_EXTRACTION_METHOD
        self.table_extraction_method = config.TABLE_EXTRACTION_METHOD
        self.logger = self.setup_logging()

=== __init__ ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def __init__(self):
        """
        İşlem yöneticisi, Redis ve multiprocessing/threading desteği ile işlem yönetimini sağlar.
        """
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.max_workers = config.MAX_WORKERS  # .env'den max işçi sayısını al
        self.task_queue = multiprocessing.Queue()  # Yerel işlem kuyruğu
        self.log_file = "process_manager.log"

        logging.basicConfig(
            filename=self.log_file,
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

=== __init__ ===
Modül: query_expansion
Sınıf: QueryExpansion
Program: zapata_m6h

    def __init__(self):
        """Sorgu genişletme modülü başlatma işlemi"""
        self.logger = self.setup_logging()

=== __init__ ===
Modül: rag_pipeline
Sınıf: RAGPipeline
Program: zapata_m6h

    def __init__(self):
        """RAG Pipeline başlatma işlemi"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()

=== __init__ ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def __init__(self):
        """Redis önbellek yönetimi için sınıf."""
        self.logger = self.setup_logging()
        try:
            # decode_responses=False ile pickle için binary mod, True ile JSON için string mod
            self.client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
            self.redis_client_str = redis.StrictRedis(
                host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True
            )
            self.logger.info("✅ Redis bağlantısı kuruldu.")
        except Exception as e:
            self.logger.error(f"❌ Redis bağlantı hatası: {e}")

=== __init__ ===
Modül: redisqueue
Sınıf: RedisQueue
Program: zapata_m6h

    def __init__(self, queue_name="task_queue", retry_limit=3):
        """Redis kuyruğu yöneticisi."""
        self.logger = self.setup_logging()
        try:
            self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
            self.queue_name = queue_name
            self.retry_limit = retry_limit
            self.logger.info(f"✅ Redis kuyruğu ({queue_name}) başlatıldı.")
        except Exception as e:
            self.logger.error(f"❌ Redis kuyruğu başlatılamadı: {e}")

=== __init__ ===
Modül: reranking_module
Sınıf: RerankingModule
Program: zapata_m6h

    def __init__(self):
        """Reranking modülü başlatma işlemi"""
        self.logger = self.setup_logging()
        self.faiss = FAISSIntegration()
        self.retriever = RetrieverIntegration()

=== __init__ ===
Modül: retrieval_reranker
Sınıf: RetrievalReranker
Program: zapata_m6h

    def __init__(self, model_name="cross-encoder/ms-marco-MiniLM-L-6-v2"):
        """Reranking modülü başlatma işlemi"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()
        self.rag_pipeline = RAGPipeline()

        self.model = CrossEncoder(model_name)  # Eğitimli Cross-Encoder modeli yükleniyor

=== __init__ ===
Modül: retriever_integration
Sınıf: RetrieverIntegration
Program: zapata_m6h

    def __init__(self):
        """Retrieve entegrasyonu yöneticisi"""
        self.logger = self.setup_logging()
        self.retrieve_api_url = config.RETRIEVE_API_URL

=== __init__ ===
Modül: robustembeddingmodule
Sınıf: RobustEmbeddingProcessor
Program: zapata_m6h

    def __init__(self):
        """Hata toleranslı embedding işlemleri için sınıf."""
        self.embedding_models = {
            "openai": "text-embedding-ada-002",
            "contriever": "facebook/contriever",
            "specter": "allenai/specter",
            "minilm": "sentence-transformers/all-MiniLM-L6-v2",
            "scibert": "allenai/scibert_scivocab_uncased",
            "mpnet": "sentence-transformers/all-mpnet-base-v2",
            "gte": "thenlper/gte-base",
        }

        self.selected_model = config.EMBEDDING_MODEL.lower()
        self.chroma_client = chromadb.PersistentClient(path=str(config.CHROMA_DB_PATH))
        self.redis_client = redis.StrictRedis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=False)
        self.logger = self.setup_logging()

        if self.selected_model != "openai":
            self.model = SentenceTransformer(
                self.embedding_models.get(self.selected_model, "sentence-transformers/all-MiniLM-L6-v2")
            )

=== __init__ ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def __init__(self, db_path=None):
        """SQLite veritabanı bağlantısını yönetir."""
        self.logger = self.setup_logging()
        self.db_path = db_path if db_path else config.SQLITE_DB_PATH
        self.connection = self.create_connection()
        self.create_tables()

=== __init__ ===
Modül: scientific_mapping
Sınıf: ScientificMapper
Program: zapata_m6h

    def __init__(self):
        """Bilimsel makale haritalama yöneticisi."""
        self.logger = self.setup_logging()
        self.redis_cache = RedisCache()
        self.connection = self.create_db_connection()

        # Bölüm başlıkları tespiti için regex desenleri
        self.section_patterns = {
            "Özet": r"\b(?:Özet|Abstract)\b",
            "Giriş": r"\b(?:Giriş|Introduction)\b",
            "Yöntem": r"\b(?:Metodoloji|Yöntemler|Methods)\b",
            "Bulgular": r"\b(?:Bulgular|Results)\b",
            "Tartışma": r"\b(?:Tartışma|Discussion)\b",
            "Sonuç": r"\b(?:Sonuç|Conclusion)\b",
            "Kaynakça": r"\b(?:Kaynakça|References|Bibliography)\b",
        }

=== __init__ ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def __init__(self):
        """Arama motoru başlatma işlemi"""
        self.logger = self.setup_logging()
        self.sqlite = SQLiteStorage()
        self.redis = RedisQueue()
        self.chroma_client = PersistentClient(path="chroma_db")
        self.faiss_index = self.load_faiss_index()
        self.query_expander = QueryExpansion()

=== __init__ ===
Modül: sync_faiss_chromadb
Sınıf: SyncFAISSChromaDB
Program: zapata_m6h

    def __init__(self):
        """FAISS & ChromaDB senkronizasyon modülü başlatma işlemi"""
        self.logger = self.setup_logging()
        self.chroma_client = PersistentClient(path=config.CHROMA_DB_PATH)
        self.redis = RedisQueue()
        self.faiss_index = self.load_faiss_index()
        self.chroma_collection = self.chroma_client.get_collection("embeddings")

=== __init__ ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def __init__(self):
        self.stop_words = set(stopwords.words("english")) | set(
            stopwords.words("turkish")
        )  # Türkçe ve İngilizce stop-word listesi
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)
        self.sqlite_db = config.SQLITE_DB_PATH

=== __init__ ===
Modül: training_monitor
Sınıf: TrainingMonitor
Program: zapata_m6h

    def __init__(self, root):
        """Eğitim monitörünü başlatır."""
        self.root = root
        self.root.title("Eğitim Monitörü")
        self.root.geometry("500x300")

        self.setup_logging()
        self.create_widgets()

=== __init__ ===
Modül: guimodule
Sınıf: ZapataGUI
Program: zapata_m6h

    def __init__(self, root):
        """GUI başlatma işlemi"""
        self.root = root
        self.root.title("Zapata M6H - Bilimsel Arama ve İşleme Sistemi")
        self.root.geometry("800x600")

        self.setup_logging()
        self.create_widgets()

=== __init__ ===
Modül: main
Sınıf: ZapataM6H
Program: zapata_m6h

    def __init__(self):
        """Ana programın başlatılması ve ayarlanması"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()
        self.rag_pipeline = RAGPipeline()
        self.reranker = RerankingModule()

=== __init__ ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def __init__(self):
        """Zotero ile bağlantıyı kurar."""
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.library_type = "user"
        self.zot = zotero.Zotero(self.user_id, self.library_type, self.api_key)
        self.zapata_api_url = config.ZAPATA_REST_API_URL  # Zapata Rest API ile iletişim
        self.output_folder = config.ZOTERO_OUTPUT_FOLDER  # Zapata'ya gönderilecek dosyalar için dizin

        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)

=== __init__ ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def __init__(self):
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.api_url = config.ZOTERO_API_URL
        self.headers = {"Authorization": f"Bearer {self.api_key}"}

        # Redis bağlantısı
        self.redis_client = redis.Redis(host=config.REDIS_HOST, port=config.REDIS_PORT, decode_responses=True)

        # SQLite bağlantısı
        self.sqlite_db = config.SQLITE_DB_PATH
        self.ensure_tables()

=== __init__ ===
Modül: zoteromodule
Sınıf: ZoteroManager
Program: zapata_m6h

    def __init__(self):
        """Zotero API ile veri çekmek ve PDF indirmek için yönetici sınıfı."""
        self.api_key = config.ZOTERO_API_KEY
        self.user_id = config.ZOTERO_USER_ID
        self.api_url = config.ZOTERO_API_URL
        self.logger = self.setup_logging()

=== __len__ ===
Modül: FineTuning
Sınıf: FineTuningDataset
Program: zapata_m6h

    def __len__(self):
        return len(self.texts)

=== __len__ ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningDataset
Program: zapata_m6h

    def __len__(self):
        return len(self.texts)

=== _classify_block ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def _classify_block(self, block):
        """Blok sınıflandırma"""
        block_type_map = {
            "Title": "title",
            "Text": "text",
            "Figure": "figure",
            "Table": "table",
            "Header": "header",
            "Footer": "footer",
        }

        return block_type_map.get(block.type, "text")

=== _extract_references_by_section ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def _extract_references_by_section(self, text):
        """Bölüm bazlı referans çıkarma"""
        sections = ["References", "Bibliography", "Works Cited"]
        references = []

        for section in sections:
            section_match = re.search(f"{section}(.*?)(\n\n|\Z)", text, re.IGNORECASE | re.DOTALL)
            if section_match:
                section_text = section_match.group(1)
                references.extend(re.findall(r"\[(\d+)\]\s*(.+?)(?=\[|\n\n|$)", section_text, re.DOTALL))

        return references

=== _load_layout_model ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def _load_layout_model(self):
        """Layout tespiti için model"""
        return lp.Detectron2LayoutModel("lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config")

=== _load_reference_model ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def _load_reference_model(self):
        """Referans çıkarma için ML modeli"""
        return pipeline("token-classification", model="dslim/bert-base-NER")

=== add_embedding ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def add_embedding(self, doc_id, embedding):
        """Embedding verisini FAISS'e ekler."""
        try:
            embedding = np.array(embedding, dtype=np.float32).reshape(1, -1)
            self.index.add(embedding)

            # Redis'e önbelleğe kaydet
            self.redis_cache.cache_embedding(doc_id, embedding.tolist())

            # SQLite'e kaydet
            self.store_embedding_to_db(doc_id, embedding.tolist())

            self.logger.info(f"✅ {doc_id} için embedding FAISS'e eklendi.")
        except Exception as e:
            self.logger.error(f"❌ FAISS embedding ekleme hatası: {e}")

=== cache_embedding ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def cache_embedding(self, doc_id, embedding, ttl=86400):
        """Embedding verisini Redis’e kaydeder (JSON ile)."""
        try:
            key = f"embedding:{doc_id}"
            self.redis_client_str.setex(key, ttl, json.dumps(embedding))
            self.logger.info(f"✅ Embedding verisi Redis’e kaydedildi: {key}")
        except Exception as e:
            self.logger.error(f"❌ Embedding kaydetme hatası: {e}")

=== cache_map_data ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def cache_map_data(self, doc_id, map_type, map_data, ttl=86400):
        """Yapısal ve bilimsel haritalama verilerini Redis’e kaydeder."""
        try:
            key = f"{map_type}_map:{doc_id}"
            self.redis_client_str.setex(key, ttl, json.dumps(map_data))
            self.logger.info(f"✅ {map_type} haritası Redis’e kaydedildi: {key}")
        except Exception as e:
            self.logger.error(f"❌ {map_type} haritası kaydetme hatası: {e}")

=== cache_mindmap_data ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def cache_mindmap_data(self, key, mindmap_json, ttl=None):
        """Zihin haritası verisini Redis’te saklar."""
        try:
            serialized = json.dumps(mindmap_json)
            if ttl:
                self.redis_client_str.setex(key, ttl, serialized)
            else:
                self.redis_client_str.set(key, serialized)
            self.logger.info(f"✅ {key} için zihin haritası verisi Redis’e kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ Zihin haritası kaydetme hatası: {e}")

=== cache_references_to_redis ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def cache_references_to_redis(self, references):
        """Kaynakça verilerini Redis önbelleğine kaydeder."""
        for ref in references:
            item_id = ref["key"]
            ref_data = json.dumps(ref["data"])
            self.redis_client.set(f"reference:{item_id}", ref_data)
        print("✅ Kaynakçalar Redis’e kaydedildi.")

=== clean_text ===
Modül: helpermodule
Sınıf: HelperFunctions
Program: zapata_m6h

    def clean_text(self, text, remove_stopwords=True, language="turkish"):
        """Metni temizler, durdurma kelimelerini kaldırır, gereksiz boşlukları temizler."""
        self.logger.info("📝 Metin temizleme işlemi başlatıldı...")

        # Küçük harfe çevir
        text = text.lower()

        # Özel karakterleri kaldır
        text = re.sub(r"[^\w\s]", "", text)

        # Fazla boşlukları temizle
        text = re.sub(r"\s+", " ", text).strip()

        # Stopword temizleme
        if remove_stopwords:
            stopwords_list = self.turkish_stopwords if language == "turkish" else self.english_stopwords
            text = " ".join([word for word in text.split() if word not in stopwords_list])

        self.logger.info("✅ Metin temizleme işlemi tamamlandı.")
        return text

=== clean_text ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def clean_text(self, text):
        """Metni temizler: özel karakterleri kaldırır, küçük harfe çevirir, fazla boşlukları siler."""
        text = text.lower()
        text = re.sub(r"\s+", " ", text)  # Fazla boşlukları sil
        text = re.sub(r"[^\w\s]", "", text)  # Noktalama işaretlerini kaldır
        return text.strip()

=== clear_cache ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def clear_cache(self):
        """Redis’te saklanan tüm verileri temizler."""
        try:
            self.client.flushdb()
            self.logger.info("🗑️ Redis önbelleği temizlendi.")
        except Exception as e:
            self.logger.error(f"❌ Önbellek temizleme hatası: {e}")

=== cluster_documents ===
Modül: clustering_module
Sınıf: ClusteringProcessor
Program: zapata_m6h

    def cluster_documents(self, embeddings):
        """Belirtilen algoritmaya göre kümeleme yapar."""
        self.logger.info(f"🔍 {self.method.upper()} yöntemi ile kümeleme işlemi başlatıldı...")

        if self.method == "kmeans":
            model = KMeans(n_clusters=self.num_clusters, random_state=42)
        elif self.method == "dbscan":
            model = DBSCAN(eps=0.5, min_samples=5)
        elif self.method == "hac":
            model = AgglomerativeClustering(n_clusters=self.num_clusters)
        else:
            self.logger.error("❌ Geçersiz kümeleme yöntemi!")
            return None

        cluster_labels = model.fit_predict(embeddings)
        self.logger.info(f"✅ Kümeleme tamamlandı. {len(set(cluster_labels))} küme oluşturuldu.")
        return cluster_labels

=== create_connection ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def create_connection(self):
        """Veritabanı bağlantısını oluşturur."""
        try:
            conn = sqlite3.connect(self.db_path)
            self.logger.info(f"✅ SQLite bağlantısı kuruldu: {self.db_path}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite bağlantı hatası: {e}")
            return None

=== create_db_connection ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanı bağlantısını oluşturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"✅ SQLite bağlantısı kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite bağlantı hatası: {e}")
            return None

=== create_db_connection ===
Modül: veri_gorsellestirme
Sınıf: DataVisualizer
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanı bağlantısını oluşturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"✅ SQLite bağlantısı kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite bağlantı hatası: {e}")
            return None

=== create_db_connection ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanı bağlantısını oluşturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"✅ SQLite bağlantısı kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite bağlantı hatası: {e}")
            return None

=== create_db_connection ===
Modül: layout_analysis
Sınıf: LayoutAnalyzer
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanı bağlantısını oluşturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"✅ SQLite bağlantısı kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite bağlantı hatası: {e}")
            return None

=== create_db_connection ===
Modül: scientific_mapping
Sınıf: ScientificMapper
Program: zapata_m6h

    def create_db_connection(self):
        """SQLite veritabanı bağlantısını oluşturur."""
        try:
            conn = sqlite3.connect(config.SQLITE_DB_PATH)
            self.logger.info(f"✅ SQLite bağlantısı kuruldu: {config.SQLITE_DB_PATH}")
            return conn
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite bağlantı hatası: {e}")
            return None

=== create_tables ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def create_tables(self):
        """Gerekli tabloları oluşturur."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS documents (
                    id TEXT PRIMARY KEY,
                    title TEXT,
                    authors TEXT,
                    abstract TEXT,
                    content TEXT,
                    metadata TEXT
                )
            """
            )
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS embeddings (
                    doc_id TEXT PRIMARY KEY,
                    embedding TEXT,
                    FOREIGN KEY(doc_id) REFERENCES documents(id)
                )
            """
            )
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS citations (
                    doc_id TEXT,
                    citation TEXT,
                    FOREIGN KEY(doc_id) REFERENCES documents(id)
                )
            """
            )
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS scientific_maps (
                    doc_id TEXT PRIMARY KEY,
                    map_data TEXT,
                    FOREIGN KEY(doc_id) REFERENCES documents(id)
                )
            """
            )
            self.connection.commit()
            self.logger.info("✅ SQLite tabloları oluşturuldu veya zaten mevcut.")
        except sqlite3.Error as e:
            self.logger.error(f"❌ Tablolar oluşturulurken hata oluştu: {e}")

=== create_ui ===
Modül: Mind_Map_Visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def create_ui(self):
        """
        Kullanıcı arayüzünü oluşturur.
        """
        self.tree_frame = ttk.Frame(self.root)
        self.tree_frame.pack(fill="both", expand=True)

        self.load_button = ttk.Button(self.root, text="Haritayı Yükle", command=self.load_mind_map)
        self.load_button.pack()

=== create_widgets ===
Modül: guimindmap
Sınıf: MindMapGUI
Program: zapata_m6h

    def create_widgets(self):
        """GUI bileşenlerini oluşturur."""
        self.label = ttk.Label(self.master, text="Zihin Haritası Görselleştirme", font=("Arial", 14))
        self.label.pack(pady=10)

        self.load_button = ttk.Button(self.master, text="Veri Yükle", command=self.load_mindmap_data)
        self.load_button.pack(pady=5)

        self.open_map_button = ttk.Button(self.master, text="Haritayı Görüntüle", command=self.open_mindmap)
        self.open_map_button.pack(pady=5)

=== create_widgets ===
Modül: training_monitor
Sınıf: TrainingMonitor
Program: zapata_m6h

    def create_widgets(self):
        """GUI öğelerini oluşturur."""
        self.progress_label = ctk.CTkLabel(self.root, text="Eğitim Durumu:")
        self.progress_label.pack(pady=10)

        self.progress_bar = ctk.CTkProgressBar(self.root, width=400)
        self.progress_bar.set(0)
        self.progress_bar.pack(pady=10)

        self.status_label = ctk.CTkLabel(self.root, text="Bekleniyor...")
        self.status_label.pack(pady=5)

        self.start_button = ctk.CTkButton(self.root, text="Eğitimi Başlat", command=self.start_training)
        self.start_button.pack(pady=10)

=== create_widgets ===
Modül: guimodule
Sınıf: ZapataGUI
Program: zapata_m6h

    def create_widgets(self):
        """GUI öğelerini oluşturur."""
        self.query_label = ctk.CTkLabel(self.root, text="Sorgu Girin:")
        self.query_label.pack(pady=5)

        self.query_entry = ctk.CTkEntry(self.root, width=400)
        self.query_entry.pack(pady=5)

        self.search_button = ctk.CTkButton(self.root, text="Arama Yap", command=self.run_search)
        self.search_button.pack(pady=10)

        self.result_text = ctk.CTkTextbox(self.root, width=600, height=300)
        self.result_text.pack(pady=10)

=== delete_cache ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def delete_cache(self, doc_id, data_type):
        """Redis’teki belirli bir veriyi siler."""
        try:
            key = f"{data_type}:{doc_id}"
            self.redis_client_str.delete(key)
            self.logger.info(f"✅ Redis’ten veri silindi: {key}")
        except Exception as e:
            self.logger.error(f"❌ Redis verisi silme hatası: {e}")

=== dequeue_task ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def dequeue_task(self):
        """
        Kuyruktan bir görevi çeker.
        """
        try:
            task_data = self.redis_client.rpop("task_queue")
            if task_data:
                logging.info(f"🔄 Görev işlenmek üzere alındı: {task_data}")
            return task_data
        except Exception as e:
            logging.error(f"❌ Görev çekme hatası: {e}")
            return None

=== dequeue_task ===
Modül: redisqueue
Sınıf: RedisQueue
Program: zapata_m6h

    def dequeue_task(self):
        """Kuyruktan bir görevi çeker ve JSON olarak döndürür."""
        try:
            task_json = self.redis_client.lpop(self.queue_name)
            if task_json:
                task_data = json.loads(task_json)
                self.logger.info(f"📌 Görev alındı: {task_data}")
                return task_data
            else:
                self.logger.info("⚠️ Kuyruk boş.")
                return None
        except Exception as e:
            self.logger.error(f"❌ Görev alınırken hata oluştu: {e}")
            return None

=== detect_layout ===
Modül: pdfprocessing
Sınıf: PDFProcessor
Program: zapata_m6h

    def detect_layout(self, pdf_path):
        """PDF'in sayfa yapısını analiz eder (başlıklar, paragraflar, sütunlar)."""
        self.logger.info(f"📑 PDF sayfa düzeni analiz ediliyor: {pdf_path}")
        # TODO: Layout analiz için PyMuPDF, LayoutParser veya Detectron2 entegrasyonu düşünülebilir.
        return {"layout": "analyzed"}

=== detect_page_layout ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def detect_page_layout(self, pdf_path):
        """Gelişmiş sayfa düzeni tespiti"""
        doc = fitz.open(pdf_path)
        layouts = []

        # Layout Parser
        model = lp.Detectron2LayoutModel("lp://PubLayNet/faster_rcnn_R_50_FPN_3x/config")

        for page_num, page in enumerate(doc):
            # Sayfa görüntüsü
            pix = page.get_pixmap()
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

            # Layout tespiti
            detected_layout = model.detect(img)

            page_layout = {
                "page_number": page_num + 1,
                "elements": {
                    "text_blocks": [],
                    "titles": [],
                    "figures": [],
                    "tables": [],
                    "headers": [],
                    "footers": [],
                },
            }

            for block in detected_layout:
                block_type = self._classify_block(block)
                page_layout["elements"][f"{block_type}s"].append(block)

            layouts.append(page_layout)

        return layouts

=== download_pdf_from_doi ===
Modül: zoteromodule
Sınıf: ZoteroManager
Program: zapata_m6h

    def download_pdf_from_doi(self, doi, save_path):
        """DOI kullanarak Sci-Hub üzerinden PDF indirir."""
        self.logger.info(f"📥 DOI ile PDF indiriliyor: {doi}")
        sci_hub_url = f"https://sci-hub.se/{doi}"

        try:
            response = requests.get(sci_hub_url, stream=True)
            if response.status_code == 200:
                with open(save_path, "wb") as pdf_file:
                    for chunk in response.iter_content(chunk_size=1024):
                        pdf_file.write(chunk)
                self.logger.info(f"✅ PDF başarıyla indirildi: {save_path}")
                return True
            else:
                self.logger.error(f"❌ Sci-Hub üzerinden PDF indirilemedi: {response.status_code}")
                return False
        except Exception as e:
            self.logger.error(f"❌ DOI ile PDF indirme hatası: {e}")
            return False

=== encode_queries ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def encode_queries(self, queries):
        """Sorguları FAISS için vektörlere dönüştürür."""
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer("all-MiniLM-L6-v2")
        return model.encode(queries)

=== encode_queries ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def encode_queries(self, queries):
        """Sorguları FAISS için vektörlere dönüştürür."""
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer("all-MiniLM-L6-v2")
        return model.encode(queries)

=== enqueue_task ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def enqueue_task(self, task_data):
        """
        Görevleri Redis kuyruğuna ekler.
        """
        try:
            self.redis_client.lpush("task_queue", task_data)
            logging.info(f"✅ Görev kuyruğa eklendi: {task_data}")
        except Exception as e:
            logging.error(f"❌ Görev ekleme hatası: {e}")

=== enqueue_task ===
Modül: redisqueue
Sınıf: RedisQueue
Program: zapata_m6h

    def enqueue_task(self, task_data):
        """Görevi Redis kuyruğuna ekler."""
        try:
            task_data["retry_count"] = 0  # Başlangıçta sıfır deneme
            self.redis_client.rpush(self.queue_name, json.dumps(task_data))
            self.logger.info(f"✅ Görev kuyruğa eklendi: {task_data}")
        except Exception as e:
            self.logger.error(f"❌ Görev kuyruğa eklenemedi: {e}")

=== ensure_directories ===
Modül: configmodule
Sınıf: Config
Program: zapata_m6h

    def ensure_directories(self):
        """Gerekli dizinleri oluşturur."""
        directories = [
            self.PDF_DIR,
            self.EMBEDDING_PARCA_DIR,
            self.HEDEF_DIZIN,
            self.TEMIZ_TABLO_DIZIN,
            self.TEMIZ_KAYNAKCA_DIZIN,
            self.CITATIONS_DIR,
            self.TABLES_DIR,
        ]
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)

=== ensure_tables ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def ensure_tables(self):
        """SQLite içinde kaynakça verilerini saklamak için gerekli tabloları oluşturur."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS references (
                id TEXT PRIMARY KEY,
                title TEXT,
                authors TEXT,
                year TEXT,
                journal TEXT,
                doi TEXT,
                file_path TEXT
            )
        """
        )
        conn.commit()
        conn.close()

=== evaluate_model ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningManager
Program: zapata_m6h

    def evaluate_model(self):
        """Eğitilmiş modelin test seti üzerindeki performansını değerlendirir."""
        dataset = self.load_dataset()
        trainer = Trainer(model=self.model, tokenizer=self.tokenizer)
        results = trainer.evaluate(eval_dataset=dataset["test"])
        return results

=== expand_query ===
Modül: query_expansion
Sınıf: QueryExpansion
Program: zapata_m6h

    def expand_query(self, query, method="synonyms", max_expansions=5):
        """
        Sorguyu genişletir.
        - method: "synonyms" (Eş anlamlı kelimeler), "stems" (Kök kelime), "combined" (Her ikisi)
        - max_expansions: Eklenen kelime sayısı
        """
        expanded_query = set()
        query_words = query.lower().split()

        try:
            if method in ["synonyms", "combined"]:
                for word in query_words:
                    synonyms = self.get_synonyms(word, max_expansions)
                    expanded_query.update(synonyms)

            if method in ["stems", "combined"]:
                stemmed_words = self.get_stems(query_words)
                expanded_query.update(stemmed_words)

            final_query = list(expanded_query)
            self.logger.info(f"✅ Genişletilmiş sorgu: {final_query}")
            return final_query

        except Exception as e:
            self.logger.error(f"❌ Sorgu genişletme hatası: {e}")
            return query_words  # Hata durumunda orijinal sorguyu döndür

=== export_graph_json ===
Modül: mindmap_visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def export_graph_json(self):
        """
        Zotero atıf ağını D3.js uyumlu bir JSON formatında dışa aktarır.
        """
        graph = self.extract_citation_network()
        nodes = [{"id": node, "label": data["label"]} for node, data in graph.nodes(data=True)]
        links = [{"source": u, "target": v} for u, v in graph.edges()]

        graph_data = {"nodes": nodes, "links": links}
        output_path = os.path.join(self.output_folder, "citation_network.json")

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(graph_data, f, indent=4)

        print(f"✅ Zihin haritası JSON olarak kaydedildi: {output_path}")

=== export_references ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def export_references(self, format="ris"):
        """Kaynakçaları farklı formatlarda dışa aktarır (RIS, BibTeX, CSV, Pajek, VOSviewer)."""
        references = self.load_cached_references()
        export_path = os.path.join(config.TEMIZ_KAYNAKCA_DIZIN, f"references.{format}")

        if format == "ris":
            with open(export_path, "w", encoding="utf-8") as f:
                for ref in references:
                    f.write(
                        f"TY  - JOUR\nTI  - {ref.get('title', '')}\nAU  - {ref.get('authors', '')}\nPY  - {ref.get('year', '')}\nJO  - {ref.get('journal', '')}\nDO  - {ref.get('doi', '')}\nER  -\n\n"
                    )
        elif format == "bib":
            with open(export_path, "w", encoding="utf-8") as f:
                for ref in references:
                    f.write(
                        f"@article{{{ref.get('doi', '')},\ntitle = {{{ref.get('title', '')}}},\nauthor = {{{ref.get('authors', '')}}},\nyear = {{{ref.get('year', '')}}},\njournal = {{{ref.get('journal', '')}}},\ndoi = {{{ref.get('doi', '')}}}\n}}\n\n"
                    )
        elif format == "csv":
            with open(export_path, "w", encoding="utf-8") as f:
                f.write("Title,Authors,Year,Journal,DOI\n")
                for ref in references:
                    f.write(
                        f"{ref.get('title', '')},{ref.get('authors', '')},{ref.get('year', '')},{ref.get('journal', '')},{ref.get('doi', '')}\n"
                    )

        print(f"✅ Kaynakçalar {format.upper()} formatında dışa aktarıldı: {export_path}")

=== extract_citation_network ===
Modül: mindmap_visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def extract_citation_network(self):
        """
        Zotero’daki atıf ilişkilerini çıkararak bir network grafiği oluşturur.
        """
        references = self.fetch_references()
        citation_graph = nx.DiGraph()

        for ref in references:
            ref_id = ref["key"]
            title = ref["data"]["title"]
            citation_graph.add_node(ref_id, label=title)

            if "relations" in ref["data"] and "dc:relation" in ref["data"]["relations"]:
                cited_refs = ref["data"]["relations"]["dc:relation"]
                for cited in cited_refs:
                    cited_id = cited.split("/")[-1]
                    citation_graph.add_edge(ref_id, cited_id)

        return citation_graph

=== extract_citations ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def extract_citations(self, document_text):
        """Metin içindeki atıfları tespit eder."""
        try:
            citations = []
            lines = document_text.split("\n")
            for line in lines:
                if "[" in line and "]" in line:  # Basit köşeli parantez atıf algılama
                    citations.append(line.strip())
            self.logger.info(f"✅ {len(citations)} atıf tespit edildi.")
            return citations
        except Exception as e:
            self.logger.error(f"❌ Atıf tespit hatası: {e}")
            return []

=== extract_notes ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def extract_notes(self, item_id):
        """
        Zotero'daki belirli bir öğeye ait notları çeker.
        """
        try:
            notes = self.zot.item(item_id, "notes")
            return notes
        except Exception as e:
            print(f"❌ Zotero notlarını çekerken hata oluştu: {e}")
            return []

=== extract_references ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def extract_references(self, pdf_path) -> List[str]:
        """Gelişmiş referans çıkarma"""
        text = self.extract_text(pdf_path)
        references = []

        # Regex Tabanlı
        if self.reference_method in ["regex", "multi"]:
            regex_patterns = [
                r"\[(\d+)\]\s*(.+?)(?=\[|\n\n|$)",  # Sayısal referans
                r"([A-Z][a-z]+ et al\., \d{4})",  # Yazar stili
                r"(\w+,\s\d{4}[a-z]?)",  # APA stili
            ]
            for pattern in regex_patterns:
                references.extend(re.findall(pattern, text, re.DOTALL))

        # ML Tabanlı
        if self.reference_method in ["ml", "multi"]:
            ml_references = self.reference_model(text)
            references.extend([entity["word"] for entity in ml_references if entity["entity"] == "B-MISC"])

        # Bölüm Bazlı
        if self.reference_method in ["section_based", "multi"]:
            section_references = self._extract_references_by_section(text)
            references.extend(section_references)

        return list(set(references))

=== extract_references ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def extract_references(self, text):
        """Ham metindeki atıfları ve kaynakçaları tespit eder (40 popüler atıf stili)."""
        self.logger.info("🔍 Atıflar ham metinden çıkarılıyor...")

        # En sık kullanılan 40 atıf stilini kapsayan regex desenleri
        citation_patterns = [
            r"\(([^)]+, \d{4})\)",  # (Smith, 2020)
            r"\[\d+\]",  # [1]
            r"\[(\d+,\s*)*\d+\]",  # [1, 2, 3]
            r"\b(\w+,\s*\d{4})\b",  # Smith, 2020
            r"\b(\w+\s+et\s+al\.,\s*\d{4})\b",  # Smith et al., 2020
            r"\((\w+,\s*\d{4};\s*)+(\w+,\s*\d{4})\)",  # (Smith, 2020; Doe, 2021)
            r"\b(\w+\s+\d{4})\b",  # Smith 2020
            r"\((\w+\s+et\s+al\.,\s*\d{4})\)",  # (Smith et al., 2020)
            r"\[\w+,\s*\d{4}\]",  # [Smith, 2020]
            r"\[(\d+;\s*)*\d+\]",  # [1; 2; 3]
            r"\b(\d{4})\b",  # 2020 (yalnızca yıl)
            r"\((\w+,\s*\d{4},\s*p\.\s*\d+)\)",  # (Smith, 2020, p. 45)
            r"\b(\w+\s+and\s+\w+,\s*\d{4})\b",  # Smith and Doe, 2020
            r"\b(\w+\s+&\s+\w+,\s*\d{4})\b",  # Smith & Doe, 2020
            r"\((\d{4})\)",  # (2020)
            r"\b(\w+,\s*\d{4},\s*\d{4})\b",  # Smith, 2020, 2021
            r"\[\w+\s+et\s+al\.,\s*\d{4}\]",  # [Smith et al., 2020]
            r"\b(\w+,\s*\d{4},\s*[a-z])\b",  # Smith, 2020a
            r"\((\w+,\s*\d{4}[a-z])\)",  # (Smith, 2020a)
            r"\b(\w+\s+et\s+al\.\s+\d{4})\b",  # Smith et al. 2020
            # Yeni 20+ desen
            r"\((\w+,\s*\w+,\s*&\s*\w+,\s*\d{4})\)",  # APA: (Smith, Jones, & Doe, 2020)
            r"\[(\d+–\d+)\]",  # Nature: [1–3]
            r"\b(\d+)\b",  # Science: 1
            r"\((\w+\s+et\s+al\.\s*\d{4})\)",  # PNAS: (Smith et al. 2020)
            r"\b(\w+,\s*\d{4},\s*vol\.\s*\d+)\b",  # WOS: Smith, 2020, vol. 5
            r"\b(\w+,\s*\d{4},\s*\d+:\d+–\d+)\b",  # JBC: Smith, 2020, 45:123–130
            r"\b(\w+,\s*\w+\.\s*\w+\.,\s*\d{4})\b",  # ACS: Smith, J. A., 2020
            r"\((\w+\s+\d{4})\)",  # Chicago: (Smith 2020)
            r"\b(\w+\s+\d+)\b",  # MLA: Smith 123
            r"\((\w+\s+et\s+al\.,\s*\d{4},\s*Cell)\)",  # Cell: (Smith et al., 2020, Cell)
            r"\[\d+:\d+\]",  # BMJ: [1:5]
            r"\((\w+,\s*\d{4},\s*doi:\S+)\)",  # PLOS: (Smith, 2020, doi:10.1000/xyz)
            r"\b(\w+\s+et\s+al\.\s*\d{4},\s*\d+)\b",  # Ecology Letters: Smith et al. 2020, 15
            r"\b(\w+,\s*\d{4},\s*Geophys\.\s*Res\.\s*Lett\.)\b",  # AGU: Smith, 2020, Geophys. Res. Lett.
            r"\[\d+;\s*\d+\]",  # JAMA: [1; 2]
            r"\b(\w+,\s*\d{4},\s*ApJ,\s*\d+)\b",  # ApJ: Smith, 2020, ApJ, 875
            r"\((\w+,\s*\d{4},\s*Environ\.\s*Sci\.\s*Technol\.)\)",  # ES&T: (Smith, 2020, Environ. Sci. Technol.)
            r"\b(\w+,\s*\d{4},\s*J\.\s*Appl\.\s*Phys\.\s*\d+)\b",  # JAP: Smith, 2020, J. Appl. Phys. 128
        ]

        references = []
        for pattern in citation_patterns:
            matches = re.findall(pattern, text)
            references.extend(matches)

        # Tekrarları kaldır
        references = list(set(references))
        self.logger.info(f"✅ {len(references)} atıf tespit edildi.")
        return references

=== extract_references_parallel ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def extract_references_parallel(self, texts):
        """Çoklu işlem kullanarak birden fazla metinden atıf çıkarır."""
        self.logger.info("🔍 Paralel işlemle atıflar çıkarılıyor...")

        def extract(text):
            return self.extract_references(text)

        with concurrent.futures.ProcessPoolExecutor() as executor:
            results = list(executor.map(extract, texts))

        self.logger.info("✅ Paralel atıf çıkarma tamamlandı.")
        return results

=== extract_tables ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def extract_tables(self, pdf_path) -> List[pd.DataFrame]:
        """Çoklu kütüphane ile tablo çıkarma"""
        all_tables = []

        # PyMuPDF
        if "pymupdf" in self.table_method or self.table_method == "multi":
            doc = fitz.open(pdf_path)
            for page in doc:
                pymupdf_tables = page.find_tables()
                all_tables.extend(pymupdf_tables)

        # PDFPlumber
        if "pdfplumber" in self.table_method or self.table_method == "multi":
            with pdfplumber.open(pdf_path) as pdf:
                pdfplumber_tables = [pd.DataFrame(page.extract_table()) for page in pdf.pages if page.extract_table()]
                all_tables.extend(pdfplumber_tables)

        # Tabula
        if "tabula" in self.table_method or self.table_method == "multi":
            tabula_tables = tabula.read_pdf(pdf_path, pages="all")
            all_tables.extend(tabula_tables)

        # Camelot
        if "camelot" in self.table_method or self.table_method == "multi":
            camelot_tables = camelot.read_pdf(pdf_path)
            all_tables.extend([table.df for table in camelot_tables])

        return all_tables

=== extract_tables_from_pdf ===
Modül: pdfprocessing
Sınıf: PDFProcessor
Program: zapata_m6h

    def extract_tables_from_pdf(self, pdf_path):
        """PDF'ten tablo çıkarır, belirlenen yönteme göre çalışır."""
        self.logger.info(f"📊 PDF'ten tablolar çıkarılıyor: {pdf_path}")

        tables = []
        if self.table_extraction_method == "pdfplumber":
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    extracted_tables = page.extract_tables()
                    if extracted_tables:
                        tables.extend(extracted_tables)
        elif self.table_extraction_method == "pymupdf":
            doc = fitz.open(pdf_path)
            for page in doc:
                tables.append(page.get_text("blocks"))  # Alternatif tablo işleme yöntemi
        else:
            self.logger.error("❌ Desteklenmeyen PDF tablo çıkarma yöntemi!")

        return tables

=== extract_text ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def extract_text(self, pdf_path) -> str:
        """Çoklu kütüphane ile metin çıkarma"""
        texts = []

        # PDFPlumber
        if "pdfplumber" in self.text_method or self.text_method == "multi":
            with pdfplumber.open(pdf_path) as pdf:
                texts.append(" ".join([page.extract_text() for page in pdf.pages]))

        # PyMuPDF
        if "pymupdf" in self.text_method or self.text_method == "multi":
            doc = fitz.open(pdf_path)
            texts.append(" ".join([page.get_text() for page in doc]))

        # Borb
        if "borb" in self.text_method or self.text_method == "multi":
            with open(pdf_path, "rb") as file:
                doc = borb.pdf.DocumentFromBytes(file.read())
                borb_text = " ".join([page.extract_text() for page in doc.pages])
                texts.append(borb_text)

        # Tika
        if "tika" in self.text_method or self.text_method == "multi":
            raw = tika.parser.from_file(pdf_path)
            texts.append(raw.get("content", ""))

        # PDFMiner
        if "pdfminer" in self.text_method or self.text_method == "multi":
            from pdfminer.high_level import extract_text

            pdfminer_text = extract_text(pdf_path)
            texts.append(pdfminer_text)

        # En uzun metni seç veya birleştir
        return max(texts, key=len) if texts else ""

=== extract_text_from_pdf ===
Modül: pdfprocessing
Sınıf: PDFProcessor
Program: zapata_m6h

    def extract_text_from_pdf(self, pdf_path):
        """PDF'ten metin çıkarır, belirlenen yönteme göre çalışır."""
        self.logger.info(f"📄 PDF'ten metin çıkarılıyor: {pdf_path}")

        text = ""
        if self.text_extraction_method == "pdfplumber":
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    text += page.extract_text() + "\n"
        elif self.text_extraction_method == "pymupdf":
            doc = fitz.open(pdf_path)
            text = "\n".join([page.get_text("text") for page in doc])
        else:
            self.logger.error("❌ Desteklenmeyen PDF metin çıkarma yöntemi!")

        return text

=== faiss_search ===
Modül: retrieve_with_faiss
Sınıf: 
Program: zapata_m6h

def faiss_search(query_text, top_k=3):
    """
    FAISS kullanarak vektör araması yapar.
    """
    try:
        query_embedding = sentence_model.encode(query_text).reshape(1, -1)
        distances, indices = index.search(query_embedding, top_k)

        results = []
        for idx in indices[0]:
            doc_data = redis_client.get(f"faiss_doc:{idx}")
            if doc_data:
                results.append(json.loads(doc_data))

        return results

    except Exception as e:
        logging.error(f"❌ FAISS araması başarısız oldu: {str(e)}")
        return []

=== fetch_all_references ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def fetch_all_references(self):
        """
        Zotero'dan tüm referansları getirir.
        """
        try:
            references = self.zot.items()
            return references
        except Exception as e:
            print(f"❌ Zotero referanslarını çekerken hata oluştu: {e}")
            return []

=== fetch_citation_network ===
Modül: veri_gorsellestirme
Sınıf: DataVisualizer
Program: zapata_m6h

    def fetch_citation_network(self, doc_id):
        """Belge için atıf ağını SQLite veritabanından çeker."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT citation FROM citations WHERE doc_id = ?", (doc_id,))
            references = cursor.fetchall()
            citation_network = []
            for ref in references:
                citation_network.append(json.loads(ref[0]))

            self.logger.info(f"✅ {len(citation_network)} atıf ağı düğümü alındı.")
            return citation_network
        except sqlite3.Error as e:
            self.logger.error(f"❌ Atıf ağı verisi alınamadı: {e}")
            return None

=== fetch_from_redis ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def fetch_from_redis(self, doc_id):
        """Redis’ten işlenmiş metni alır."""
        return self.redis_client.get(f"text:{doc_id}")

=== fetch_from_sqlite ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def fetch_from_sqlite(self, doc_id):
        """SQLite’ten işlenmiş metni alır."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT text FROM processed_texts WHERE id=?", (doc_id,))
        result = cursor.fetchone()
        conn.close()
        return result[0] if result else None

=== fetch_pdf_files ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def fetch_pdf_files(self):
        """
        Zotero'daki tüm PDF dosyalarını çeker.
        """
        try:
            pdf_files = []
            items = self.zot.items()
            for item in items:
                if "data" in item and "attachments" in item["data"]:
                    for attachment in item["data"]["attachments"]:
                        if attachment["contentType"] == "application/pdf":
                            pdf_files.append(attachment["path"])
            return pdf_files
        except Exception as e:
            print(f"❌ Zotero PDF dosyalarını çekerken hata oluştu: {e}")
            return []

=== fetch_pdf_from_scihub ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def fetch_pdf_from_scihub(self, doi):
        """DOI’ye göre Sci-Hub üzerinden makale PDF dosyasını indirir."""
        sci_hub_url = f"https://sci-hub.se/{doi}"
        response = requests.get(sci_hub_url, stream=True)
        if response.status_code == 200:
            pdf_path = os.path.join(config.PDF_DIR, f"{doi}.pdf")
            with open(pdf_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=1024):
                    f.write(chunk)
            print(f"✅ PDF indirildi: {pdf_path}")
            return pdf_path
        else:
            print(f"❌ Sci-Hub'tan PDF indirilemedi: {response.status_code}")
            return None

=== fetch_references ===
Modül: mindmap_visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def fetch_references(self):
        """
        Zotero'dan tüm referansları çeker.
        """
        try:
            references = self.zot.items()
            return references
        except Exception as e:
            print(f"❌ Zotero referanslarını çekerken hata oluştu: {e}")
            return []

=== fetch_references_from_zotero ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def fetch_references_from_zotero(self):
        """Zotero’dan tüm kaynakça verilerini çeker ve JSON formatında kaydeder."""
        response = requests.get(f"{self.api_url}/items", headers=self.headers)
        if response.status_code == 200:
            references = response.json()
            with open(os.path.join(config.TEMIZ_KAYNAKCA_DIZIN, "zotero_references.json"), "w", encoding="utf-8") as f:
                json.dump(references, f, indent=4)
            print("✅ Zotero'dan kaynakça verileri alındı ve kaydedildi.")
            return references
        else:
            print(f"❌ Zotero'dan veri alınamadı: {response.status_code}")
            return None

=== fetch_references_from_zotero ===
Modül: zoteromodule
Sınıf: ZoteroManager
Program: zapata_m6h

    def fetch_references_from_zotero(self, limit=10):
        """Zotero'dan en son eklenen kaynakçaları çeker."""
        self.logger.info(f"📚 Zotero'dan son {limit} kaynak getiriliyor...")
        headers = {"Zotero-API-Key": self.api_key, "Content-Type": "application/json"}
        response = requests.get(f"{self.api_url}?limit={limit}", headers=headers)

        if response.status_code == 200:
            self.logger.info("✅ Zotero kaynakları başarıyla çekildi.")
            return response.json()
        else:
            self.logger.error(f"❌ Zotero API hatası: {response.status_code}")
            return None

=== fetch_results ===
Modül: fetch_top_k_results
Sınıf: FetchTopKResults
Program: zapata_m6h

    def fetch_results(self, query):
        """
        En iyi K sonucu getirir ve sıralar.
        - query: Kullanıcının arama sorgusu.
        """
        try:
            self.logger.info(f"🔍 Arama sorgusu: {query}")

            # Çoklu kaynaktan sonuçları getir
            raw_results = self.search_engine.multi_source_search(query, top_k=self.top_k)

            if not raw_results:
                self.logger.warning("⚠️ Hiç sonuç bulunamadı.")
                self.log_error(query, "Sonuç bulunamadı.")
                return []

            # Reranking işlemi
            sorted_results = self.reranker.rank_results(raw_results)

            self.logger.info(f"✅ {len(sorted_results)} sonuç bulundu ve sıralandı.")
            return sorted_results[: self.top_k]

        except Exception as e:
            self.logger.error(f"❌ En iyi K sonucu getirme hatası: {e}")
            self.log_error(query, str(e))
            return []

=== fetch_results_from_zapata ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def fetch_results_from_zapata(self, query):
        """
        Zapata M6H'dan Zotero'ya sorgu yaparak sonuçları getirir.
        """
        try:
            response = requests.get(f"{self.zapata_api_url}/search", params={"query": query})
            if response.status_code == 200:
                results = response.json()
                return results
            else:
                print(f"❌ Zapata'dan veri alırken hata oluştu: {response.text}")
                return []
        except Exception as e:
            print(f"❌ Zapata'dan veri alırken hata oluştu: {e}")
            return []

=== fetch_training_data ===
Modül: FineTuning
Sınıf: FineTuner
Program: zapata_m6h

    def fetch_training_data(self):
        """SQLite veritabanından eğitim verisini çeker"""
        conn = sqlite3.connect(config.SQLITE_DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT text, label FROM training_data")
        rows = cursor.fetchall()
        conn.close()

        texts = [row[0] for row in rows]
        labels = [row[1] for row in rows]
        return texts, labels

=== fetch_training_data ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuner
Program: zapata_m6h

    def fetch_training_data(self):
        """
        SQLite veritabanından eğitim verisini çeker.
        """
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute("SELECT text, label FROM training_data")
        rows = cursor.fetchall()
        conn.close()
        texts = [row[0] for row in rows]
        labels = [row[1] for row in rows]
        return texts, labels

=== full_sync ===
Modül: sync_faiss_chromadb
Sınıf: SyncFAISSChromaDB
Program: zapata_m6h

    def full_sync(self):
        """FAISS ve ChromaDB arasında çift yönlü senkronizasyon yapar."""
        self.logger.info("🔄 FAISS ↔ ChromaDB tam senkronizasyon başlatıldı.")
        self.sync_from_chromadb_to_faiss()
        self.sync_from_faiss_to_chromadb()
        self.logger.info("✅ FAISS ↔ ChromaDB senkronizasyonu tamamlandı.")

=== generate_embedding ===
Modül: alternativeembeddingmodule
Sınıf: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def generate_embedding(self, text):
        """Metni seçilen modelle embedding vektörüne dönüştürür."""
        self.logger.info("🧠 Alternatif model ile embedding işlemi başlatıldı.")

        if self.selected_model:
            embedding_vector = self.selected_model.encode(text, convert_to_numpy=True)
            return embedding_vector
        else:
            self.logger.error(
                "❌ Seçilen model bulunamadı! Lütfen .env dosyasındaki EMBEDDING_MODEL değerini kontrol edin."
            )
            return None

=== generate_embedding ===
Modül: embeddingmodule
Sınıf: EmbeddingProcessor
Program: zapata_m6h

    def generate_embedding(self, text):
        """Metni embedding vektörüne dönüştürür."""
        self.logger.info("🧠 Metin embedding işlemi başlatıldı.")

        if self.embedding_model.startswith("text-embedding-ada"):
            try:
                response = openai.Embedding.create(input=text, model=self.embedding_model)
                embedding_vector = response["data"][0]["embedding"]
                return np.array(embedding_vector)
            except Exception as e:
                self.logger.error(f"❌ OpenAI embedding hatası: {e}")
                return None
        else:
            self.logger.warning("⚠ Alternatif embedding modelleri desteklenmelidir!")
            return None

=== generate_embedding ===
Modül: robustembeddingmodule
Sınıf: RobustEmbeddingProcessor
Program: zapata_m6h

    def generate_embedding(self, text):
        """Metni embedding vektörüne dönüştürür, hata toleransı sağlar."""
        self.logger.info("🧠 Hata toleranslı embedding işlemi başlatıldı.")

        if not text.strip():
            self.logger.warning("⚠ Boş metin verildi, embedding yapılmadı.")
            return None

        try:
            if self.selected_model == "openai":
                response = openai.Embedding.create(input=text, model=self.embedding_models["openai"])
                embedding_vector = response["data"][0]["embedding"]
            else:
                embedding_vector = self.model.encode(text, convert_to_numpy=True)
            return np.array(embedding_vector)
        except Exception as e:
            self.logger.error(f"❌ Embedding işlemi başarısız oldu: {e}")
            return None

=== generate_html ===
Modül: d3js_visualizer
Sınıf: D3Visualizer
Program: zapata_m6h

    def generate_html(self, json_data):
        """
        JSON verisini D3.js kullanarak interaktif bir HTML dosyası oluşturur.
        """
        json_string = json.dumps(json_data).replace("'", "&#39;")
        html_content = self.html_template.replace("%DATA%", json_string)

        html_path = os.path.join(config.OUTPUT_DIR, "mindmap.html")
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        return html_path

=== generate_response ===
Modül: rag_pipeline
Sınıf: RAGPipeline
Program: zapata_m6h

    def generate_response(self, query):
        """RAG modeli ile en iyi yanıtı üretir."""
        retrieved_data = self.retrieve_data(query)

        # Burada RAG modeli çalıştırılabilir (örneğin LlamaIndex veya LangChain ile)
        response = f"🔍 {query} için en uygun sonuç: {retrieved_data[0] if retrieved_data else 'Sonuç bulunamadı'}"
        self.logger.info(f"✅ RAG yanıtı üretildi: {response}")
        return response

=== get_api_status ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def get_api_status():
    return jsonify({"status": "API çalışıyor"}), 200

=== get_cached_embedding ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def get_cached_embedding(self, doc_id):
        """Redis’ten embedding verisini alır (JSON ile)."""
        try:
            key = f"embedding:{doc_id}"
            cached_embedding = self.redis_client_str.get(key)
            if cached_embedding:
                self.logger.info(f"✅ Redis’ten embedding alındı: {key}")
                return json.loads(cached_embedding)
            self.logger.warning(f"⚠️ Redis’te embedding bulunamadı: {key}")
            return None
        except Exception as e:
            self.logger.error(f"❌ Embedding alma hatası: {e}")
            return None

=== get_cached_map ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def get_cached_map(self, doc_id, map_type):
        """Redis’ten haritalama verisini alır."""
        try:
            key = f"{map_type}_map:{doc_id}"
            cached_map = self.redis_client_str.get(key)
            if cached_map:
                self.logger.info(f"✅ Redis’ten {map_type} haritası alındı: {key}")
                return json.loads(cached_map)
            self.logger.warning(f"⚠️ Redis’te {map_type} haritası bulunamadı: {key}")
            return None
        except Exception as e:
            self.logger.error(f"❌ Harita alma hatası: {e}")
            return None

=== get_citation_network ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def get_citation_network(self, doc_id):
        """Saklanan atıf verilerini görselleştirme/analiz için alır."""
        self.logger.info(f"🔍 Atıf haritası getiriliyor: {doc_id}")

        try:
            # Önce Redis'ten kontrol et
            citation_data = self.redis_client.get(f"citations:{doc_id}")
            if citation_data:
                self.logger.info("✅ Redis'ten atıf haritası alındı.")
                return json.loads(citation_data)

            # Redis'te yoksa SQLite'ten çek
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT citation, reference, text_parametre FROM citations WHERE doc_id=?", (doc_id,))
            results = cursor.fetchall()
            conn.close()

            if results:
                citation_map = {row[0]: {"reference": row[1], "text_parametre": row[2]} for row in results}
                self.logger.info("✅ SQLite'ten atıf haritası alındı.")
                return citation_map

            self.logger.warning(f"⚠️ {doc_id} için atıf haritası bulunamadı.")
            return {}
        except Exception as e:
            self.logger.error(f"❌ Atıf haritası getirilirken hata: {str(e)}")
            return {}

=== get_db_connection ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def get_db_connection():
    return sqlite3.connect(config.SQLITE_DB_PATH)

=== get_env_variable ===
Modül: configmodule
Sınıf: Config
Program: zapata_m6h

    def get_env_variable(self, var_name, default=None):
        """Belirtilen değişkeni .env dosyasından okur."""
        return os.getenv(var_name, default)

=== get_max_workers ===
Modül: configmodule
Sınıf: Config
Program: zapata_m6h

    def get_max_workers(self):
        """Maksimum işlemci işçi sayısını döndürür."""
        return self.MAX_WORKERS

=== get_mindmap_data ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def get_mindmap_data(self, key):
        """Zihin haritası verisini Redis’ten alır."""
        try:
            data = self.redis_client_str.get(key)
            if data:
                self.logger.info(f"✅ Redis’ten zihin haritası alındı: {key}")
                return json.loads(data)
            self.logger.warning(f"⚠️ Redis’te zihin haritası bulunamadı: {key}")
            return None
        except Exception as e:
            self.logger.error(f"❌ Zihin haritası alma hatası: {e}")
            return None

=== get_query_result ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def get_query_result(self, query):
        """Önbelleğe alınmış sorgu sonucunu alır."""
        try:
            data = self.redis_client_str.get(query)
            if data:
                self.logger.info(f"✅ Redis’ten sorgu sonucu alındı: {query}")
                return json.loads(data)
            self.logger.warning(f"⚠️ Redis’te sorgu sonucu bulunamadı: {query}")
            return None
        except Exception as e:
            self.logger.error(f"❌ Sorgu sonucu alma hatası: {e}")
            return None

=== get_stems ===
Modül: query_expansion
Sınıf: QueryExpansion
Program: zapata_m6h

    def get_stems(self, words):
        """Kelime köklerini döndürür (Porter Stemmer)."""
        from nltk.stem import PorterStemmer

        ps = PorterStemmer()
        return {ps.stem(word) for word in words}

=== get_synonyms ===
Modül: query_expansion
Sınıf: QueryExpansion
Program: zapata_m6h

    def get_synonyms(self, word, max_expansions):
        """Bir kelimenin eş anlamlılarını getirir."""
        synonyms = set()
        for syn in wordnet.synsets(word):
            for lemma in syn.lemmas():
                synonyms.add(lemma.name().replace("_", " "))
                if len(synonyms) >= max_expansions:
                    break
        return synonyms

=== get_training_results ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def get_training_results():
    results = redis_client.get("training_results")
    if results:
        return jsonify({"training_results": results}), 200
    else:
        return jsonify({"error": "Henüz eğitim tamamlanmadı veya sonuç bulunamadı."}), 404

=== get_training_status ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def get_training_status():
    status = redis_client.get("training_status")
    return jsonify({"training_status": status or "Bilinmiyor"}), 200

=== highlight_references ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def highlight_references(self, query):
        """
        Zotero'da bir sorguya uygun referansları işaretler.
        """
        try:
            results = self.fetch_results_from_zapata(query)
            for result in results:
                item_id = result["id"]
                self.zot.update_item(item_id, {"tags": ["Zapata Highlight"]})
                print(f"✅ {result['title']} işaretlendi.")
        except Exception as e:
            print(f"❌ Zotero'da referans işaretleme hatası: {e}")

=== home ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def home():
    return jsonify({"message": "Zapata M6H REST API Çalışıyor 🚀"}), 200

=== init_sqlite_log_table ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def init_sqlite_log_table(self):
        """
        SQLite veritabanında hata log tablosunu oluşturur.
        """
        try:
            conn = sqlite3.connect(self.sqlite_db_path)
            cursor = conn.cursor()
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS error_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    level TEXT,
                    message TEXT,
                    module TEXT,
                    function TEXT,
                    details TEXT
                )
            """
            )
            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"SQLite log tablosu oluşturulurken hata: {e}")

=== load_cached_references ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def load_cached_references(self):
        """Redis'ten kaynakça verilerini yükler."""
        keys = self.redis_client.keys("reference:*")
        references = [json.loads(self.redis_client.get(key)) for key in keys]
        return references

=== load_dataset ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningManager
Program: zapata_m6h

    def load_dataset(self):
        """Veri kümesini yükleyip tokenizasyon yapar."""
        dataset = load_dataset("csv", data_files=self.dataset_path)
        dataset = dataset.map(lambda x: self.tokenizer(x["text"], truncation=True, padding="max_length"), batched=True)
        return dataset

=== load_embeddings_from_chromadb ===
Modül: clustering_module
Sınıf: ClusteringProcessor
Program: zapata_m6h

    def load_embeddings_from_chromadb(self):
        """ChromaDB'den tüm embedding vektörlerini çeker."""
        self.logger.info("📥 ChromaDB'den embedding verileri yükleniyor...")
        collection = self.chroma_client.get_or_create_collection(name="embeddings")
        results = collection.get(include=["embeddings", "ids"])

        embeddings = np.array(results["embeddings"])
        doc_ids = results["ids"]

        self.logger.info(f"✅ {len(embeddings)} adet embedding yüklendi.")
        return embeddings, doc_ids

=== load_faiss_index ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def load_faiss_index(self):
        """FAISS dizinini yükler veya yeni oluşturur."""
        try:
            if faiss.read_index("faiss_index.idx"):
                index = faiss.read_index("faiss_index.idx")
                self.logger.info("✅ FAISS dizini yüklendi.")
                return index
            else:
                index = faiss.IndexFlatL2(768)
                self.logger.warning("⚠️ Yeni FAISS dizini oluşturuldu.")
                return index
        except Exception as e:
            self.logger.error(f"❌ FAISS yükleme hatası: {e}")
            return None

=== load_faiss_index ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def load_faiss_index(self):
        """FAISS dizinini yükler."""
        try:
            index = faiss.read_index("faiss_index.idx")
            self.logger.info("✅ FAISS dizini yüklendi.")
            return index
        except Exception as e:
            self.logger.error(f"❌ FAISS yükleme hatası: {e}")
            return None

=== load_faiss_index ===
Modül: sync_faiss_chromadb
Sınıf: SyncFAISSChromaDB
Program: zapata_m6h

    def load_faiss_index(self):
        """FAISS dizinini yükler veya yeni oluşturur."""
        try:
            if os.path.exists("faiss_index.idx"):
                index = faiss.read_index("faiss_index.idx")
                self.logger.info("✅ FAISS dizini yüklendi.")
                return index
            else:
                index = faiss.IndexFlatL2(768)  # Öntanımlı boyut (768)
                self.logger.warning("⚠️ Yeni FAISS dizini oluşturuldu.")
                return index
        except Exception as e:
            self.logger.error(f"❌ FAISS yükleme hatası: {e}")
            return None

=== load_json ===
Modül: helpermodule
Sınıf: HelperFunctions
Program: zapata_m6h

    def load_json(self, file_path):
        """JSON dosyasını yükler."""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            self.logger.info(f"✅ JSON dosyası yüklendi: {file_path}")
            return data
        except Exception as e:
            self.logger.error(f"❌ JSON yükleme hatası: {e}")
            return None

=== load_mind_map ===
Modül: Mind_Map_Visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def load_mind_map(self):
        """
        JSON formatında saklanan zihin haritasını yükler ve görüntüler.
        """
        try:
            with open(config.MINDMAP_JSON_PATH, "r", encoding="utf-8") as f:
                mind_map_data = json.load(f)
            d3js_visualizer.display_mind_map(mind_map_data)
        except Exception as e:
            print(f"❌ Hata: {e}")

=== load_mindmap_data ===
Modül: guimindmap
Sınıf: MindMapGUI
Program: zapata_m6h

    def load_mindmap_data(self):
        """Zotero ve Zapata’dan verileri çekerek JSON formatında kaydeder."""
        zotero_data = fetch_zotero_data()
        zapata_data = fetch_mindmap_data()

        mindmap_data = {"nodes": [], "links": []}

        # Zotero’dan gelen kaynakça verileri
        for item in zotero_data:
            mindmap_data["nodes"].append({"id": item["title"], "group": "zotero"})

        # Zapata’dan gelen atıf ve bağlantılar
        for link in zapata_data["links"]:
            mindmap_data["links"].append({"source": link["source"], "target": link["target"], "type": "citation"})

        with open("mindmap_data.json", "w", encoding="utf-8") as f:
            json.dump(mindmap_data, f, indent=4)
        print("✅ Zihin haritası verileri başarıyla yüklendi!")

=== load_model_from_redis ===
Modül: FineTuning
Sınıf: FineTuner
Program: zapata_m6h

    def load_model_from_redis(self):
        """Redis'ten modeli yükler"""
        model_data = redis_client.get(f"fine_tuned_model:{self.model_name}")
        if model_data:
            with open(os.path.join(self.output_dir, "pytorch_model.bin"), "wb") as f:
                f.write(model_data)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.output_dir)
            logging.info(f"📌 {self.model_name} modeli Redis’ten alındı ve belleğe yüklendi.")
        else:
            logging.error(f"❌ {self.model_name} için Redis’te kayıtlı model bulunamadı.")

=== load_model_from_redis ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuner
Program: zapata_m6h

    def load_model_from_redis(self):
        """
        Redis'ten modeli alır ve belleğe yükler.
        """
        model_data = self.redis_client.get(f"fine_tuned_model_{self.model_name}")
        if model_data:
            with open(os.path.join(self.output_dir, "pytorch_model.bin"), "wb") as f:
                f.write(model_data)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.output_dir)
            logger.info("📌 Model Redis’ten alındı ve belleğe yüklendi.")
        else:
            logger.error("❌ Redis’te kayıtlı model bulunamadı.")

=== log_error ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def log_error(self, message, level="ERROR", module="Unknown", function="Unknown", details=""):
        """
        Hata mesajlarını üç farklı formata (TXT, JSON, SQLite) kaydeder.
        """
        error_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "level": level,
            "message": message,
            "module": module,
            "function": function,
            "details": details,
        }

        self.log_to_file(message, level)
        self.log_to_json(error_data)
        self.log_to_sqlite(message, level, module, function, details)

        print(f"❌ Hata kaydedildi: {message}")

=== log_error ===
Modül: fetch_top_k_results
Sınıf: FetchTopKResults
Program: zapata_m6h

    def log_error(self, query, error_message):
        """Hataları JSON formatında log dosyasına kaydeder."""
        error_data = {
            "timestamp": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            "query": query,
            "error": error_message,
        }
        try:
            with open(self.error_log_file, "a", encoding="utf-8") as log_file:
                json.dump(error_data, log_file, ensure_ascii=False)
                log_file.write("\n")
            self.logger.error(f"❌ Hata kaydedildi: {error_message}")
        except Exception as e:
            self.logger.critical(f"⚠️ Hata logu kaydedilemedi: {e}")

=== log_test_result ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def log_test_result(self, test_name, status, details=""):
        """
        Test sonuçlarını JSON ve SQLite formatında kaydeder.
        """
        test_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "test_name": test_name,
            "status": status,
            "details": details,
        }

        # JSON kaydı
        try:
            if not os.path.exists(self.test_log_file):
                with open(self.test_log_file, "w", encoding="utf-8") as f:
                    json.dump([], f, indent=4)

            with open(self.test_log_file, "r+", encoding="utf-8") as f:
                logs = json.load(f)
                logs.append(test_data)
                f.seek(0)
                json.dump(logs, f, indent=4)
        except Exception as e:
            logging.error(f"Test sonucu JSON'a kaydedilemedi: {e}")

        # SQLite kaydı
        try:
            conn = sqlite3.connect(self.sqlite_db_path)
            cursor = conn.cursor()
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS test_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT,
                    test_name TEXT,
                    status TEXT,
                    details TEXT
                )
            """
            )
            cursor.execute(
                """
                INSERT INTO test_results (timestamp, test_name, status, details)
                VALUES (?, ?, ?, ?)
            """,
                (test_data["timestamp"], test_data["test_name"], test_data["status"], test_data["details"]),
            )
            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"Test sonucu SQLite'a kaydedilemedi: {e}")

=== log_to_file ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def log_to_file(self, message, level="ERROR"):
        """
        Hata mesajlarını TXT dosyasına kaydeder.
        """
        logging.log(getattr(logging, level, logging.ERROR), message)

=== log_to_json ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def log_to_json(self, error_data):
        """
        Hata mesajlarını JSON dosyasına kaydeder.
        """
        try:
            if not os.path.exists(self.json_log_file):
                with open(self.json_log_file, "w", encoding="utf-8") as f:
                    json.dump([], f, indent=4)

            with open(self.json_log_file, "r+", encoding="utf-8") as f:
                logs = json.load(f)
                logs.append(error_data)
                f.seek(0)
                json.dump(logs, f, indent=4)
        except Exception as e:
            logging.error(f"JSON log kaydı sırasında hata: {e}")

=== log_to_sqlite ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def log_to_sqlite(self, message, level="ERROR", module="Unknown", function="Unknown", details=""):
        """
        Hata mesajlarını SQLite veritabanına kaydeder.
        """
        try:
            conn = sqlite3.connect(self.sqlite_db_path)
            cursor = conn.cursor()
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            cursor.execute(
                """
                INSERT INTO error_logs (timestamp, level, message, module, function, details)
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (timestamp, level, message, module, function, details),
            )

            conn.commit()
            conn.close()
        except Exception as e:
            logging.error(f"SQLite hata kaydı sırasında hata: {e}")

=== map_citations_to_references ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def map_citations_to_references(self, doc_id):
        """Atıfları kaynakça ile eşleştirir ve ChromaDB'ye kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT citation FROM citations WHERE doc_id = ?", (doc_id,))
            references = cursor.fetchall()
            mapped_citations = []

            for ref in references:
                ref_text = json.loads(ref[0])
                for citation in ref_text:
                    mapped_citations.append({"doc_id": doc_id, "citation": citation, "reference": ref_text})

            self.chroma_db.store_data(doc_id, mapped_citations)
            self.logger.info(f"✅ {len(mapped_citations)} atıf ChromaDB'ye kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ Atıf eşleştirme hatası: {e}")

=== map_citations_to_references ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def map_citations_to_references(self, citations, reference_list):
        """Atıfları kaynakçalarla eşleştirir."""
        self.logger.info("📌 Atıflar kaynakçalarla eşleştiriliyor...")

        citation_map = {}
        for citation in citations:
            for ref in reference_list:
                if citation in ref:
                    citation_map[citation] = ref
                    break

        self.logger.info(f"✅ {len(citation_map)} atıf eşleşmesi yapıldı.")
        return citation_map

=== map_document_structure ===
Modül: layout_analysis
Sınıf: LayoutAnalyzer
Program: zapata_m6h

    def map_document_structure(self, doc_id, document_text):
        """Makale yapısını belirler ve işaretler."""
        try:
            mapped_layout = {}
            for element, pattern in self.layout_patterns.items():
                matches = re.finditer(pattern, document_text, re.IGNORECASE)
                mapped_layout[element] = [match.start() for match in matches]

            self.redis_cache.cache_map_data(doc_id, "layout_mapping", mapped_layout)
            self.store_mapping_to_db(doc_id, mapped_layout)

            self.logger.info(f"✅ {len(mapped_layout)} yapısal öğe tespit edildi ve kaydedildi.")
            return mapped_layout
        except Exception as e:
            self.logger.error(f"❌ Yapısal haritalama hatası: {e}")
            return None

=== map_scientific_sections ===
Modül: scientific_mapping
Sınıf: ScientificMapper
Program: zapata_m6h

    def map_scientific_sections(self, doc_id, document_text):
        """Makale bölümlerini belirler ve işaretler."""
        try:
            mapped_sections = {}
            for section, pattern in self.section_patterns.items():
                match = re.search(pattern, document_text, re.IGNORECASE)
                if match:
                    mapped_sections[section] = match.start()

            sorted_sections = sorted(mapped_sections.items(), key=lambda x: x[1])
            structured_sections = {k: document_text[v:] for k, v in sorted_sections}

            # Redis'e kaydet
            self.redis_cache.cache_map_data(doc_id, "scientific_mapping", structured_sections)
            # SQLite'e kaydet
            self.store_mapping_to_db(doc_id, structured_sections)

            self.logger.info(f"✅ {len(structured_sections)} bölüm tespit edildi ve kaydedildi.")
            return structured_sections
        except Exception as e:
            self.logger.error(f"❌ Bilimsel haritalama hatası: {e}")
            return None

=== multi_source_search ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def multi_source_search(self, query, top_k=5):
        """
        Aynı anda FAISS, ChromaDB, SQLite, Redis ve Retrieve üzerinde arama yapar.
        - query: Kullanıcının arama sorgusu.
        - top_k: En iyi eşleşme sayısı.
        """
        try:
            expanded_query = self.query_expander.expand_query(query, method="combined", max_expansions=3)
            self.logger.info(f"🔍 Genişletilmiş sorgu: {expanded_query}")

            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [
                    executor.submit(self.search_faiss, expanded_query, top_k),
                    executor.submit(self.search_chromadb, expanded_query, top_k),
                    executor.submit(self.search_sqlite, expanded_query, top_k),
                    executor.submit(self.search_redis, expanded_query, top_k),
                    executor.submit(self.search_retrieve, expanded_query, top_k),
                ]
                results = [future.result() for future in futures]

            combined_results = sum(results, [])  # Sonuçları düz liste haline getir
            reranked_results = self.reranker.rank_results(combined_results)

            self.logger.info(f"✅ {len(reranked_results)} sonuç bulundu ve sıralandı.")
            return reranked_results[:top_k]

        except Exception as e:
            self.logger.error(f"❌ Multi-Source arama hatası: {e}")
            return []

=== multi_source_search ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def multi_source_search(self, query, top_k=5):
        """
        Aynı anda FAISS, ChromaDB, SQLite ve Redis üzerinden arama yapar.
        - query: Kullanıcının arama sorgusu.
        - top_k: En iyi eşleşme sayısı.
        """
        try:
            expanded_query = self.query_expander.expand_query(query, method="combined", max_expansions=3)
            self.logger.info(f"🔍 Genişletilmiş sorgu: {expanded_query}")

            faiss_results = self.search_faiss(expanded_query, top_k)
            chroma_results = self.search_chromadb(expanded_query, top_k)
            sqlite_results = self.search_sqlite(expanded_query, top_k)
            redis_results = self.search_redis(expanded_query, top_k)

            combined_results = faiss_results + chroma_results + sqlite_results + redis_results
            sorted_results = sorted(combined_results, key=lambda x: x[1], reverse=True)

            self.logger.info(f"✅ {len(sorted_results)} sonuç bulundu ve sıralandı.")
            return sorted_results[:top_k]

        except Exception as e:
            self.logger.error(f"❌ Arama hatası: {e}")
            return []

=== open_mindmap ===
Modül: guimindmap
Sınıf: MindMapGUI
Program: zapata_m6h

    def open_mindmap(self):
        """Zihin haritasını görüntülemek için yerel bir HTML sunucusu başlatır."""
        file_path = os.path.abspath("mindmap.html")
        webbrowser.open("file://" + file_path)

        if self.server is None:
            self.server = HTTPServer(("localhost", 8080), SimpleHTTPRequestHandler)
            print("🌍 Mind Map Server başlatıldı: http://localhost:8080")
            self.server.serve_forever()

=== optimize_memory ===
Modül: helpermodule
Sınıf: HelperFunctions
Program: zapata_m6h

    def optimize_memory(self):
        """Bellek optimizasyonu için çöp toplayıcıyı çalıştırır."""
        self.logger.info("🔄 Bellek optimizasyonu başlatılıyor...")
        gc.collect()
        self.logger.info("✅ Bellek optimizasyonu tamamlandı.")

=== parallel_finetune ===
Modül: FineTuning
Sınıf: 
Program: zapata_m6h

def parallel_finetune(model_name):
    """Seçilen modeli paralel olarak eğitir"""
    fine_tuner = FineTuner(model_name)
    fine_tuner.train_model()
    fine_tuner.save_model_to_redis()

=== parallel_training ===
Modül: yapay_zeka_finetuning
Sınıf: 
Program: zapata_m6h

def parallel_training(selected_models):
    """
    Seçilen modellerin **paralel olarak** eğitilmesini sağlar.
    """
    with ProcessPoolExecutor(max_workers=len(selected_models)) as executor:
        futures = [executor.submit(FineTuner(model).train_model) for model in selected_models]
        for future in futures:
            future.result()  # İşlemlerin tamamlanmasını bekle

=== parallel_training ===
Modül: yapay_zeka_finetuning
Sınıf: 
Program: zapata_m6h

def parallel_training(selected_models):
    """
    Seçilen modellerin **paralel olarak** eğitilmesini sağlar.
    """
    with ProcessPoolExecutor(max_workers=len(selected_models)) as executor:
        futures = [executor.submit(FineTuner(model).train_model) for model in selected_models]
        for future in futures:
            future.result()  # İşlemlerin tamamlanmasını bekle

=== parse_pdf ===
Modül: document_parser
Sınıf: DocumentParser
Program: zapata_m6h

    def parse_pdf(self, pdf_path):
        """
        PDF dosyasından içerik ve metadata çıkartır.
        """
        try:
            self.logger.info(f"📂 PDF işleniyor: {pdf_path}")
            doc = fitz.open(pdf_path)

            metadata = {
                "title": doc.metadata.get("title", "Bilinmeyen Başlık"),
                "author": doc.metadata.get("author", "Bilinmeyen Yazar"),
                "doi": None,  # DOI bilgisi metin içinden çekilecek
                "date": doc.metadata.get("creationDate", "Bilinmeyen Tarih"),
            }

            raw_text = ""
            for page in doc:
                raw_text += page.get_text("text") + "\n"

            # Yapısal ve bilimsel haritalama
            structure_map = self.layout_analyzer.analyze_layout(raw_text)
            science_map = self.scientific_mapper.map_scientific_sections(raw_text)

            result = {
                "metadata": metadata,
                "text": raw_text,
                "structure_map": structure_map,
                "science_map": science_map,
            }

            # Redis ve SQLite'e kaydet
            self.queue.enqueue_task(json.dumps(result))
            self.db.store_document_metadata(metadata)

            self.logger.info(f"✅ PDF işleme tamamlandı: {pdf_path}")
            return result

        except Exception as e:
            self.logger.error(f"❌ PDF işleme hatası: {e}")
            return None

=== parse_ris ===
Modül: document_parser
Sınıf: DocumentParser
Program: zapata_m6h

    def parse_ris(self, ris_path):
        """
        RIS formatındaki kaynakça dosyalarını işler ve metadata çıkartır.
        """
        try:
            self.logger.info(f"📂 RIS işleniyor: {ris_path}")
            with open(ris_path, "r", encoding="utf-8") as f:
                ris_data = f.readlines()

            metadata = {}
            for line in ris_data:
                if line.startswith("TY  -"):
                    metadata["type"] = line.split("-")[1].strip()
                elif line.startswith("TI  -"):
                    metadata["title"] = line.split("-")[1].strip()
                elif line.startswith("AU  -"):
                    metadata.setdefault("authors", []).append(line.split("-")[1].strip())
                elif line.startswith("DO  -"):
                    metadata["doi"] = line.split("-")[1].strip()
                elif line.startswith("PY  -"):
                    metadata["year"] = line.split("-")[1].strip()

            self.db.store_document_metadata(metadata)

            self.logger.info(f"✅ RIS işleme tamamlandı: {ris_path}")
            return metadata

        except Exception as e:
            self.logger.error(f"❌ RIS işleme hatası: {e}")
            return None

=== parse_txt ===
Modül: document_parser
Sınıf: DocumentParser
Program: zapata_m6h

    def parse_txt(self, txt_path):
        """
        TXT dosyasından içerik çıkarır ve analiz eder.
        """
        try:
            self.logger.info(f"📂 TXT işleniyor: {txt_path}")

            with open(txt_path, "r", encoding="utf-8") as f:
                raw_text = f.read()

            structure_map = self.layout_analyzer.analyze_layout(raw_text)
            science_map = self.scientific_mapper.map_scientific_sections(raw_text)

            result = {
                "metadata": {"title": Path(txt_path).stem, "author": "Bilinmeyen"},
                "text": raw_text,
                "structure_map": structure_map,
                "science_map": science_map,
            }

            self.queue.enqueue_task(json.dumps(result))
            self.db.store_document_metadata(result["metadata"])

            self.logger.info(f"✅ TXT işleme tamamlandı: {txt_path}")
            return result

        except Exception as e:
            self.logger.error(f"❌ TXT işleme hatası: {e}")
            return None

=== perform_search ===
Modül: guimodule
Sınıf: ZapataGUI
Program: zapata_m6h

    def perform_search(self, query):
        """Retrieve, FAISS ve RAG pipeline üzerinden arama yapar."""
        retriever = RetrieverIntegration()
        faiss = FAISSIntegration()
        rag = RAGPipeline()

        retrieve_results = retriever.send_query(query)
        faiss_results, _ = faiss.search_similar(query, top_k=5)
        rag_results = rag.generate_response(query)

        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", f"📌 Retrieve Sonuçları: {retrieve_results}\n")
        self.result_text.insert("end", f"📌 FAISS Sonuçları: {faiss_results}\n")
        self.result_text.insert("end", f"📌 RAG Cevabı: {rag_results}\n")

=== plot_citation_network ===
Modül: veri_gorsellestirme
Sınıf: DataVisualizer
Program: zapata_m6h

    def plot_citation_network(self, doc_id):
        """Atıf ağını çizerek gösterir."""
        citation_data = self.fetch_citation_network(doc_id)
        if not citation_data:
            self.logger.warning(f"⚠️ Atıf ağı verisi bulunamadı: {doc_id}")
            return

        G = nx.DiGraph()
        for citation in citation_data:
            for ref in citation:
                G.add_edge(doc_id, ref)

        plt.figure(figsize=(10, 6))
        pos = nx.spring_layout(G)
        nx.draw(
            G,
            pos,
            with_labels=True,
            node_size=3000,
            node_color="skyblue",
            edge_color="gray",
            font_size=10,
            font_weight="bold",
        )
        plt.title(f"📊 Atıf Ağı Görselleştirmesi: {doc_id}")
        plt.show()
        self.logger.info(f"✅ Atıf ağı görselleştirildi: {doc_id}")

=== plot_clustering_results ===
Modül: veri_gorsellestirme
Sınıf: DataVisualizer
Program: zapata_m6h

    def plot_clustering_results(self, clustering_data):
        """Kümelenme sonuçlarını görselleştirir."""
        try:
            plt.figure(figsize=(10, 6))
            sns.scatterplot(
                x=clustering_data[:, 0], y=clustering_data[:, 1], hue=clustering_data[:, 2], palette="viridis"
            )
            plt.title("📊 Embedding Kümeleme Sonuçları")
            plt.xlabel("Özellik 1")
            plt.ylabel("Özellik 2")
            plt.show()
            self.logger.info("✅ Embedding kümeleme sonuçları görselleştirildi.")
        except Exception as e:
            self.logger.error(f"❌ Kümeleme görselleştirme hatası: {e}")

=== process_and_store ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def process_and_store(self, text, doc_id, apply_stemming=False):
        """Metni işler ve SQLite + Redis’e kaydeder."""
        processed_text = self.process_text(text, apply_stemming)
        self.save_to_sqlite(processed_text, doc_id)
        self.save_to_redis(processed_text, doc_id)
        return processed_text

=== process_citation_data ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def process_citation_data():
    thread = threading.Thread(target=process_citations)
    thread.start()

    logging.info("📌 Atıf zinciri analizi başlatıldı.")
    return jsonify({"status": "Atıf zinciri analizi başlatıldı."}), 200

=== process_document ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def process_document(self, doc_id, document_text):
        """Belgeyi analiz eder ve atıf eşleştirmesi yapar."""
        citations = self.extract_citations(document_text)
        if citations:
            self.redis_cache.cache_map_data(doc_id, "citation", citations)
            self.map_citations_to_references(doc_id)
        else:
            self.logger.warning(f"⚠️ Belge içinde atıf bulunamadı: {doc_id}")

=== process_pdf ===
Modül: pdfkutuphane
Sınıf: AdvancedPDFProcessor
Program: zapata_m6h

    def process_pdf(self, pdf_path):
        """Tüm özellikleri birleştirilmiş PDF işleme"""
        return {
            "text": self.extract_text(pdf_path),
            "tables": self.extract_tables(pdf_path),
            "references": self.extract_references(pdf_path),
            "layout": self.detect_page_layout(pdf_path),
        }

=== process_task ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def process_task(self, task_data):
        """
        Bir görevi işler (dummy işlem).
        """
        try:
            logging.info(f"🚀 İşlem başlatıldı: {task_data}")
            time.sleep(2)  # Simülasyon için bekletme
            logging.info(f"✅ İşlem tamamlandı: {task_data}")
        except Exception as e:
            logging.error(f"❌ İşlem sırasında hata oluştu: {e}")

=== process_text ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def process_text(self, text, apply_stemming=False):
        """Tam metin işleme sürecini uygular."""
        text = self.clean_text(text)
        text = self.remove_stopwords(text)
        if apply_stemming:
            text = self.stem_words(text)
        return text

=== reflow_columns ===
Modül: pdfprocessing
Sınıf: PDFProcessor
Program: zapata_m6h

    def reflow_columns(self, text):
        """Çok sütunlu metni düzene sokar."""
        self.logger.info("📝 Metin sütun düzenleme işlemi başlatıldı.")
        cleaned_text = text.replace("\n", " ")  # Basit sütun birleştirme işlemi
        return cleaned_text

=== remove_stopwords ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def remove_stopwords(self, text):
        """Metinden stop-word’leri kaldırır."""
        words = word_tokenize(text)
        filtered_words = [word for word in words if word not in self.stop_words]
        return " ".join(filtered_words)

=== rerank_results ===
Modül: retrieve_with_reranking
Sınıf: 
Program: zapata_m6h

def rerank_results(query, documents, method="bert", top_n=3):
    """
    Retrieve edilen metinleri re-rank eder.
    :param query: Kullanıcının sorgusu
    :param documents: Retrieve edilen metinler
    :param method: "bert" veya "tfidf" (re-ranking yöntemi)
    :param top_n: En iyi kaç sonuç döndürülecek
    :return: En iyi sıralanmış metinler
    """
    try:
        if method == "bert":
            query_embedding = bert_model.encode(query, convert_to_tensor=True)
            doc_embeddings = bert_model.encode([doc["text"] for doc in documents], convert_to_tensor=True)
            cosine_scores = util.pytorch_cos_sim(query_embedding, doc_embeddings)[0]
            ranked_indices = cosine_scores.argsort(descending=True)[:top_n]

        elif method == "tfidf":
            vectorizer = TfidfVectorizer()
            all_texts = [query] + [doc["text"] for doc in documents]
            tfidf_matrix = vectorizer.fit_transform(all_texts)
            query_vec = tfidf_matrix[0]
            doc_vectors = tfidf_matrix[1:]
            scores = np.dot(doc_vectors, query_vec.T).toarray().flatten()
            ranked_indices = np.argsort(scores)[::-1][:top_n]

        else:
            logging.error(f"❌ Geçersiz re-ranking yöntemi: {method}")
            return documents[:top_n]

        return [documents[i] for i in ranked_indices]

    except Exception as e:
        logging.error(f"❌ Re-ranking işlemi başarısız oldu: {str(e)}")
        return documents[:top_n]

=== rerank_results ===
Modül: reranking_module
Sınıf: RerankingModule
Program: zapata_m6h

    def rerank_results(self, query, retrieve_results, faiss_results, weights=(0.5, 0.5)):
        """
        Retrieve ve FAISS sonuçlarını tekrar sıralar.
        - retrieve_results: Retrieve API'den gelen sonuçlar
        - faiss_results: FAISS tarafından döndürülen benzerlik sonuçları
        - weights: (retrieve_weight, faiss_weight) - Sonuçların ağırlık katsayıları
        """
        try:
            if not retrieve_results and not faiss_results:
                self.logger.warning("⚠️ Reranking için yeterli veri bulunamadı.")
                return []

            # Ağırlıklı skorlama yaparak sıralama oluştur
            retrieve_weight, faiss_weight = weights
            combined_results = {}

            for idx, result in enumerate(retrieve_results):
                combined_results[result] = retrieve_weight * (1.0 / (idx + 1))  # İlk sonuçlara daha fazla önem ver

            for idx, (doc_id, similarity) in enumerate(faiss_results):
                if doc_id in combined_results:
                    combined_results[doc_id] += faiss_weight * similarity
                else:
                    combined_results[doc_id] = faiss_weight * similarity

            # Skorları büyükten küçüğe sırala
            sorted_results = sorted(combined_results.items(), key=lambda x: x[1], reverse=True)

            self.logger.info(f"✅ {len(sorted_results)} sonuç tekrar sıralandı.")
            return sorted_results

        except Exception as e:
            self.logger.error(f"❌ Reranking sırasında hata oluştu: {e}")
            return []

=== rerank_results ===
Modül: retrieval_reranker
Sınıf: RetrievalReranker
Program: zapata_m6h

    def rerank_results(self, query, retrieve_results, faiss_results, weights=(0.5, 0.5)):
        """
        Retrieve ve FAISS sonuçlarını yeniden sıralar.
        - retrieve_results: Retrieve API'den gelen sonuçlar
        - faiss_results: FAISS tarafından döndürülen benzerlik sonuçları
        - weights: (retrieve_weight, faiss_weight) - Sonuçların ağırlık katsayıları
        """
        try:
            if not retrieve_results and not faiss_results:
                self.logger.warning("⚠️ Reranking için yeterli veri bulunamadı.")
                return []

            combined_results = []
            for doc_id, text in retrieve_results.items():
                combined_results.append((doc_id, text, "retrieve"))

            for doc_id, similarity in faiss_results:
                combined_results.append((doc_id, similarity, "faiss"))

            reranked_scores = []
            for doc_id, text_or_score, source in combined_results:
                input_pair = [(query, text_or_score)] if source == "retrieve" else [(query, "")]
                score = self.model.predict(input_pair)[0]
                reranked_scores.append((doc_id, score))

            sorted_results = sorted(reranked_scores, key=lambda x: x[1], reverse=True)

            self.logger.info(f"✅ {len(sorted_results)} sonuç yeniden sıralandı.")
            return sorted_results

        except Exception as e:
            self.logger.error(f"❌ Reranking sırasında hata oluştu: {e}")
            return []

=== retrieve_and_rerank ===
Modül: retrieve_with_reranking
Sınıf: 
Program: zapata_m6h

def retrieve_and_rerank(query, source="faiss", method="bert", top_k=5, top_n=3):
    """
    Retrieve edilen verileri alır, re-rank eder ve en iyi sonuçları döndürür.
    :param query: Kullanıcının sorgusu
    :param source: FAISS veya ChromaDB
    :param method: Re-ranking yöntemi ("bert" veya "tfidf")
    :param top_k: Retrieve edilecek toplam sonuç sayısı
    :param top_n: En iyi döndürülecek sonuç sayısı
    :return: En iyi sıralanmış metinler
    """
    try:
        documents = retrieve_from_source(query, source, top_k)
        return rerank_results(query, documents, method, top_n)

    except Exception as e:
        logging.error(f"❌ Retrieve + Re-Ranking başarısız oldu: {str(e)}")
        return []

=== retrieve_and_rerank_parallel ===
Modül: retrieve_and_rerank_parallel
Sınıf: 
Program: zapata_m6h

def retrieve_and_rerank_parallel(query, source="faiss", method="bert", top_k=5, top_n=3):
    """
    Retrieve edilen verileri çoklu işlem desteğiyle re-rank eder.
    """
    try:
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_retrieve = executor.submit(retrieve_from_source, query, source, top_k)
            documents = future_retrieve.result()

            future_rerank = executor.submit(rerank_results, query, documents, method, top_n)
            ranked_documents = future_rerank.result()

        return ranked_documents

    except Exception as e:
        logging.error(f"❌ Paralel Retrieve + Re-Ranking başarısız oldu: {str(e)}")
        return []

=== retrieve_citation_network ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def retrieve_citation_network(self, doc_id):
        """Belge için atıf ağını oluşturur."""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT citation FROM citations WHERE doc_id = ?", (doc_id,))
            references = cursor.fetchall()
            if references:
                citation_network = []
                for ref in references:
                    citation_network.append(json.loads(ref[0]))
                self.logger.info(f"✅ {len(citation_network)} atıf ağı düğümü oluşturuldu.")
                return citation_network
            else:
                self.logger.warning(f"⚠️ Atıf ağı verisi bulunamadı: {doc_id}")
                return None
        except Exception as e:
            self.logger.error(f"❌ Atıf ağı oluşturma hatası: {e}")
            return None

=== retrieve_data ===
Modül: rag_pipeline
Sınıf: RAGPipeline
Program: zapata_m6h

    def retrieve_data(self, query):
        """Retrieve ve FAISS üzerinden veri çeker."""
        retrieve_results = self.retriever.send_query(query)
        faiss_results, _ = self.faiss.search_similar(query, top_k=5)

        combined_results = retrieve_results + faiss_results
        self.logger.info(f"✅ Retrieve ve FAISS sonuçları birleştirildi: {combined_results}")
        return combined_results

=== retrieve_document ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def retrieve_document(self, doc_id):
        """Belgeyi SQLite veritabanından alır."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                SELECT * FROM documents WHERE id = ?
            """,
                (doc_id,),
            )
            row = cursor.fetchone()
            if row:
                self.logger.info(f"✅ Belge SQLite'ten alındı: {doc_id}")
                return {
                    "id": row[0],
                    "title": row[1],
                    "authors": row[2],
                    "abstract": row[3],
                    "content": row[4],
                    "metadata": json.loads(row[5]),
                }
            else:
                self.logger.warning(f"⚠️ Belge SQLite'te bulunamadı: {doc_id}")
                return None
        except sqlite3.Error as e:
            self.logger.error(f"❌ Belge alınırken hata oluştu: {e}")
            return None

=== retrieve_documents_api ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def retrieve_documents_api():
    data = request.json
    query = data.get("query", "")
    if not query:
        return jsonify({"error": "Sorgu metni belirtilmedi."}), 400

    results = retrieve_documents(query)
    return jsonify({"results": results}), 200

=== retrieve_embedding ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def retrieve_embedding(self, key):
        """Redis’ten embedding verisini çeker (pickle ile)."""
        try:
            data = self.client.get(key)
            if data:
                self.logger.info(f"✅ Redis’ten embedding alındı: {key}")
                return pickle.loads(data)
            self.logger.warning(f"⚠️ Redis’te embedding bulunamadı: {key}")
            return None
        except Exception as e:
            self.logger.error(f"❌ Embedding alma hatası: {e}")
            return None

=== retrieve_from_source ===
Modül: retrieve_with_reranking
Sınıf: 
Program: zapata_m6h

def retrieve_from_source(query, source="faiss", top_k=5):
    """
    FAISS veya ChromaDB üzerinden veri retrieve eder.
    :param query: Kullanıcının sorgusu
    :param source: "faiss" veya "chroma" (veri kaynağı)
    :param top_k: Döndürülecek sonuç sayısı
    :return: Retrieve edilen belgeler listesi
    """
    try:
        if source == "faiss":
            return faiss_search(query, top_k=top_k)
        elif source == "chroma":
            return chroma_search(query, top_k=top_k)
        else:
            logging.error(f"❌ Geçersiz veri kaynağı: {source}")
            return []
    except Exception as e:
        logging.error(f"❌ Retrieve işlemi başarısız oldu: {str(e)}")
        return []

=== retrieve_logs ===
Modül: error_logging
Sınıf: ErrorLogger
Program: zapata_m6h

    def retrieve_logs(self, log_type="sqlite"):
        """
        Kayıtlı hataları SQLite, JSON veya TXT formatından çeker.
        """
        if log_type == "sqlite":
            try:
                conn = sqlite3.connect(self.sqlite_db_path)
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM error_logs ORDER BY timestamp DESC")
                logs = cursor.fetchall()
                conn.close()
                return logs
            except Exception as e:
                logging.error(f"SQLite hata logları alınırken hata: {e}")
                return []

        elif log_type == "json":
            try:
                with open(self.json_log_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"JSON hata logları okunurken hata: {e}")
                return []

        elif log_type == "txt":
            try:
                with open(self.log_file, "r", encoding="utf-8") as f:
                    return f.readlines()
            except Exception as e:
                logging.error(f"TXT hata logları okunurken hata: {e}")
                return []

        return []

=== retrieve_mapping ===
Modül: layout_analysis
Sınıf: LayoutAnalyzer
Program: zapata_m6h

    def retrieve_mapping(self, doc_id):
        """Redis veya SQLite'den yapısal haritalamayı getirir."""
        mapping = self.redis_cache.get_cached_map(doc_id, "layout_mapping")
        if mapping:
            self.logger.info(f"✅ Redis'ten getirildi: {doc_id}")
            return mapping

        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT mapping FROM layout_mapping WHERE doc_id = ?", (doc_id,))
            result = cursor.fetchone()
            if result:
                self.logger.info(f"✅ SQLite'ten getirildi: {doc_id}")
                return json.loads(result[0])
        except sqlite3.Error as e:
            self.logger.error(f"❌ Veritabanından veri çekme hatası: {e}")

        self.logger.warning(f"⚠️ {doc_id} için yapısal haritalama verisi bulunamadı.")
        return None

=== retrieve_mapping ===
Modül: scientific_mapping
Sınıf: ScientificMapper
Program: zapata_m6h

    def retrieve_mapping(self, doc_id):
        """Redis veya SQLite'den bilimsel haritalamayı getirir."""
        mapping = self.redis_cache.get_cached_map(doc_id, "scientific_mapping")
        if mapping:
            self.logger.info(f"✅ Redis'ten getirildi: {doc_id}")
            return mapping

        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT mapping FROM scientific_mapping WHERE doc_id = ?", (doc_id,))
            result = cursor.fetchone()
            if result:
                self.logger.info(f"✅ SQLite'ten getirildi: {doc_id}")
                return json.loads(result[0])
        except sqlite3.Error as e:
            self.logger.error(f"❌ Veritabanından veri çekme hatası: {e}")

        self.logger.warning(f"⚠️ {doc_id} için bilimsel haritalama verisi bulunamadı.")
        return None

=== retry_failed_tasks ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def retry_failed_tasks(self, max_attempts=3):
        """
        Başarısız olan görevleri tekrar kuyruğa ekler.
        """
        for attempt in range(max_attempts):
            task = self.dequeue_task()
            if task:
                try:
                    self.process_task(task)
                    logging.info(f"✅ Yeniden işlem başarılı: {task}")
                except Exception as e:
                    logging.error(f"❌ Yeniden işlem hatası: {e}")
                    self.enqueue_task(task)  # Başarısız olursa tekrar kuyruğa ekle
            else:
                logging.info("📌 Bekleyen hata işlemi bulunamadı.")

=== retry_failed_tasks ===
Modül: redisqueue
Sınıf: RedisQueue
Program: zapata_m6h

    def retry_failed_tasks(self):
        """Başarısız görevleri tekrar kuyruğa ekler."""
        MAX_RETRY = int(config.get_env_variable("MAX_TASK_RETRY", 3))
        failed_tasks = self.redis_client.lrange("failed_tasks", 0, -1)

        def process_task(task_json):
            task_data = json.loads(task_json)
            retry_count = task_data.get("retry_count", 0)
            failure_reason = task_data.get("failure_reason", "Bilinmeyen hata")

            if retry_count < MAX_RETRY:
                task_data["retry_count"] += 1
                self.enqueue_task(task_data)
                self.redis_client.lrem("failed_tasks", 1, task_json)
                self.logger.info(f"🔄 Görev tekrar kuyruğa alındı: {task_data}")
            else:
                self.logger.error(f"❌ Görev {MAX_RETRY} kez denendi ve başarısız oldu: {task_data}")
                self.save_failure_reason(task_data["task_id"], failure_reason)
                self.redis_client.rpush("permanently_failed_tasks", task_json)

        threads = [threading.Thread(target=process_task, args=(task,)) for task in failed_tasks]
        for t in threads:
            t.start()
        for t in threads:
            t.join()

=== run_console_mode ===
Modül: main
Sınıf: ZapataM6H
Program: zapata_m6h

    def run_console_mode(self, query):
        """Konsol üzerinden çalıştırma modu"""
        self.logger.info("✅ Konsol Modu Başlatıldı.")
        retrieve_results = self.retriever.send_query(query)
        faiss_results, _ = self.faiss.search_similar(query, top_k=5)
        rag_results = self.rag_pipeline.generate_response(query)

        reranked_results = self.reranker.rerank_results(query, retrieve_results, faiss_results)

        print("\n📄 Retrieve Sonuçları:", retrieve_results)
        print("📄 FAISS Sonuçları:", faiss_results)
        print("📄 RAG Yanıtı:", rag_results)
        print("📄 Yeniden Sıralanmış Sonuçlar:", reranked_results)

=== run_gui ===
Modül: guimindmap
Sınıf: 
Program: zapata_m6h

def run_gui():
    root = tk.Tk()
    app = MindMapGUI(root)
    root.mainloop()

=== run_gui_mode ===
Modül: main
Sınıf: ZapataM6H
Program: zapata_m6h

    def run_gui_mode(self):
        """GUI üzerinden çalıştırma modu"""
        self.logger.info("✅ GUI Modu Başlatıldı.")
        root = ctk.CTk()
        app = ZapataGUI(root)
        root.mainloop()

=== run_multiprocessing ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def run_multiprocessing(self):
        """
        Paralel işlemcilerle görevleri çalıştırır.
        """
        with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            while True:
                task = self.dequeue_task()
                if task:
                    executor.submit(self.process_task, task)
                else:
                    time.sleep(1)

=== run_search ===
Modül: guimodule
Sınıf: ZapataGUI
Program: zapata_m6h

    def run_search(self):
        """Retrieve ve FAISS araması yapar."""
        query = self.query_entry.get()
        if not query:
            self.logger.warning("⚠️ Lütfen bir sorgu girin.")
            return

        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", "Arama yapılıyor...\n")

        threading.Thread(target=self.perform_search, args=(query,)).start()

=== run_threading ===
Modül: process_manager
Sınıf: ProcessManager
Program: zapata_m6h

    def run_threading(self):
        """
        Paralel threading ile görevleri çalıştırır.
        """
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            while True:
                task = self.dequeue_task()
                if task:
                    executor.submit(self.process_task, task)
                else:
                    time.sleep(1)

=== run_training ===
Modül: training_monitor
Sınıf: TrainingMonitor
Program: zapata_m6h

    def run_training(self):
        """Eğitim ilerlemesini simüle eder ve GUI'yi günceller."""
        num_epochs = 10  # Örnek epoch sayısı
        for epoch in range(1, num_epochs + 1):
            time.sleep(2)  # Eğitimi simüle etmek için bekleme süresi
            progress = epoch / num_epochs
            self.progress_bar.set(progress)
            self.status_label.configure(text=f"Epoch {epoch}/{num_epochs} - İlerleme: %{int(progress * 100)}")
            self.logger.info(f"✅ Epoch {epoch} tamamlandı. İlerleme: %{int(progress * 100)}")

        self.status_label.configure(text="✅ Eğitim Tamamlandı!")
        self.logger.info("🚀 Eğitim başarıyla tamamlandı.")

=== run_training_monitor ===
Modül: main
Sınıf: ZapataM6H
Program: zapata_m6h

    def run_training_monitor(self):
        """Eğitim monitörünü başlatır."""
        self.logger.info("✅ Eğitim Monitörü Başlatıldı.")
        root = ctk.CTk()
        monitor = TrainingMonitor(root)
        root.mainloop()

=== save_citation_map_to_chromadb ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_chromadb(self, doc_id, citation_map, text):
        """Atıf haritasını ChromaDB'ye kaydeder."""
        self.logger.info(f"💾 Atıf haritası ChromaDB'ye kaydediliyor: {doc_id}")

        try:
            collection = self.chroma_client.get_or_create_collection(name="citation_mappings")
            for citation, reference in citation_map.items():
                collection.add(
                    ids=[f"{doc_id}_{citation}"],
                    metadatas=[
                        {"doc_id": doc_id, "citation": citation, "reference": reference, "text_parametre": text}
                    ],
                )
            self.logger.info("✅ Atıf haritası ChromaDB'ye başarıyla kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ ChromaDB'ye kayıt başarısız: {str(e)}")

=== save_citation_map_to_json ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_json(self, doc_id, citation_map, text):
        """Atıf haritasını JSON dosyasına kaydeder."""
        self.logger.info(f"💾 Atıf haritası JSON dosyasına kaydediliyor: {doc_id}")

        try:
            json_data = {
                citation: {"reference": reference, "text_parametre": text}
                for citation, reference in citation_map.items()
            }
            with open(f"{config.CHROMA_DB_PATH}/{doc_id}_citations.json", "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=4)
            self.logger.info("✅ Atıf haritası JSON'a başarıyla kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ JSON'a kayıt başarısız: {str(e)}")

=== save_citation_map_to_redis ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_redis(self, doc_id, citation_map, text):
        """Atıf haritasını Redis'e kaydeder."""
        self.logger.info(f"💾 Atıf haritası Redis'e kaydediliyor: {doc_id}")

        try:
            redis_data = {
                citation: {"reference": reference, "text_parametre": text}
                for citation, reference in citation_map.items()
            }
            self.redis_client.set(f"citations:{doc_id}", json.dumps(redis_data))
            self.logger.info("✅ Atıf haritası Redis'e başarıyla kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ Redis'e kayıt başarısız: {str(e)}")

=== save_citation_map_to_sqlite ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def save_citation_map_to_sqlite(self, doc_id, citation_map, text):
        """Atıf haritasını SQLite veritabanına kaydeder."""
        self.logger.info(f"💾 Atıf haritası SQLite veritabanına kaydediliyor: {self.db_path}")

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS citations (
                    doc_id TEXT,
                    citation TEXT,
                    reference TEXT,
                    text_parametre TEXT
                )
            """
            )

            for citation, reference in citation_map.items():
                cursor.execute(
                    "INSERT INTO citations (doc_id, citation, reference, text_parametre) VALUES (?, ?, ?, ?)",
                    (doc_id, citation, reference, text),
                )

            conn.commit()
            conn.close()
            self.logger.info("✅ Atıf haritası SQLite'e başarıyla kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ SQLite'e kayıt başarısız: {str(e)}")

=== save_clusters_to_chromadb ===
Modül: clustering_module
Sınıf: ClusteringProcessor
Program: zapata_m6h

    def save_clusters_to_chromadb(self, doc_ids, cluster_labels):
        """Kümeleme sonuçlarını ChromaDB'ye kaydeder."""
        self.logger.info(f"💾 Kümeleme sonuçları ChromaDB'ye kaydediliyor...")

        collection = self.chroma_client.get_or_create_collection(name="document_clusters")
        for doc_id, cluster_id in zip(doc_ids, cluster_labels):
            collection.add(ids=[doc_id], metadatas=[{"cluster_id": int(cluster_id)}])

        self.logger.info("✅ Kümeleme verileri ChromaDB'ye başarıyla kaydedildi.")

=== save_clusters_to_sqlite ===
Modül: clustering_module
Sınıf: ClusteringProcessor
Program: zapata_m6h

    def save_clusters_to_sqlite(self, doc_ids, cluster_labels):
        """Kümeleme sonuçlarını SQLite veritabanına kaydeder."""
        self.logger.info(f"💾 Kümeleme sonuçları SQLite veritabanına kaydediliyor: {self.db_path}")

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS document_clusters (
                doc_id TEXT,
                cluster_id INTEGER
            )
        """
        )

        for doc_id, cluster_id in zip(doc_ids, cluster_labels):
            cursor.execute(
                "INSERT INTO document_clusters (doc_id, cluster_id) VALUES (?, ?)", (doc_id, int(cluster_id))
            )

        conn.commit()
        conn.close()
        self.logger.info("✅ Kümeleme verileri SQLite'e başarıyla kaydedildi.")

=== save_embedding_to_chromadb ===
Modül: alternativeembeddingmodule
Sınıf: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_chromadb(self, doc_id, embedding):
        """Embedding vektörünü ChromaDB'ye kaydeder."""
        self.logger.info(f"💾 Alternatif embedding ChromaDB'ye kaydediliyor: {doc_id}")
        collection = self.chroma_client.get_or_create_collection(name="alt_embeddings")
        collection.add(ids=[doc_id], embeddings=[embedding.tolist()])
        self.logger.info("✅ Alternatif embedding başarıyla kaydedildi.")

=== save_embedding_to_chromadb ===
Modül: embeddingmodule
Sınıf: EmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_chromadb(self, doc_id, embedding):
        """Embedding vektörünü ChromaDB'ye kaydeder."""
        self.logger.info(f"💾 Embedding ChromaDB'ye kaydediliyor: {doc_id}")
        collection = self.chroma_client.get_or_create_collection(name="embeddings")
        collection.add(ids=[doc_id], embeddings=[embedding.tolist()])
        self.logger.info("✅ Embedding başarıyla kaydedildi.")

=== save_embedding_to_chromadb ===
Modül: robustembeddingmodule
Sınıf: RobustEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_chromadb(self, doc_id, embedding):
        """Embedding vektörünü ChromaDB'ye kaydeder."""
        if embedding is None:
            self.logger.error(f"❌ {doc_id} için geçersiz embedding, ChromaDB'ye kaydedilmedi.")
            return

        self.logger.info(f"💾 Embedding ChromaDB'ye kaydediliyor: {doc_id}")
        collection = self.chroma_client.get_or_create_collection(name="robust_embeddings")
        collection.add(ids=[doc_id], embeddings=[embedding.tolist()])
        self.logger.info("✅ Embedding başarıyla kaydedildi.")

=== save_embedding_to_redis ===
Modül: alternativeembeddingmodule
Sınıf: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_redis(self, doc_id, embedding):
        """Embedding vektörünü Redis'e kaydeder."""
        self.logger.info(f"💾 Alternatif embedding Redis'e kaydediliyor: {doc_id}")
        self.redis_client.set(doc_id, np.array(embedding).tobytes())
        self.logger.info("✅ Alternatif embedding Redis'e başarıyla kaydedildi.")

=== save_embedding_to_redis ===
Modül: embeddingmodule
Sınıf: EmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_redis(self, doc_id, embedding):
        """Embedding vektörünü Redis'e kaydeder."""
        self.logger.info(f"💾 Embedding Redis'e kaydediliyor: {doc_id}")
        self.redis_client.set(doc_id, np.array(embedding).tobytes())
        self.logger.info("✅ Embedding Redis'e başarıyla kaydedildi.")

=== save_embedding_to_redis ===
Modül: robustembeddingmodule
Sınıf: RobustEmbeddingProcessor
Program: zapata_m6h

    def save_embedding_to_redis(self, doc_id, embedding):
        """Embedding vektörünü Redis'e kaydeder."""
        if embedding is None:
            self.logger.error(f"❌ {doc_id} için geçersiz embedding, Redis'e kaydedilmedi.")
            return

        self.logger.info(f"💾 Embedding Redis'e kaydediliyor: {doc_id}")
        self.redis_client.set(doc_id, np.array(embedding).tobytes())
        self.logger.info("✅ Embedding Redis'e başarıyla kaydedildi.")

=== save_json ===
Modül: helpermodule
Sınıf: HelperFunctions
Program: zapata_m6h

    def save_json(self, data, file_path):
        """Veriyi JSON dosyasına kaydeder."""
        try:
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=4)
            self.logger.info(f"✅ JSON dosyası kaydedildi: {file_path}")
        except Exception as e:
            self.logger.error(f"❌ JSON kaydetme hatası: {e}")

=== save_model_to_redis ===
Modül: FineTuning
Sınıf: FineTuner
Program: zapata_m6h

    def save_model_to_redis(self):
        """Eğitilmiş modeli Redis'e kaydeder"""
        with open(os.path.join(self.output_dir, "pytorch_model.bin"), "rb") as f:
            model_data = f.read()
            redis_client.set(f"fine_tuned_model:{self.model_name}", model_data)
        logging.info(f"📌 {self.model_name} modeli Redis'e kaydedildi.")

=== save_model_to_redis ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuner
Program: zapata_m6h

    def save_model_to_redis(self):
        """
        Eğitilen modeli Redis içinde saklar.
        """
        with open(os.path.join(self.output_dir, "pytorch_model.bin"), "rb") as f:
            model_data = f.read()
            self.redis_client.set(f"fine_tuned_model_{self.model_name}", model_data)
        logger.info("📌 Eğitilmiş model Redis'e kaydedildi.")

=== save_references ===
Modül: zoteromodule
Sınıf: ZoteroManager
Program: zapata_m6h

    def save_references(self, references, save_path):
        """Kaynakçaları JSON formatında kaydeder."""
        import json

        self.logger.info(f"💾 Kaynakçalar {save_path} dosyasına kaydediliyor...")
        try:
            with open(save_path, "w", encoding="utf-8") as file:
                json.dump(references, file, indent=4, ensure_ascii=False)
            self.logger.info("✅ Kaynakçalar başarıyla kaydedildi.")
            return True
        except Exception as e:
            self.logger.error(f"❌ Kaynakça kaydetme hatası: {e}")
            return False

=== save_references_to_sqlite ===
Modül: zotero_integration
Sınıf: ZoteroIntegration
Program: zapata_m6h

    def save_references_to_sqlite(self, references):
        """Kaynakçaları SQLite veritabanına kaydeder."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        for ref in references:
            item_id = ref["key"]
            title = ref["data"].get("title", "Bilinmiyor")
            authors = ", ".join([creator["lastName"] for creator in ref["data"].get("creators", [])])
            year = ref["data"].get("date", "Bilinmiyor")
            journal = ref["data"].get("publicationTitle", "Bilinmiyor")
            doi = ref["data"].get("DOI", None)
            file_path = ref["data"].get("filePath", None)

            cursor.execute(
                """
                INSERT OR REPLACE INTO references (id, title, authors, year, journal, doi, file_path)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (item_id, title, authors, year, journal, doi, file_path),
            )

        conn.commit()
        conn.close()
        print("✅ Zotero kaynakçaları SQLite veritabanına kaydedildi.")

=== save_to_redis ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def save_to_redis(self, text, doc_id):
        """Temizlenmiş metni Redis önbelleğine kaydeder."""
        self.redis_client.set(f"text:{doc_id}", text)

=== save_to_sqlite ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def save_to_sqlite(self, text, doc_id):
        """Temizlenmiş metni SQLite'e kaydeder."""
        conn = sqlite3.connect(self.sqlite_db)
        cursor = conn.cursor()
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS processed_texts (
                id TEXT PRIMARY KEY,
                text TEXT
            )
        """
        )
        cursor.execute("INSERT OR REPLACE INTO processed_texts (id, text) VALUES (?, ?)", (doc_id, text))
        conn.commit()
        conn.close()

=== search_chromadb ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def search_chromadb(self, queries, top_k=5):
        """ChromaDB üzerinde arama yapar."""
        try:
            collection = self.chroma_client.get_collection("embeddings")
            results = collection.query(query_texts=queries, n_results=top_k)
            return [(doc["id"], doc["score"]) for doc in results["documents"]]
        except Exception as e:
            self.logger.error(f"❌ ChromaDB arama hatası: {e}")
            return []

=== search_chromadb ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def search_chromadb(self, queries, top_k=5):
        """ChromaDB üzerinde arama yapar."""
        try:
            collection = self.chroma_client.get_collection("embeddings")
            results = collection.query(query_texts=queries, n_results=top_k)
            return [(doc["id"], doc["score"]) for doc in results["documents"]]
        except Exception as e:
            self.logger.error(f"❌ ChromaDB arama hatası: {e}")
            return []

=== search_faiss ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def search_faiss(self, queries, top_k=5):
        """FAISS üzerinden arama yapar."""
        try:
            if self.faiss_index:
                query_vec = self.encode_queries(queries)
                distances, indices = self.faiss_index.search(query_vec, top_k)
                results = [(idx, 1 - dist) for idx, dist in zip(indices[0], distances[0])]
                return results
            return []
        except Exception as e:
            self.logger.error(f"❌ FAISS arama hatası: {e}")
            return []

=== search_faiss ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def search_faiss(self, queries, top_k=5):
        """FAISS üzerinden arama yapar."""
        try:
            if self.faiss_index:
                query_vec = self.encode_queries(queries)
                distances, indices = self.faiss_index.search(query_vec, top_k)
                results = [(idx, 1 - dist) for idx, dist in zip(indices[0], distances[0])]
                return results
            return []
        except Exception as e:
            self.logger.error(f"❌ FAISS arama hatası: {e}")
            return []

=== search_in_chromadb ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def search_in_chromadb():
    data = request.json
    query = data.get("query", "")
    if not query:
        return jsonify({"error": "Sorgu metni belirtilmedi."}), 400

    results = search_chromadb(query)
    return jsonify({"results": results}), 200

=== search_in_faiss ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def search_in_faiss():
    data = request.json
    query = data.get("query", "")
    if not query:
        return jsonify({"error": "Sorgu metni belirtilmedi."}), 400

    results = search_faiss(query)
    return jsonify({"results": results}), 200

=== search_redis ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def search_redis(self, queries, top_k=5):
        """Redis üzerinde anahtar kelime bazlı arama yapar."""
        try:
            results = self.redis.search(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"❌ Redis arama hatası: {e}")
            return []

=== search_redis ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def search_redis(self, queries, top_k=5):
        """Redis üzerinde anahtar kelime bazlı arama yapar."""
        try:
            results = self.redis.search(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"❌ Redis arama hatası: {e}")
            return []

=== search_retrieve ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def search_retrieve(self, queries, top_k=5):
        """Retrieve API kullanarak arama yapar."""
        try:
            results = self.retrieve_engine.retrieve_documents(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"❌ Retrieve arama hatası: {e}")
            return []

=== search_similar ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def search_similar(self, query_embedding, top_k=5):
        """Verilen embedding için FAISS üzerinde en benzer vektörleri arar."""
        try:
            query_embedding = np.array(query_embedding, dtype=np.float32).reshape(1, -1)
            distances, indices = self.index.search(query_embedding, top_k)

            self.logger.info(f"🔍 FAISS arama tamamlandı. En yakın {top_k} sonuç döndü.")
            return indices.tolist(), distances.tolist()
        except Exception as e:
            self.logger.error(f"❌ FAISS arama hatası: {e}")
            return None, None

=== search_sqlite ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def search_sqlite(self, queries, top_k=5):
        """SQLite üzerinde tam metin arama yapar."""
        try:
            results = self.sqlite.search_full_text(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"❌ SQLite arama hatası: {e}")
            return []

=== search_sqlite ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def search_sqlite(self, queries, top_k=5):
        """SQLite üzerinde tam metin arama yapar."""
        try:
            results = self.sqlite.search_full_text(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"❌ SQLite arama hatası: {e}")
            return []

=== send_query ===
Modül: retriever_integration
Sınıf: RetrieverIntegration
Program: zapata_m6h

    def send_query(self, query):
        """Retrieve API'ye sorgu gönderir."""
        try:
            response = requests.post(f"{self.retrieve_api_url}/query", json={"query": query})
            response.raise_for_status()
            self.logger.info(f"✅ Retrieve sorgusu başarıyla gönderildi: {query}")
            return response.json()
        except requests.RequestException as e:
            self.logger.error(f"❌ Retrieve API hatası: {e}")
            return None

=== send_to_zapata ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def send_to_zapata(self, item_id):
        """
        Zotero'dan belirli bir makaleyi alıp Zapata'ya gönderir.
        """
        try:
            item = self.zot.item(item_id)
            data = {
                "title": item["data"]["title"],
                "abstract": item["data"].get("abstractNote", ""),
                "authors": item["data"].get("creators", []),
                "publication": item["data"].get("publicationTitle", ""),
                "year": item["data"].get("date", ""),
                "doi": item["data"].get("DOI", ""),
                "pdf_path": item["data"].get("attachments", []),
            }

            response = requests.post(f"{self.zapata_api_url}/analyze", json=data)
            if response.status_code == 200:
                print(f"✅ {item['data']['title']} başarıyla Zapata'ya gönderildi.")
            else:
                print(f"❌ Zapata'ya gönderirken hata oluştu: {response.text}")
        except Exception as e:
            print(f"❌ Zotero'dan Zapata'ya veri gönderirken hata oluştu: {e}")

=== setUpClass ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def setUpClass(cls):
        """
        Test öncesi gerekli kurulumları yapar.
        """
        cls.error_logger = ErrorLogger()
        cls.process_manager = ProcessManager()
        cls.fine_tuner = FineTuner()
        cls.test_log_file = os.path.join(config.LOG_DIR, "test_results.json")
        cls.sqlite_db_path = config.SQLITE_DB_PATH

        logging.basicConfig(
            filename=os.path.join(config.LOG_DIR, "test_log.txt"),
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

=== setup_logging ===
Modül: alternativeembeddingmodule
Sınıf: AlternativeEmbeddingProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("alternative_embedding_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: veri_isleme
Sınıf: CitationAnalyzer
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("veri_isleme.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: citationmappingmodule
Sınıf: CitationMapper
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar (colorlog ile konsol ve dosya loglaması)."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("citation_mapping.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: clustering_module
Sınıf: ClusteringProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("clustering.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: configmodule
Sınıf: Config
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("pdf_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(getattr(logging, self.LOG_LEVEL.upper(), logging.DEBUG))
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)

=== setup_logging ===
Modül: veri_gorsellestirme
Sınıf: DataVisualizer
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("veri_gorsellestirme.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: document_parser
Sınıf: DocumentParser
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("document_parser.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: embeddingmodule
Sınıf: EmbeddingProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("embedding_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("faiss_integration.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: fetch_top_k_results
Sınıf: FetchTopKResults
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("fetch_top_k_results.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: helpermodule
Sınıf: HelperFunctions
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("helpermodule.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: layout_analysis
Sınıf: LayoutAnalyzer
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("layout_analysis.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: multi_source_search
Sınıf: MultiSourceSearch
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("multi_source_search.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: pdfprocessing
Sınıf: PDFProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("pdf_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: query_expansion
Sınıf: QueryExpansion
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("query_expansion.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: rag_pipeline
Sınıf: RAGPipeline
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("rag_pipeline.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("rediscache.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: redisqueue
Sınıf: RedisQueue
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("redisqueue.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: reranking_module
Sınıf: RerankingModule
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("reranking_module.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: retrieval_reranker
Sınıf: RetrievalReranker
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("retrieval_reranker.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: retriever_integration
Sınıf: RetrieverIntegration
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("retriever_integration.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: robustembeddingmodule
Sınıf: RobustEmbeddingProcessor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("robust_embedding.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("sqlite_storage.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: scientific_mapping
Sınıf: ScientificMapper
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("scientific_mapping.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: search_engine
Sınıf: SearchEngine
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("search_engine.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: sync_faiss_chromadb
Sınıf: SyncFAISSChromaDB
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("sync_faiss_chromadb.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: training_monitor
Sınıf: TrainingMonitor
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(console_handler)

=== setup_logging ===
Modül: guimodule
Sınıf: ZapataGUI
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(console_handler)

=== setup_logging ===
Modül: main
Sınıf: ZapataM6H
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("zapata_m6h.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== setup_logging ===
Modül: zoteromodule
Sınıf: ZoteroManager
Program: zapata_m6h

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "bold_red",
            },
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("zotero_processing.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

=== show_mindmap ===
Modül: d3js_visualizer
Sınıf: D3Visualizer
Program: zapata_m6h

    def show_mindmap(self, json_data):
        """
        Zihin haritasını oluşturup varsayılan tarayıcıda açar.
        """
        html_file = self.generate_html(json_data)
        webbrowser.open("file://" + html_file)

=== split_text ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def split_text(self, text, method="paragraph"):
        """Metni cümle bazlı veya paragraf bazlı ayırır."""
        if method == "sentence":
            return sent_tokenize(text)
        elif method == "paragraph":
            return text.split("\n\n")  # Çift newline karakteriyle paragraf bölme
        return [text]

=== start_training ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def start_training():
    data = request.json
    models = data.get("models", [])
    if not models:
        return jsonify({"error": "Eğitim için model seçilmedi."}), 400

    thread = threading.Thread(target=train_selected_models, args=(models,))
    thread.start()

    logging.info(f"📌 Eğitim başlatıldı: {models}")
    return jsonify({"status": "Eğitim başlatıldı.", "models": models}), 200

=== start_training ===
Modül: training_monitor
Sınıf: TrainingMonitor
Program: zapata_m6h

    def start_training(self):
        """Eğitim sürecini başlatır."""
        self.status_label.configure(text="Eğitim Başlatıldı...")
        self.progress_bar.set(0)

        threading.Thread(target=self.run_training).start()

=== stem_words ===
Modül: text_processing
Sınıf: TextProcessor
Program: zapata_m6h

    def stem_words(self, text):
        """Kelime köklerine ayırma işlemi (Stemming)."""
        from nltk.stem import PorterStemmer

        stemmer = PorterStemmer()
        words = word_tokenize(text)
        stemmed_words = [stemmer.stem(word) for word in words]
        return " ".join(stemmed_words)

=== stop_training ===
Modül: rest_api
Sınıf: 
Program: zapata_m6h

def stop_training():
    redis_client.set("training_status", "Durduruldu")
    logging.info("📌 Model eğitimi durduruldu.")
    return jsonify({"status": "Eğitim süreci durduruldu."}), 200

=== store_citation ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def store_citation(self, doc_id, citation):
        """Kaynakçayı SQLite veritabanına kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO citations (doc_id, citation) 
                VALUES (?, ?)
            """,
                (doc_id, json.dumps(citation)),
            )
            self.connection.commit()
            self.logger.info(f"✅ Citation SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"❌ Citation SQLite'e kaydedilemedi: {e}")

=== store_document ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def store_document(self, doc_id, title, authors, abstract, content, metadata):
        """Belgeyi SQLite veritabanına kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO documents (id, title, authors, abstract, content, metadata) 
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (doc_id, title, authors, abstract, content, json.dumps(metadata)),
            )
            self.connection.commit()
            self.logger.info(f"✅ Belge SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"❌ Belge SQLite'e kaydedilemedi: {e}")

=== store_embedding ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def store_embedding(self, key, embedding, ttl=None):
        """Embedding vektörünü Redis’e kaydeder (pickle ile)."""
        try:
            serialized = pickle.dumps(embedding)
            if ttl:
                self.client.setex(key, ttl, serialized)
            else:
                self.client.set(key, serialized)
            self.logger.info(f"✅ {key} için embedding Redis’e kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ Embedding kaydetme hatası: {e}")

=== store_embedding ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def store_embedding(self, doc_id, embedding):
        """Embedding verisini SQLite veritabanına kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO embeddings (doc_id, embedding) 
                VALUES (?, ?)
            """,
                (doc_id, json.dumps(embedding)),
            )
            self.connection.commit()
            self.logger.info(f"✅ Embedding SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"❌ Embedding SQLite'e kaydedilemedi: {e}")

=== store_embedding_to_db ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def store_embedding_to_db(self, doc_id, embedding):
        """Embedding verisini SQLite veritabanına kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                "INSERT INTO faiss_embeddings (doc_id, embedding) VALUES (?, ?)", (doc_id, json.dumps(embedding))
            )
            self.connection.commit()
            self.logger.info(f"✅ {doc_id} için embedding SQLite'e kaydedildi.")
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite embedding kaydetme hatası: {e}")

=== store_mapping_to_db ===
Modül: layout_analysis
Sınıf: LayoutAnalyzer
Program: zapata_m6h

    def store_mapping_to_db(self, doc_id, mapped_layout):
        """Yapısal haritalamayı SQLite'e kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                "INSERT INTO layout_mapping (doc_id, mapping) VALUES (?, ?)", (doc_id, json.dumps(mapped_layout))
            )
            self.connection.commit()
            self.logger.info(f"✅ {doc_id} için yapısal haritalama SQLite'e kaydedildi.")
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite'e kaydetme hatası: {e}")

=== store_mapping_to_db ===
Modül: scientific_mapping
Sınıf: ScientificMapper
Program: zapata_m6h

    def store_mapping_to_db(self, doc_id, structured_sections):
        """Bilimsel haritalamayı SQLite'e kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                "INSERT INTO scientific_mapping (doc_id, mapping) VALUES (?, ?)",
                (doc_id, json.dumps(structured_sections)),
            )
            self.connection.commit()
            self.logger.info(f"✅ {doc_id} için bilimsel haritalama SQLite'e kaydedildi.")
        except sqlite3.Error as e:
            self.logger.error(f"❌ SQLite'e kaydetme hatası: {e}")

=== store_query_result ===
Modül: rediscache
Sınıf: RedisCache
Program: zapata_m6h

    def store_query_result(self, query, result, ttl=3600):
        """Sorgu sonuçlarını Redis’e kaydeder."""
        try:
            self.redis_client_str.setex(query, ttl, json.dumps(result))
            self.logger.info(f"✅ {query} için sorgu sonucu Redis’e kaydedildi.")
        except Exception as e:
            self.logger.error(f"❌ Sorgu sonucu kaydetme hatası: {e}")

=== store_scientific_map ===
Modül: sqlite_storage
Sınıf: SQLiteStorage
Program: zapata_m6h

    def store_scientific_map(self, doc_id, map_data):
        """Bilimsel haritalama verisini SQLite veritabanına kaydeder."""
        try:
            cursor = self.connection.cursor()
            cursor.execute(
                """
                INSERT INTO scientific_maps (doc_id, map_data) 
                VALUES (?, ?)
            """,
                (doc_id, json.dumps(map_data)),
            )
            self.connection.commit()
            self.logger.info(f"✅ Bilimsel haritalama SQLite'e kaydedildi: {doc_id}")
        except sqlite3.Error as e:
            self.logger.error(f"❌ Bilimsel haritalama SQLite'e kaydedilemedi: {e}")

=== sync_from_chromadb_to_faiss ===
Modül: sync_faiss_chromadb
Sınıf: SyncFAISSChromaDB
Program: zapata_m6h

    def sync_from_chromadb_to_faiss(self):
        """ChromaDB’de olup FAISS’te olmayan embedding’leri FAISS’e ekler."""
        try:
            chroma_embeddings = self.chroma_collection.get()
            if not chroma_embeddings:
                self.logger.warning("⚠️ ChromaDB’de senkronize edilecek embedding bulunamadı.")
                return

            faiss_existing_ids = self.redis.get_all_faiss_ids()
            new_embeddings = []
            new_ids = []

            for doc in chroma_embeddings["documents"]:
                doc_id = doc["id"]
                embedding = np.array(doc["embedding"], dtype=np.float32)

                if doc_id not in faiss_existing_ids:
                    new_embeddings.append(embedding)
                    new_ids.append(int(doc_id))

            if new_embeddings:
                self.faiss_index.add_with_ids(np.array(new_embeddings), np.array(new_ids))
                faiss.write_index(self.faiss_index, "faiss_index.idx")
                self.redis.store_faiss_ids(new_ids)
                self.logger.info(f"✅ {len(new_embeddings)} yeni embedding FAISS'e eklendi.")
            else:
                self.logger.info("✅ FAISS zaten güncel, yeni embedding eklenmedi.")

        except Exception as e:
            self.logger.error(f"❌ FAISS senkronizasyon hatası: {e}")

=== sync_from_faiss_to_chromadb ===
Modül: sync_faiss_chromadb
Sınıf: SyncFAISSChromaDB
Program: zapata_m6h

    def sync_from_faiss_to_chromadb(self):
        """FAISS’te olup ChromaDB’de olmayan embedding’leri ChromaDB’ye ekler."""
        try:
            faiss_existing_ids = self.redis.get_all_faiss_ids()
            chroma_existing_ids = self.chroma_collection.get()["ids"]

            missing_in_chroma = set(faiss_existing_ids) - set(chroma_existing_ids)
            if not missing_in_chroma:
                self.logger.info("✅ ChromaDB zaten güncel, FAISS'ten eksik veri yok.")
                return

            embeddings_to_add = []
            for doc_id in missing_in_chroma:
                embedding_vector = self.faiss_index.reconstruct(int(doc_id))
                embeddings_to_add.append({"id": str(doc_id), "embedding": embedding_vector.tolist()})

            self.chroma_collection.add(embeddings_to_add)
            self.logger.info(f"✅ {len(embeddings_to_add)} embedding ChromaDB'ye eklendi.")

        except Exception as e:
            self.logger.error(f"❌ ChromaDB senkronizasyon hatası: {e}")

=== sync_with_chromadb ===
Modül: faiss_integration
Sınıf: FAISSIntegration
Program: zapata_m6h

    def sync_with_chromadb(self, chroma_embeddings):
        """FAISS indeksini ChromaDB'den alınan verilerle senkronize eder."""
        try:
            for doc_id, embedding in chroma_embeddings.items():
                self.add_embedding(doc_id, embedding)
            self.logger.info("✅ FAISS ile ChromaDB senkronizasyonu tamamlandı.")
        except Exception as e:
            self.logger.error(f"❌ FAISS-ChromaDB senkronizasyon hatası: {e}")

=== sync_with_zapata ===
Modül: zotero_extension
Sınıf: ZoteroExtension
Program: zapata_m6h

    def sync_with_zapata(self):
        """
        Zotero'daki tüm referansları Zapata ile senkronize eder.
        """
        try:
            references = self.fetch_all_references()
            for ref in references:
                self.send_to_zapata(ref["key"])
        except Exception as e:
            print(f"❌ Zotero senkronizasyonunda hata oluştu: {e}")

=== tearDownClass ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def tearDownClass(cls):
        """
        Testler tamamlandıktan sonra yapılacak işlemler.
        """
        print("✅ Tüm testler tamamlandı.")

=== test_citation_mapping ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def test_citation_mapping(self):
        """
        Metin içi atıf analizinin düzgün çalıştığını test eder.
        """
        try:
            test_text = "Bu bir test cümlesidir [1]."
            references = ["Kaynak 1"]
            mapped = map_citations_to_references(test_text, references)
            self.assertTrue("[1]" in mapped)
            self.log_test_result("test_citation_mapping", "PASS")
        except Exception as e:
            self.log_test_result("test_citation_mapping", "FAIL", str(e))
            self.fail(f"Atıf eşleme testi başarısız oldu: {e}")

=== test_error_logging ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def test_error_logging(self):
        """
        Hata loglama sisteminin düzgün çalıştığını test eder.
        """
        try:
            self.error_logger.log_error(
                "Test hatası", "ERROR", "test_module", "test_function", "Detaylı hata açıklaması"
            )
            self.log_test_result("test_error_logging", "PASS")
        except Exception as e:
            self.log_test_result("test_error_logging", "FAIL", str(e))
            self.fail(f"Hata loglama testi başarısız oldu: {e}")

=== test_fetch_results ===
Modül: fetch_top_k_results
Sınıf: FetchTopKResults
Program: zapata_m6h

    def test_fetch_results(self):
        """Otomatik test mekanizması"""
        test_queries = [
            "Bilimsel makale analizleri",
            "Makine öğrenmesi modelleri",
            "Doğal dil işleme teknikleri",
            "Veri madenciliği algoritmaları",
            "Hata loglama sistemleri",
        ]

        for query in test_queries:
            self.logger.info(f"🛠 Test ediliyor: {query}")
            results = self.fetch_results(query)
            if results:
                self.logger.info(f"✅ Test başarılı: {len(results)} sonuç bulundu.")
            else:
                self.logger.warning(f"⚠️ Test başarısız: Sonuç bulunamadı.")

=== test_fine_tuning ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def test_fine_tuning(self):
        """
        Fine-tuning modelinin başlatılabilir olup olmadığını test eder.
        """
        try:
            texts, labels = self.fine_tuner.fetch_training_data()
            self.assertIsInstance(texts, list)
            self.assertIsInstance(labels, list)
            self.log_test_result("test_fine_tuning", "PASS")
        except Exception as e:
            self.log_test_result("test_fine_tuning", "FAIL", str(e))
            self.fail(f"Fine-tuning testi başarısız oldu: {e}")

=== test_pdf_processing ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def test_pdf_processing(self):
        """
        PDF'den metin çıkarma işlemini test eder.
        """
        try:
            test_pdf_path = "test_papers/sample.pdf"
            extracted_text = extract_text_from_pdf(test_pdf_path)
            self.assertTrue(isinstance(extracted_text, str) and len(extracted_text) > 0)
            self.log_test_result("test_pdf_processing", "PASS")
        except Exception as e:
            self.log_test_result("test_pdf_processing", "FAIL", str(e))
            self.fail(f"PDF işleme testi başarısız oldu: {e}")

=== test_process_manager ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def test_process_manager(self):
        """
        Görev kuyruğu yönetiminin çalıştığını test eder.
        """
        try:
            self.process_manager.enqueue_task("test_task")
            task = self.process_manager.dequeue_task()
            self.assertEqual(task, "test_task")
            self.log_test_result("test_process_manager", "PASS")
        except Exception as e:
            self.log_test_result("test_process_manager", "FAIL", str(e))
            self.fail(f"Process Manager testi başarısız oldu: {e}")

=== test_save_clean_text ===
Modül: test_suite
Sınıf: TestZapataModules
Program: zapata_m6h

    def test_save_clean_text(self):
        """
        Temiz metinlerin kaydedildiğini test eder.
        """
        try:
            test_text = "Bu bir test metnidir."
            save_clean_text(test_text, "test_output.txt")
            self.assertTrue(os.path.exists("test_output.txt"))
            self.log_test_result("test_save_clean_text", "PASS")
        except Exception as e:
            self.log_test_result("test_save_clean_text", "FAIL", str(e))
            self.fail(f"Temiz metin kaydetme testi başarısız oldu: {e}")

=== train_model ===
Modül: FineTuning
Sınıf: FineTuner
Program: zapata_m6h

    def train_model(self):
        """Modeli eğitir ve kaydeder"""
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch",
        )

        trainer = Trainer(model=self.model, args=training_args, train_dataset=dataset, tokenizer=self.tokenizer)

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        logging.info(f"✅ {self.model_name} modeli eğitildi ve {self.output_dir} dizinine kaydedildi.")

=== train_model ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuner
Program: zapata_m6h

    def train_model(self):
        """
        Modeli fine-tune ederek eğitir.
        """
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch",
        )

        trainer = Trainer(model=self.model, args=training_args, train_dataset=dataset, tokenizer=self.tokenizer)

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        logger.info(f"✅ Model {self.model_name} eğitildi ve {self.output_dir} dizinine kaydedildi.")

=== train_model ===
Modül: yapay_zeka_finetuning
Sınıf: FineTuningManager
Program: zapata_m6h

    def train_model(self):
        """
        Modeli fine-tune ederek eğitir.
        """
        texts, labels = self.fetch_training_data()
        dataset = FineTuningDataset(texts, labels, self.tokenizer)

        training_args = TrainingArguments(
            output_dir=self.output_dir,
            per_device_train_batch_size=self.batch_size,
            num_train_epochs=self.epochs,
            learning_rate=self.learning_rate,
            logging_dir=os.path.join(self.output_dir, "logs"),
            save_strategy="epoch",
        )

        trainer = Trainer(model=self.model, args=training_args, train_dataset=dataset, tokenizer=self.tokenizer)

        trainer.train()
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        logger.info(f"✅ Model {self.model_name} eğitildi ve {self.output_dir} dizinine kaydedildi.")

=== train_selected_models ===
Modül: FineTuning
Sınıf: 
Program: zapata_m6h

def train_selected_models(model_list):
    """Seçilen modelleri multiprocessing ile eğitir"""
    with ProcessPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
        executor.map(parallel_finetune, model_list)

=== visualize_citation_network ===
Modül: mindmap_visualizer
Sınıf: MindMapVisualizer
Program: zapata_m6h

    def visualize_citation_network(self):
        """
        Zotero’daki atıf ilişkilerini bir zihin haritası olarak görselleştirir.
        """
        graph = self.extract_citation_network()
        plt.figure(figsize=(12, 8))

        pos = nx.spring_layout(graph, seed=42)
        labels = {node: data["label"] for node, data in graph.nodes(data=True)}

        nx.draw(graph, pos, with_labels=True, node_size=3000, node_color="lightblue", edge_color="gray", font_size=10)
        nx.draw_networkx_labels(graph, pos, labels, font_size=8, font_weight="bold")

        output_path = os.path.join(self.output_folder, "citation_network.png")
        plt.savefig(output_path)
        plt.show()

        print(f"✅ Zihin haritası oluşturuldu: {output_path}")

