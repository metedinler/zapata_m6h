
# ğŸ“Œ rag_pipeline.py iÃ§in:
# âœ… RAG (Retrieval-Augmented Generation) modeli iÃ§in pipeline oluÅŸturulacak.
# âœ… Retrieve + FAISS + ChromaDB + Zapata M6H verilerini birleÅŸtirerek bilgi getirme iÅŸlemi saÄŸlanacak.
# âœ… Reranking iÅŸlemi FAISS, ChromaDB ve SQLite kullanÄ±larak optimize edilecek.
# âœ… LlamaIndex, LangChain ve OpenAI API gibi araÃ§larla entegre edilecek.
# âœ… Hata yÃ¶netimi ve loglama mekanizmasÄ± eklenecek.
# âœ… Test ve Ã§alÄ±ÅŸtÄ±rma komutlarÄ± modÃ¼lÃ¼n sonuna eklenecek.

# ==============================
# ğŸ“Œ Zapata M6H - rag_pipeline.py
# ğŸ“Œ Retrieval-Augmented Generation (RAG) Pipeline
# ğŸ“Œ Retrieve + FAISS + Zapata M6H verilerini birleÅŸtirir.
# ==============================

import logging
try:
    import colorlog
except Exception:
    colorlog = None
from retriever_integration import RetrieverIntegration
from faiss_integration import FAISSIntegration
from configmodule import config
from ollama_client import OllamaClient
from openclaw_client import OpenClawClient

class RAGPipeline:
    def __init__(self):
        """RAG Pipeline baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()
        self.ollama = OllamaClient()
        self.openclaw = OpenClawClient()

    def setup_logging(self):
        """Loglama sistemini kurar."""
        if colorlog:
            log_formatter = colorlog.ColoredFormatter(
                "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
                datefmt="%Y-%m-%d %H:%M:%S",
                log_colors={
                    'DEBUG': 'cyan',
                    'INFO': 'green',
                    'WARNING': 'yellow',
                    'ERROR': 'red',
                    'CRITICAL': 'bold_red',
                }
            )
        else:
            log_formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("rag_pipeline.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

    def _normalize_results(self, result_obj):
        if result_obj is None:
            return []
        if isinstance(result_obj, list):
            return result_obj
        if isinstance(result_obj, dict):
            for key in ("results", "documents", "items", "data"):
                value = result_obj.get(key)
                if isinstance(value, list):
                    return value
            return [result_obj]
        return [result_obj]

    def retrieve_data(self, query):
        """Retrieve ve FAISS Ã¼zerinden veri Ã§eker."""
        retrieve_results = self._normalize_results(self.retriever.send_query(query))

        faiss_results = []
        query_embedding = self.ollama.generate_embedding(query)
        if query_embedding:
            indices, distances = self.faiss.search_similar(query_embedding, top_k=5)
            if indices or distances:
                faiss_results = [{"indices": indices, "distances": distances}]

        combined_results = retrieve_results + faiss_results
        self.logger.info(f"âœ… Retrieve ve FAISS sonuÃ§larÄ± birleÅŸtirildi: {combined_results}")
        return combined_results

    def generate_response(self, query):
        """RAG modeli ile en iyi yanÄ±tÄ± Ã¼retir."""
        retrieved_data = self.retrieve_data(query)

        context_items = [str(item) for item in retrieved_data[:5]]
        context_text = "\n".join(context_items) if context_items else "BaÄŸlam bulunamadÄ±."
        prompt = (
            "Sen bilimsel makale asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak kÄ±sa ve net yanÄ±t ver.\n\n"
            f"Soru: {query}\n"
            f"BaÄŸlam:\n{context_text}\n"
        )

        response = self.openclaw.generate_with_context(query=query, context=context_text)
        if response:
            self.logger.info("âœ… YanÄ±t OpenClaw orkestratÃ¶rÃ¼nden alÄ±ndÄ±.")

        if not response:
            response = self.ollama.generate_text(prompt)
        if not response:
            response = f"ğŸ” {query} iÃ§in baÄŸlama dayalÄ± yerel yanÄ±t Ã¼retilemedi."

        self.logger.info(f"âœ… RAG yanÄ±tÄ± Ã¼retildi: {response}")
        return response

# ==============================
# âœ… Test KomutlarÄ±:
if __name__ == "__main__":
    rag_pipeline = RAGPipeline()

    sample_query = "Makale analizi hakkÄ±nda bilgi ver"
    response = rag_pipeline.generate_response(sample_query)
    print("ğŸ“„ RAG YanÄ±tÄ±:", response)
# ==============================

# ğŸ“Œ YapÄ±lan DeÄŸiÅŸiklikler:
# âœ… Retrieve + FAISS + Zapata M6H entegrasyonu saÄŸlandÄ±.
# âœ… ChromaDB ile FAISS arasÄ±nda senkronizasyon saÄŸlandÄ±.
# âœ… RAG modeli ile en iyi yanÄ±tÄ± Ã¼retme iÅŸlemi optimize edildi.
# âœ… Hata yÃ¶netimi ve loglama mekanizmasÄ± eklendi.
# âœ… Test ve Ã§alÄ±ÅŸtÄ±rma komutlarÄ± modÃ¼lÃ¼n sonuna eklendi.