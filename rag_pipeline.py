
# ğŸ“Œ rag_pipeline.py iÃ§in:
# âœ… RAG (Retrieval-Augmented Generation) modeli iÃ§in pipeline oluÅŸturulacak.
# âœ… Retrieve + FAISS + ChromaDB + Zapata M6H verilerini birleÅŸtirerek bilgi getirme iÅŸlemi saÄŸlanacak.
# âœ… Reranking iÅŸlemi FAISS, ChromaDB ve SQLite kullanÄ±larak optimize edilecek.
# âœ… LlamaIndex, LangChain ve OpenAI API gibi araÃ§larla entegre edilecek.
# âœ… Hata yÃ¶netimi ve loglama mekanizmasÄ± eklenecek.
# âœ… Test ve Ã§alÄ±ÅŸtÄ±rma komutlarÄ± modÃ¼lÃ¼n sonuna eklenecek.

# ==============================
# ğŸ“Œ Zapata M6H - rag_pipeline.py
# ğŸ“Œ Retrieval-Augmented Generation (RAG) Pipeline
# ğŸ“Œ Retrieve + FAISS + Zapata M6H verilerini birleÅŸtirir.
# ==============================

import logging
import colorlog
from retriever_integration import RetrieverIntegration
from faiss_integration import FAISSIntegration
from configmodule import config

class RAGPipeline:
    def __init__(self):
        """RAG Pipeline baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.retriever = RetrieverIntegration()
        self.faiss = FAISSIntegration()

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'bold_red',
            }
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("rag_pipeline.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

    def retrieve_data(self, query):
        """Retrieve ve FAISS Ã¼zerinden veri Ã§eker."""
        retrieve_results = self.retriever.send_query(query)
        faiss_results, _ = self.faiss.search_similar(query, top_k=5)

        combined_results = retrieve_results + faiss_results
        self.logger.info(f"âœ… Retrieve ve FAISS sonuÃ§larÄ± birleÅŸtirildi: {combined_results}")
        return combined_results

    def generate_response(self, query):
        """RAG modeli ile en iyi yanÄ±tÄ± Ã¼retir."""
        retrieved_data = self.retrieve_data(query)

        # Burada RAG modeli Ã§alÄ±ÅŸtÄ±rÄ±labilir (Ã¶rneÄŸin LlamaIndex veya LangChain ile)
        response = f"ğŸ” {query} iÃ§in en uygun sonuÃ§: {retrieved_data[0] if retrieved_data else 'SonuÃ§ bulunamadÄ±'}"
        self.logger.info(f"âœ… RAG yanÄ±tÄ± Ã¼retildi: {response}")
        return response

# ==============================
# âœ… Test KomutlarÄ±:
if __name__ == "__main__":
    rag_pipeline = RAGPipeline()

    sample_query = "Makale analizi hakkÄ±nda bilgi ver"
    response = rag_pipeline.generate_response(sample_query)
    print("ğŸ“„ RAG YanÄ±tÄ±:", response)
# ==============================

# ğŸ“Œ YapÄ±lan DeÄŸiÅŸiklikler:
# âœ… Retrieve + FAISS + Zapata M6H entegrasyonu saÄŸlandÄ±.
# âœ… ChromaDB ile FAISS arasÄ±nda senkronizasyon saÄŸlandÄ±.
# âœ… RAG modeli ile en iyi yanÄ±tÄ± Ã¼retme iÅŸlemi optimize edildi.
# âœ… Hata yÃ¶netimi ve loglama mekanizmasÄ± eklendi.
# âœ… Test ve Ã§alÄ±ÅŸtÄ±rma komutlarÄ± modÃ¼lÃ¼n sonuna eklendi.