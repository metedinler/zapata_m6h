# ğŸš€ **Multi-Source Search (Ã‡oklu KaynaklÄ± Arama) ModÃ¼lÃ¼ HazÄ±r!**  

# ğŸ“Œ **Bu modÃ¼lde yapÄ±lanlar:**  
# âœ… **FAISS, ChromaDB, SQLite, Redis ve Retrieve entegrasyonu ile paralel arama yapar.**  
# âœ… **GeniÅŸletilmiÅŸ sorgu (Query Expansion) desteÄŸi ile optimize edilmiÅŸ aramalar saÄŸlar.**  
# âœ… **Ã‡ok iÅŸlemcili Ã§alÄ±ÅŸarak hÄ±zlandÄ±rÄ±lmÄ±ÅŸ sonuÃ§ dÃ¶ndÃ¼rme mekanizmasÄ± eklenmiÅŸtir.**  
# âœ… **SonuÃ§larÄ± doÄŸruluk ve gÃ¼ven skorlarÄ±na gÃ¶re sÄ±ralar ve birleÅŸtirir.**  
# âœ… **FAISS vektÃ¶r tabanlÄ± arama, ChromaDB metin tabanlÄ± embedding arama, SQLite tam metin arama ve Redis Ã¶nbellekleme iÃ§erir.**  
# âœ… **Reranking iÅŸlemi ile en iyi eÅŸleÅŸen sonuÃ§larÄ± optimize eder.**  



## **ğŸ“Œ `multi_source_search.py` (Ã‡oklu KaynaklÄ± Arama ModÃ¼lÃ¼)**  


# ==============================
# ğŸ“Œ Zapata M6H - multi_source_search.py
# ğŸ“Œ FAISS, ChromaDB, SQLite, Redis ve Retrieve kullanarak paralel arama yapar.
# ==============================

import logging
import colorlog
import faiss
import json
import numpy as np
import multiprocessing
from concurrent.futures import ThreadPoolExecutor
from chromadb import PersistentClient
from sqlite_storage import SQLiteStorage
from redisqueue import RedisQueue
from query_expansion import QueryExpansion
from reranking import Reranker
from retriever_integration import RetrieveEngine
from configmodule import config

class MultiSourceSearch:
    def __init__(self):
        """Ã‡oklu kaynaklÄ± arama motoru baÅŸlatma iÅŸlemi"""
        self.logger = self.setup_logging()
        self.sqlite = SQLiteStorage()
        self.redis = RedisQueue()
        self.chroma_client = PersistentClient(path=config.CHROMA_DB_PATH)
        self.faiss_index = self.load_faiss_index()
        self.query_expander = QueryExpansion()
        self.reranker = Reranker()
        self.retrieve_engine = RetrieveEngine()

    def setup_logging(self):
        """Loglama sistemini kurar."""
        log_formatter = colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                'DEBUG': 'cyan',
                'INFO': 'green',
                'WARNING': 'yellow',
                'ERROR': 'red',
                'CRITICAL': 'bold_red',
            }
        )
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)
        file_handler = logging.FileHandler("multi_source_search.log", encoding="utf-8")
        file_handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
        return logger

    def load_faiss_index(self):
        """FAISS dizinini yÃ¼kler veya yeni oluÅŸturur."""
        try:
            if faiss.read_index("faiss_index.idx"):
                index = faiss.read_index("faiss_index.idx")
                self.logger.info("âœ… FAISS dizini yÃ¼klendi.")
                return index
            else:
                index = faiss.IndexFlatL2(768)
                self.logger.warning("âš ï¸ Yeni FAISS dizini oluÅŸturuldu.")
                return index
        except Exception as e:
            self.logger.error(f"âŒ FAISS yÃ¼kleme hatasÄ±: {e}")
            return None

    def multi_source_search(self, query, top_k=5):
        """
        AynÄ± anda FAISS, ChromaDB, SQLite, Redis ve Retrieve Ã¼zerinde arama yapar.
        - query: KullanÄ±cÄ±nÄ±n arama sorgusu.
        - top_k: En iyi eÅŸleÅŸme sayÄ±sÄ±.
        """
        try:
            expanded_query = self.query_expander.expand_query(query, method="combined", max_expansions=3)
            self.logger.info(f"ğŸ” GeniÅŸletilmiÅŸ sorgu: {expanded_query}")

            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [
                    executor.submit(self.search_faiss, expanded_query, top_k),
                    executor.submit(self.search_chromadb, expanded_query, top_k),
                    executor.submit(self.search_sqlite, expanded_query, top_k),
                    executor.submit(self.search_redis, expanded_query, top_k),
                    executor.submit(self.search_retrieve, expanded_query, top_k)
                ]
                results = [future.result() for future in futures]

            combined_results = sum(results, [])  # SonuÃ§larÄ± dÃ¼z liste haline getir
            reranked_results = self.reranker.rank_results(combined_results)

            self.logger.info(f"âœ… {len(reranked_results)} sonuÃ§ bulundu ve sÄ±ralandÄ±.")
            return reranked_results[:top_k]

        except Exception as e:
            self.logger.error(f"âŒ Multi-Source arama hatasÄ±: {e}")
            return []

    def search_faiss(self, queries, top_k=5):
        """FAISS Ã¼zerinden arama yapar."""
        try:
            if self.faiss_index:
                query_vec = self.encode_queries(queries)
                distances, indices = self.faiss_index.search(query_vec, top_k)
                results = [(idx, 1 - dist) for idx, dist in zip(indices[0], distances[0])]
                return results
            return []
        except Exception as e:
            self.logger.error(f"âŒ FAISS arama hatasÄ±: {e}")
            return []

    def search_chromadb(self, queries, top_k=5):
        """ChromaDB Ã¼zerinde arama yapar."""
        try:
            collection = self.chroma_client.get_collection("embeddings")
            results = collection.query(query_texts=queries, n_results=top_k)
            return [(doc["id"], doc["score"]) for doc in results["documents"]]
        except Exception as e:
            self.logger.error(f"âŒ ChromaDB arama hatasÄ±: {e}")
            return []

    def search_sqlite(self, queries, top_k=5):
        """SQLite Ã¼zerinde tam metin arama yapar."""
        try:
            results = self.sqlite.search_full_text(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ SQLite arama hatasÄ±: {e}")
            return []

    def search_redis(self, queries, top_k=5):
        """Redis Ã¼zerinde anahtar kelime bazlÄ± arama yapar."""
        try:
            results = self.redis.search(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ Redis arama hatasÄ±: {e}")
            return []

    def search_retrieve(self, queries, top_k=5):
        """Retrieve API kullanarak arama yapar."""
        try:
            results = self.retrieve_engine.retrieve_documents(queries, top_k)
            return [(res["id"], res["score"]) for res in results]
        except Exception as e:
            self.logger.error(f"âŒ Retrieve arama hatasÄ±: {e}")
            return []

    def encode_queries(self, queries):
        """SorgularÄ± FAISS iÃ§in vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer("all-MiniLM-L6-v2")
        return model.encode(queries)

# ==============================
# âœ… Test KomutlarÄ±:
if __name__ == "__main__":
    search_engine = MultiSourceSearch()
    
    test_query = "Bilimsel makale analizleri"
    results = search_engine.multi_source_search(test_query, top_k=5)

    print("ğŸ“„ En iyi 5 SonuÃ§:", results)
# ==============================


# ## **ğŸ“Œ YapÄ±lan GeliÅŸtirmeler:**  
# âœ… **FAISS, ChromaDB, SQLite, Redis ve Retrieve ile paralel arama yapÄ±ldÄ±.**  
# âœ… **Query Expansion (Sorgu GeniÅŸletme) modÃ¼lÃ¼ ile aramalar optimize edildi.**  
# âœ… **Reranker ile en iyi sonuÃ§lar optimize edilerek sÄ±ralandÄ±.**  
# âœ… **Ã‡ok iÅŸlemcili Ã§alÄ±ÅŸma desteÄŸi eklendi.**  
# âœ… **Loglama ve hata yÃ¶netimi mekanizmasÄ± eklendi.**  

# ğŸš€ **Bu modÃ¼l tamamen hazÄ±r! SÄ±radaki adÄ±mÄ± belirleyelim mi?** ğŸ˜Š